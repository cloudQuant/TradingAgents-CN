#!/usr/bin/env python3
"""
è¯Šæ–­ fund_etf_fund_info_em æ•°æ®é›†åˆçš„é—®é¢˜
åˆ†æä¸ºä»€ä¹ˆæ‰¹é‡ä¸‹è½½æ˜¾ç¤ºæˆåŠŸ1300å¤šä¸ªï¼Œä½†å®é™…åªæœ‰300å¤šä¸ªåŸºé‡‘
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.core.database import get_mongo_db, init_database, close_database
from app.services.data_sources.funds.providers.fund_etf_fund_info_em_provider import FundEtfFundInfoEmProvider
import pandas as pd


async def diagnose():
    """è¯Šæ–­æ•°æ®é—®é¢˜"""
    # åˆå§‹åŒ–æ•°æ®åº“
    await init_database()
    
    try:
        db = get_mongo_db()
        
        # 1. æ£€æŸ¥æºé›†åˆ fund_etf_fund_daily_em ä¸­çš„åŸºé‡‘ä»£ç æ•°é‡
        source_collection = db.get_collection("fund_etf_fund_daily_em")
        source_codes = await source_collection.distinct("åŸºé‡‘ä»£ç ")
        print(f"ğŸ“Š æºé›†åˆ fund_etf_fund_daily_em ä¸­çš„åŸºé‡‘ä»£ç æ•°é‡: {len(source_codes)}")
        
        # 2. æ£€æŸ¥ç›®æ ‡é›†åˆ fund_etf_fund_info_em ä¸­çš„åŸºé‡‘ä»£ç æ•°é‡
        target_collection = db.get_collection("fund_etf_fund_info_em")
        target_codes = await target_collection.distinct("åŸºé‡‘ä»£ç ")
        print(f"ğŸ“Š ç›®æ ‡é›†åˆ fund_etf_fund_info_em ä¸­çš„åŸºé‡‘ä»£ç æ•°é‡: {len(target_codes)}")
        
        # 3. æ‰¾å‡ºæºé›†åˆä¸­æœ‰ä½†ç›®æ ‡é›†åˆä¸­æ²¡æœ‰çš„åŸºé‡‘ä»£ç 
        missing_codes = set(source_codes) - set(target_codes)
        print(f"âŒ æºé›†åˆä¸­æœ‰ä½†ç›®æ ‡é›†åˆä¸­æ²¡æœ‰çš„åŸºé‡‘ä»£ç æ•°é‡: {len(missing_codes)}")
        
        if missing_codes:
            print(f"\nå‰10ä¸ªç¼ºå¤±çš„åŸºé‡‘ä»£ç : {list(missing_codes)[:10]}")
            
            # 4. æµ‹è¯•å…¶ä¸­ä¸€ä¸ªç¼ºå¤±çš„åŸºé‡‘ä»£ç ï¼Œçœ‹çœ‹èƒ½å¦è·å–æ•°æ®
            test_code = list(missing_codes)[0]
            print(f"\nğŸ” æµ‹è¯•åŸºé‡‘ä»£ç : {test_code}")
            
            provider = FundEtfFundInfoEmProvider()
            try:
                df = provider.fetch_data(fund_code=test_code)
                if df is not None and not df.empty:
                    print(f"âœ… æˆåŠŸè·å–æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
                    print(f"   æ•°æ®åˆ—: {list(df.columns)}")
                    print(f"   æ˜¯å¦æœ‰'åŸºé‡‘ä»£ç 'åˆ—: {'åŸºé‡‘ä»£ç ' in df.columns}")
                    if 'åŸºé‡‘ä»£ç ' in df.columns:
                        unique_codes = df['åŸºé‡‘ä»£ç '].unique()
                        print(f"   æ•°æ®ä¸­çš„åŸºé‡‘ä»£ç : {unique_codes[:5]}...")
                        print(f"   åŸºé‡‘ä»£ç æ˜¯å¦ä¸å‚æ•°ä¸€è‡´: {test_code in unique_codes}")
                else:
                    print(f"âŒ è·å–çš„æ•°æ®ä¸ºç©º")
            except Exception as e:
                print(f"âŒ è·å–æ•°æ®å¤±è´¥: {e}")
        
        # 5. æ£€æŸ¥ç›®æ ‡é›†åˆä¸­çš„æ•°æ®ç»Ÿè®¡
        total_docs = await target_collection.count_documents({})
        print(f"\nğŸ“Š ç›®æ ‡é›†åˆæ€»æ–‡æ¡£æ•°: {total_docs}")
        
        # 6. æ£€æŸ¥æ˜¯å¦æœ‰åŸºé‡‘ä»£ç ä¸ºç©ºæˆ–å¼‚å¸¸çš„æ•°æ®
        empty_code_count = await target_collection.count_documents({"åŸºé‡‘ä»£ç ": {"$in": [None, "", "nan"]}})
        print(f"âš ï¸  åŸºé‡‘ä»£ç ä¸ºç©ºæˆ–å¼‚å¸¸çš„æ–‡æ¡£æ•°: {empty_code_count}")
        
        # 7. æ£€æŸ¥æ¯ä¸ªåŸºé‡‘ä»£ç çš„æ•°æ®æ¡æ•°åˆ†å¸ƒ
        pipeline = [
            {"$group": {
                "_id": "$åŸºé‡‘ä»£ç ",
                "count": {"$sum": 1}
            }},
            {"$sort": {"count": -1}},
            {"$limit": 10}
        ]
        top_funds = await target_collection.aggregate(pipeline).to_list(None)
        print(f"\nğŸ“Š æ•°æ®æ¡æ•°æœ€å¤šçš„å‰10ä¸ªåŸºé‡‘:")
        for fund in top_funds:
            print(f"   {fund['_id']}: {fund['count']} æ¡")
        
        # 8. æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„åŸºé‡‘ä»£ç +å‡€å€¼æ—¥æœŸç»„åˆ
        pipeline = [
            {"$group": {
                "_id": {"åŸºé‡‘ä»£ç ": "$åŸºé‡‘ä»£ç ", "å‡€å€¼æ—¥æœŸ": "$å‡€å€¼æ—¥æœŸ"},
                "count": {"$sum": 1}
            }},
            {"$match": {"count": {"$gt": 1}}},
            {"$limit": 10}
        ]
        duplicates = await target_collection.aggregate(pipeline).to_list(None)
        if duplicates:
            print(f"\nâš ï¸  å‘ç°é‡å¤çš„åŸºé‡‘ä»£ç +å‡€å€¼æ—¥æœŸç»„åˆ: {len(duplicates)} ä¸ª")
            for dup in duplicates[:5]:
                print(f"   {dup['_id']}: {dup['count']} æ¡é‡å¤")
        else:
            print(f"\nâœ… æœªå‘ç°é‡å¤çš„åŸºé‡‘ä»£ç +å‡€å€¼æ—¥æœŸç»„åˆ")
    
    finally:
        # å…³é—­æ•°æ®åº“è¿æ¥
        await close_database()


if __name__ == "__main__":
    asyncio.run(diagnose())

#!/usr/bin/env python3
"""
æ£€æŸ¥fund_info_index_emé›†åˆä¸­æ˜¯å¦è¿˜æœ‰NaN/Infinityå€¼
å¹¶æ˜¾ç¤ºå…·ä½“å“ªäº›å­—æ®µå’Œè®°å½•æœ‰é—®é¢˜
"""
import asyncio
import logging
import sys
import math
from pathlib import Path

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from app.core.database import get_mongo_db, init_database, close_database

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def check_value(value):
    """æ£€æŸ¥å€¼æ˜¯å¦ä¸ºæ— æ•ˆæµ®ç‚¹æ•°"""
    if not isinstance(value, (int, float)):
        return False, None
    if isinstance(value, bool):
        return False, None
    try:
        if math.isnan(value):
            return True, "NaN"
        elif math.isinf(value):
            return True, "Infinity" if value > 0 else "-Infinity"
    except (TypeError, ValueError):
        pass
    return False, None


async def check_collection():
    """æ£€æŸ¥é›†åˆä¸­çš„æ— æ•ˆæ•°æ®"""
    try:
        db = get_mongo_db()
        collection = db.get_collection('fund_info_index_em')
        
        total = await collection.count_documents({})
        logger.info(f"æ€»è®°å½•æ•°: {total}")
        
        if total == 0:
            logger.warning("âš ï¸ é›†åˆä¸ºç©º")
            return False
        
        # éšæœºæŠ½æŸ¥ä¸€äº›è®°å½•
        sample_size = min(50, total)
        logger.info(f"æŠ½æŸ¥ {sample_size} æ¡è®°å½•...")
        
        cursor = collection.aggregate([
            {"$sample": {"size": int(sample_size)}}
        ])
        
        problem_count = 0
        problem_fields = {}
        
        async for doc in cursor:
            fund_code = doc.get('åŸºé‡‘ä»£ç ', 'Unknown')
            has_problem = False
            
            for key, value in doc.items():
                if key == '_id':
                    continue
                    
                is_invalid, invalid_type = check_value(value)
                if is_invalid:
                    has_problem = True
                    if key not in problem_fields:
                        problem_fields[key] = 0
                    problem_fields[key] += 1
                    logger.warning(
                        f"å‘ç°é—®é¢˜: åŸºé‡‘ä»£ç ={fund_code}, å­—æ®µ={key}, "
                        f"å€¼={value}, ç±»å‹={invalid_type}"
                    )
            
            if has_problem:
                problem_count += 1
        
        logger.info("=" * 60)
        logger.info(f"æŠ½æŸ¥ç»“æœ:")
        logger.info(f"  - æœ‰é—®é¢˜çš„è®°å½•: {problem_count}/{sample_size}")
        
        if problem_fields:
            logger.info(f"  - æœ‰é—®é¢˜çš„å­—æ®µ:")
            for field, count in sorted(problem_fields.items(), key=lambda x: x[1], reverse=True):
                logger.info(f"    * {field}: {count} æ¬¡")
        else:
            logger.info(f"  âœ… æœªå‘ç°NaN/Infinityå€¼")
        
        logger.info("=" * 60)
        
        return problem_count > 0
        
    except Exception as e:
        logger.error(f"æ£€æŸ¥å¤±è´¥: {e}", exc_info=True)
        raise


async def test_akshare_data():
    """æµ‹è¯•akshareè¿”å›çš„åŸå§‹æ•°æ®æ˜¯å¦åŒ…å«NaN"""
    try:
        import akshare as ak
        import pandas as pd
        
        logger.info("=" * 60)
        logger.info("æµ‹è¯• akshare è¿”å›çš„åŸå§‹æ•°æ®...")
        
        # è·å–å°‘é‡æ•°æ®æµ‹è¯•
        df = ak.fund_info_index_em(symbol="å…¨éƒ¨", indicator="å…¨éƒ¨")
        
        logger.info(f"è·å–åˆ° {len(df)} æ¡è®°å½•")
        
        # æ£€æŸ¥æ¯åˆ—çš„NaN/Infinityæƒ…å†µ
        problem_cols = {}
        for col in df.columns:
            nan_count = df[col].isna().sum()
            inf_count = 0
            
            if df[col].dtype in ['float64', 'int64']:
                inf_count = ((df[col] == float('inf')) | (df[col] == float('-inf'))).sum()
            
            if nan_count > 0 or inf_count > 0:
                problem_cols[col] = {
                    'nan': nan_count,
                    'inf': inf_count
                }
        
        if problem_cols:
            logger.warning("âš ï¸ akshareè¿”å›çš„æ•°æ®åŒ…å«æ— æ•ˆå€¼:")
            for col, counts in problem_cols.items():
                logger.warning(f"  - {col}: NaN={counts['nan']}, Infinity={counts['inf']}")
        else:
            logger.info("âœ… akshareè¿”å›çš„æ•°æ®æ²¡æœ‰æ— æ•ˆå€¼")
        
        logger.info("=" * 60)
        
        return len(problem_cols) > 0
        
    except Exception as e:
        logger.error(f"æµ‹è¯•akshareæ•°æ®å¤±è´¥: {e}", exc_info=True)
        return False


async def main():
    """ä¸»å‡½æ•°"""
    try:
        await init_database()
        
        logger.info("=" * 60)
        logger.info("æ£€æŸ¥æ•°æ®åº“ä¸­çš„æ•°æ®")
        logger.info("=" * 60)
        
        has_db_problem = await check_collection()
        
        # æµ‹è¯•akshareåŸå§‹æ•°æ®
        has_akshare_problem = await test_akshare_data()
        
        logger.info("=" * 60)
        logger.info("æ£€æŸ¥å®Œæˆ")
        if has_db_problem:
            logger.warning("âš ï¸ æ•°æ®åº“ä¸­å­˜åœ¨æ— æ•ˆå€¼ï¼Œéœ€è¦è¿è¡Œä¿®å¤è„šæœ¬")
        else:
            logger.info("âœ… æ•°æ®åº“æ•°æ®æ­£å¸¸")
            
        if has_akshare_problem:
            logger.warning("âš ï¸ akshareè¿”å›çš„æ•°æ®åŒ…å«æ— æ•ˆå€¼ï¼Œè¿™æ˜¯æ•°æ®æºçš„é—®é¢˜")
            logger.info("ğŸ’¡ è§£å†³æ–¹æ¡ˆ: ä»£ç ä¸­å·²æ·»åŠ æ•°æ®æ¸…ç†é€»è¾‘ï¼Œé‡å¯æœåŠ¡å™¨åç”Ÿæ•ˆ")
        
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        sys.exit(1)
    finally:
        await close_database()


if __name__ == "__main__":
    asyncio.run(main())

from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta
from fastapi import APIRouter, Depends, Query, BackgroundTasks, HTTPException, status, UploadFile, File, Body
from fastapi.responses import JSONResponse, FileResponse
from starlette.background import BackgroundTask
from pydantic import BaseModel
import hashlib
import logging
import uuid
import asyncio
import tempfile
import os

from app.routers.auth_db import get_current_user
from tradingagents.dataflows.interface import (
    get_cn_bond_data_unified,
    get_cn_bond_info_unified,
    get_cn_bond_yield_curve_unified,
)
from tradingagents.dataflows.providers.china.bonds import AKShareBondProvider
from tradingagents.utils.instrument_validator import normalize_bond_code
from app.core.database import get_mongo_db
from app.services.bond_data_service import BondDataService
from app.services.bond_analysis_service import BondAnalysisService
from app.services.collection_refresh_service import CollectionRefreshService
from app.utils.task_manager import get_task_manager

router = APIRouter(prefix="/api/bonds", tags=["bonds"])
logger = logging.getLogger("webapi")  # ä½¿ç”¨ä¸å…¶ä»–è·¯ç”±ä¸€è‡´çš„æ—¥å¿—å™¨

# ç®€å•çš„å†…å­˜ç¼“å­˜ï¼Œç”¨äºå‡å°‘æ•°æ®åº“æŸ¥è¯¢
_bond_list_cache = {}
_cache_ttl_seconds = 300  # 5åˆ†é’Ÿç¼“å­˜

# æ•°æ®åˆå§‹åŒ–é”ï¼Œé˜²æ­¢å¹¶å‘è¯·æ±‚æ—¶é‡å¤ä»AKShareè·å–æ•°æ®
_init_lock = asyncio.Lock()
_init_in_progress = False
_init_completed = False
_init_timestamp = None  # åˆå§‹åŒ–å®Œæˆæ—¶é—´æˆ³
_init_timeout_seconds = 3600  # 1å°æ—¶åå…è®¸é‡æ–°åˆå§‹åŒ–

def _get_cache_key(q: Optional[str], category: Optional[str], exchange: Optional[str], 
                   only_not_matured: bool, page: int, page_size: int, 
                   sort_by: Optional[str], sort_dir: str) -> str:
    """ç”Ÿæˆç¼“å­˜é”®"""
    key_str = f"{q}_{category}_{exchange}_{only_not_matured}_{page}_{page_size}_{sort_by}_{sort_dir}"
    return hashlib.md5(key_str.encode()).hexdigest()

def _is_cache_valid(cache_entry: dict) -> bool:
    """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
    if not cache_entry:
        return False
    cache_time = cache_entry.get("timestamp")
    if not cache_time:
        return False
    age = (datetime.now() - cache_time).total_seconds()
    return age < _cache_ttl_seconds


def _is_init_expired() -> bool:
    """æ£€æŸ¥åˆå§‹åŒ–æ˜¯å¦å·²è¿‡æœŸï¼ˆè¶…æ—¶åå…è®¸é‡æ–°åˆå§‹åŒ–ï¼‰"""
    global _init_timestamp
    if _init_timestamp is None:
        return True  # ä»æœªåˆå§‹åŒ–
    age = (datetime.now() - _init_timestamp).total_seconds()
    return age >= _init_timeout_seconds


@router.get("/list")
async def list_bonds(
    q: Optional[str] = Query(None, description="å…³é”®è¯è¿‡æ»¤ï¼ŒæŒ‰ä»£ç æˆ–åç§°åŒ…å«åŒ¹é…"),
    limit: int = Query(100, ge=1, le=1000, description="æœ€å¤§è¿”å›é™åˆ¶ï¼ˆå…¼å®¹å‚æ•°ï¼Œåˆ†é¡µä¼˜å…ˆï¼‰"),
    category: Optional[str] = Query(None, description="å€ºåˆ¸ç±»åˆ«ï¼šconvertible|exchangeable|interest|credit|other"),
    exchange: Optional[str] = Query(None, description="äº¤æ˜“æ‰€ï¼šSH|SZ"),
    only_not_matured: bool = Query(False, description="ä»…æ˜¾ç¤ºæœªåˆ°æœŸï¼ˆä»…å¯¹åˆ©ç‡å€ºç”Ÿæ•ˆï¼‰"),
    page: int = Query(1, ge=1, description="é¡µç ï¼Œä»1å¼€å§‹"),
    page_size: int = Query(20, ge=1, le=200, description="æ¯é¡µæ•°é‡ï¼Œé»˜è®¤20"),
    sort_by: Optional[str] = Query(None, description="æ’åºå­—æ®µï¼šcode|name|maturity_date|list_date|coupon_rate"),
    sort_dir: str = Query("asc", description="æ’åºæ–¹å‘ï¼šasc/desc"),
    current_user: dict = Depends(get_current_user),
):
    try:
        logger.info(f"ğŸ” [å€ºåˆ¸åˆ—è¡¨] æ”¶åˆ°è¯·æ±‚: category={category}, page={page}, page_size={page_size}, q={q}, exchange={exchange}")
        db = get_mongo_db()
        if db is None:
            logger.error("âŒ [å€ºåˆ¸åˆ—è¡¨] MongoDBæ•°æ®åº“è¿æ¥ä¸ºNone")
            raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")
        
        # è§„èŒƒå‚æ•°ï¼šæ¯é¡µæœ€å¤š20æ¡ï¼›æ’åºæ–¹å‘ä»…å…è®¸ asc/desc
        try:
            page_size = max(1, min(int(page_size), 20))
        except Exception as pe:
            logger.warning(f"âš ï¸ [å€ºåˆ¸åˆ—è¡¨] å‚æ•°è§£æå¤±è´¥: {pe}")
            page_size = 20
        sdir = str(sort_dir or "asc").lower()
        if sdir not in ("asc", "desc"):
            sdir = "asc"
        sort_dir = sdir
        # å¦‚æœcategoryä¸ºç©ºæˆ–Noneï¼Œä¸è®¾ç½®é»˜è®¤å€¼ï¼ŒæŸ¥è¯¢æ‰€æœ‰ç±»åˆ«
        # æ³¨æ„ï¼šè¿™é‡Œä¸å†å¼ºåˆ¶è®¾ç½®é»˜è®¤å€¼ï¼Œè®©å‰ç«¯æ§åˆ¶é»˜è®¤æ˜¾ç¤º
        if category and category.strip() == "":
            category = None
        # æ£€æŸ¥ç¼“å­˜
        cache_key = _get_cache_key(q, category, exchange, only_not_matured, page, page_size, sort_by, sort_dir)
        cached_result = _bond_list_cache.get(cache_key)
        
        if _is_cache_valid(cached_result):
            logger.info(f"ğŸ“¦ [å€ºåˆ¸åˆ—è¡¨] ä»ç¼“å­˜è·å–æ•°æ® (category={category}, page={page})")
            return cached_result["data"]
        
        logger.info(f"ğŸ”§ [å€ºåˆ¸åˆ—è¡¨] åˆå§‹åŒ–BondDataService")
        svc = BondDataService(db)
        logger.info(f"ğŸ”§ [å€ºåˆ¸åˆ—è¡¨] ç¡®ä¿ç´¢å¼•å­˜åœ¨")
        try:
            await svc.ensure_indexes()
            logger.info(f"âœ… [å€ºåˆ¸åˆ—è¡¨] ç´¢å¼•æ£€æŸ¥å®Œæˆ")
        except Exception as idx_err:
            logger.error(f"âŒ [å€ºåˆ¸åˆ—è¡¨] ç´¢å¼•æ£€æŸ¥å¤±è´¥: {idx_err}", exc_info=True)
            # ç´¢å¼•å¤±è´¥ä¸åº”è¯¥é˜»æ­¢æŸ¥è¯¢ï¼Œç»§ç»­æ‰§è¡Œ

        # ä¼˜å…ˆä»æ•°æ®åº“æŸ¥è¯¢
        logger.info(f"ğŸ” [å€ºåˆ¸åˆ—è¡¨] å¼€å§‹ä»æ•°æ®åº“æŸ¥è¯¢æ•°æ® (category={category}, page={page}, page_size={page_size}, q={q}, exchange={exchange})")
        try:
            result = await svc.query_basic_list(q=q, category=category, exchange=exchange, only_not_matured=only_not_matured, page=page, page_size=page_size, sort_by=sort_by, sort_dir=sort_dir)
        except TypeError as te:
            # å…¼å®¹è€ç‰ˆæœ¬æœªæ”¯æŒæ’åºå‚æ•°çš„æ–¹æ³•ç­¾å
            logger.warning(f"âš ï¸ [å€ºåˆ¸åˆ—è¡¨] æ–¹æ³•ç­¾åä¸åŒ¹é…ï¼Œå°è¯•å…¼å®¹è°ƒç”¨: {te}")
            try:
                result = await svc.query_basic_list(q=q, category=category, exchange=exchange, only_not_matured=only_not_matured, page=page, page_size=page_size)  # type: ignore
            except TypeError:
                # å…¼å®¹æ›´è€ç‰ˆæœ¬æœªæ”¯æŒexchangeå‚æ•°çš„æ–¹æ³•ç­¾å
                result = await svc.query_basic_list(q=q, category=category, only_not_matured=only_not_matured, page=page, page_size=page_size)  # type: ignore
        except Exception as e:
            logger.error(f"âŒ [å€ºåˆ¸åˆ—è¡¨] æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
            result = {"total": 0, "items": []}

        total = int(result.get("total") or 0)
        items = list(result.get("items") or [])
        logger.info(f"ğŸ“Š [å€ºåˆ¸åˆ—è¡¨] æ•°æ®åº“æŸ¥è¯¢ç»“æœ: total={total}, items={len(items)}")

        # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®ï¼Œæ‰ä» AKShare è·å–å¹¶ä¿å­˜
        if total == 0:
            global _init_in_progress, _init_completed, _init_timestamp
            
            # æ£€æŸ¥åˆå§‹åŒ–æ˜¯å¦å·²å®Œæˆä¸”æœªè¿‡æœŸ
            if _init_completed and not _is_init_expired():
                logger.info(f"âœ… [å€ºåˆ¸åˆ—è¡¨] åˆå§‹åŒ–å·²å®Œæˆï¼Œä½†category={category}æ— æ•°æ®ï¼Œè¿”å›ç©ºç»“æœ")
            elif _init_completed and _is_init_expired():
                # åˆå§‹åŒ–å·²è¿‡æœŸï¼Œå…è®¸é‡æ–°åˆå§‹åŒ–
                logger.warning(f"âš ï¸ [å€ºåˆ¸åˆ—è¡¨] åˆå§‹åŒ–å·²è¿‡æœŸï¼ˆè¶…è¿‡{_init_timeout_seconds}ç§’ï¼‰ï¼Œå°†é‡æ–°åˆå§‹åŒ–")
                _init_completed = False
                _init_timestamp = None
            
            # å¦‚æœæœªåˆå§‹åŒ–æˆ–å·²è¿‡æœŸï¼Œæ‰§è¡Œåˆå§‹åŒ–
            if not _init_completed:
                # ä½¿ç”¨é”é˜²æ­¢å¹¶å‘åˆå§‹åŒ–
                async with _init_lock:
                    # åŒé‡æ£€æŸ¥ï¼šå…¶ä»–è¯·æ±‚å¯èƒ½å·²ç»å®Œæˆåˆå§‹åŒ–
                    if _init_completed:
                        logger.info(f"ğŸ”„ [å€ºåˆ¸åˆ—è¡¨] å…¶ä»–è¯·æ±‚å·²å®Œæˆåˆå§‹åŒ–ï¼Œé‡æ–°æŸ¥è¯¢æ•°æ®åº“")
                        try:
                            result = await svc.query_basic_list(q=q, category=category, exchange=exchange, only_not_matured=only_not_matured, page=page, page_size=page_size, sort_by=sort_by, sort_dir=sort_dir)
                        except TypeError:
                            try:
                                result = await svc.query_basic_list(q=q, category=category, exchange=exchange, only_not_matured=only_not_matured, page=page, page_size=page_size)  # type: ignore
                            except TypeError:
                                result = await svc.query_basic_list(q=q, category=category, only_not_matured=only_not_matured, page=page, page_size=page_size)  # type: ignore
                        total = int(result.get("total") or 0)
                        items = list(result.get("items") or [])
                    else:
                        # ç¬¬ä¸€ä¸ªè¯·æ±‚æ‰§è¡Œåˆå§‹åŒ–
                        logger.warning(f"âš ï¸ [å€ºåˆ¸åˆ—è¡¨] æ•°æ®åº“ä¸ºç©º (total=0)ï¼Œå¼€å§‹ä» AKShare è·å–æ•°æ® (category={category})")
                        _init_in_progress = True
                        
                        try:
                            provider = AKShareBondProvider()
                            fetched = await provider.get_symbol_list()
                            if fetched:
                                logger.info(f"ğŸ“¡ [å€ºåˆ¸åˆ—è¡¨] ä» AKShare è·å–åˆ° {len(fetched)} æ¡å€ºåˆ¸æ•°æ®ï¼Œæ­£åœ¨ä¿å­˜åˆ°æ•°æ®åº“...")
                                # è®°å½•å‰å‡ æ¡æ•°æ®çš„categoryå€¼
                                for i, item in enumerate(fetched[:3]):
                                    logger.info(f"ğŸ” [å€ºåˆ¸åˆ—è¡¨] AKShareæ•°æ®æ ·æœ¬ {i+1}: code={item.get('code')}, category={item.get('category')}, name={item.get('name')}")
                                
                                saved_count = await svc.save_basic_list(fetched)
                                logger.info(f"ğŸ’¾ [å€ºåˆ¸åˆ—è¡¨] å·²ä¿å­˜ {saved_count} æ¡å€ºåˆ¸æ•°æ®åˆ°æ•°æ®åº“")
                                
                                # éªŒè¯ï¼šå…ˆä¸å¸¦categoryæ¡ä»¶æŸ¥è¯¢ï¼Œçœ‹çœ‹æ•°æ®æ˜¯å¦å­˜åœ¨
                                try:
                                    test_result = await svc.query_basic_list(q=None, category=None, exchange=exchange, only_not_matured=False, page=1, page_size=5, sort_by=None, sort_dir="asc")
                                    logger.info(f"ğŸ” [å€ºåˆ¸åˆ—è¡¨] éªŒè¯æŸ¥è¯¢ï¼ˆæ— categoryè¿‡æ»¤ï¼‰: total={test_result.get('total', 0)}, items={len(test_result.get('items', []))}")
                                    if test_result.get('items'):
                                        sample = test_result['items'][0]
                                        logger.info(f"ğŸ” [å€ºåˆ¸åˆ—è¡¨] æ•°æ®åº“æ ·æœ¬æ•°æ®: code={sample.get('code')}, category={sample.get('category')}, name={sample.get('name')}")
                                except Exception as test_err:
                                    logger.error(f"âŒ [å€ºåˆ¸åˆ—è¡¨] éªŒè¯æŸ¥è¯¢å¤±è´¥: {test_err}")
                                
                                # æ ‡è®°åˆå§‹åŒ–å®Œæˆï¼Œè®°å½•æ—¶é—´æˆ³
                                _init_completed = True
                                _init_timestamp = datetime.now()
                                logger.info(f"âœ… [å€ºåˆ¸åˆ—è¡¨] æ•°æ®åˆå§‹åŒ–å®Œæˆï¼Œæ—¶é—´æˆ³: {_init_timestamp}")
                                
                                # é‡æ–°æŸ¥è¯¢æ•°æ®åº“
                                try:
                                    result = await svc.query_basic_list(q=q, category=category, exchange=exchange, only_not_matured=only_not_matured, page=page, page_size=page_size, sort_by=sort_by, sort_dir=sort_dir)
                                except TypeError:
                                    # å…¼å®¹è€ç‰ˆæœ¬æœªæ”¯æŒæ’åºå‚æ•°çš„æ–¹æ³•ç­¾å
                                    try:
                                        result = await svc.query_basic_list(q=q, category=category, exchange=exchange, only_not_matured=only_not_matured, page=page, page_size=page_size)  # type: ignore
                                    except TypeError:
                                        # å…¼å®¹æ›´è€ç‰ˆæœ¬æœªæ”¯æŒexchangeå‚æ•°çš„æ–¹æ³•ç­¾å
                                        result = await svc.query_basic_list(q=q, category=category, only_not_matured=only_not_matured, page=page, page_size=page_size)  # type: ignore
                                total = int(result.get("total") or 0)
                                items = list(result.get("items") or [])
                                logger.info(f"âœ… [å€ºåˆ¸åˆ—è¡¨] ä¿å­˜åé‡æ–°æŸ¥è¯¢æ•°æ®åº“: total={total}, items={len(items)}")
                            else:
                                logger.warning(f"âš ï¸ [å€ºåˆ¸åˆ—è¡¨] ä» AKShare è·å–æ•°æ®ä¸ºç©º")
                                _init_completed = True  # å³ä½¿ä¸ºç©ºä¹Ÿæ ‡è®°å®Œæˆï¼Œé¿å…é‡å¤å°è¯•
                                _init_timestamp = datetime.now()  # è®°å½•æ—¶é—´æˆ³ï¼Œè¶…æ—¶åå¯é‡è¯•
                        except Exception as e:
                            logger.error(f"âŒ [å€ºåˆ¸åˆ—è¡¨] ä» AKShare è·å–æ•°æ®å¤±è´¥: {e}", exc_info=True)
                            _init_completed = True  # å¤±è´¥ä¹Ÿæ ‡è®°å®Œæˆï¼Œé¿å…æ— é™é‡è¯•
                            _init_timestamp = datetime.now()  # è®°å½•æ—¶é—´æˆ³ï¼Œè¶…æ—¶åå¯é‡è¯•
                        finally:
                            _init_in_progress = False
        else:
            logger.info(f"âœ… [å€ºåˆ¸åˆ—è¡¨] ä»æ•°æ®åº“è·å– {total} æ¡å€ºåˆ¸æ•°æ® (category={category}, page={page}, items={len(items)})")

        # ç§»é™¤ _id å’Œ ObjectIdï¼Œé¿å…åºåˆ—åŒ–é—®é¢˜
        from bson import ObjectId
        from datetime import datetime as dt, date
        logger.info(f"ğŸ”§ [å€ºåˆ¸åˆ—è¡¨] å¼€å§‹å¤„ç† {len(items)} æ¡æ•°æ®çš„åºåˆ—åŒ–")
        for idx, it in enumerate(items):
            try:
                if isinstance(it, dict):
                    # ç§»é™¤ _id å­—æ®µ
                    if "_id" in it:
                        it.pop("_id", None)
                    # ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¯åºåˆ—åŒ–çš„
                    for key, value in list(it.items()):
                        if value is None:
                            continue
                        # å¤„ç† ObjectId
                        if isinstance(value, ObjectId):
                            it[key] = str(value)
                        # å¤„ç† datetime å’Œ date
                        elif isinstance(value, (dt, date)):
                            it[key] = value.isoformat()
                        # å¤„ç†å…¶ä»–ä¸å¯åºåˆ—åŒ–çš„ç±»å‹
                        elif not isinstance(value, (str, int, float, bool, list, dict)):
                            try:
                                it[key] = str(value)
                            except Exception:
                                it.pop(key, None)
                        # å¤„ç†åµŒå¥—å­—å…¸ä¸­çš„ ObjectId å’Œ datetime
                        elif isinstance(value, dict):
                            for k, v in list(value.items()):
                                if isinstance(v, ObjectId):
                                    value[k] = str(v)
                                elif isinstance(v, (dt, date)):
                                    value[k] = v.isoformat()
                        # å¤„ç†åˆ—è¡¨ä¸­çš„ ObjectId å’Œ datetime
                        elif isinstance(value, list):
                            for i, v in enumerate(value):
                                if isinstance(v, ObjectId):
                                    value[i] = str(v)
                                elif isinstance(v, (dt, date)):
                                    value[i] = v.isoformat()
                                elif isinstance(v, dict):
                                    for k, v2 in list(v.items()):
                                        if isinstance(v2, ObjectId):
                                            v[k] = str(v2)
                                        elif isinstance(v2, (dt, date)):
                                            v[k] = v2.isoformat()
            except Exception as ser_err:
                logger.error(f"âŒ [å€ºåˆ¸åˆ—è¡¨] åºåˆ—åŒ–ç¬¬ {idx} æ¡æ•°æ®å¤±è´¥: {ser_err}", exc_info=True)
                # å¦‚æœæŸæ¡æ•°æ®åºåˆ—åŒ–å¤±è´¥ï¼Œå°è¯•ç§»é™¤é—®é¢˜å­—æ®µæˆ–è·³è¿‡
                try:
                    # å°è¯•å°†æ‰€æœ‰å­—æ®µè½¬ä¸ºå­—ç¬¦ä¸²
                    for k, v in list(it.items()):
                        try:
                            if not isinstance(v, (str, int, float, bool, list, dict)):
                                it[k] = str(v)
                        except:
                            it.pop(k, None)
                except:
                    # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œä»åˆ—è¡¨ä¸­ç§»é™¤è¿™æ¡æ•°æ®
                    logger.warning(f"âš ï¸ [å€ºåˆ¸åˆ—è¡¨] ç§»é™¤æ— æ³•åºåˆ—åŒ–çš„æ•°æ®é¡¹ {idx}")
                    items[idx] = None
        # ç§»é™¤ None é¡¹
        items = [it for it in items if it is not None]
        logger.info(f"âœ… [å€ºåˆ¸åˆ—è¡¨] åºåˆ—åŒ–å®Œæˆï¼Œå‰©ä½™ {len(items)} æ¡æ•°æ®")

        # å…¼å®¹ limitï¼ˆè‹¥è°ƒç”¨æ–¹ä»ä¼ å…¥limitï¼Œåˆ™ä»ç„¶ç”Ÿæ•ˆäºå½“å‰é¡µä¸Šé™ï¼‰
        if limit and len(items) > limit:
            items = items[:limit]

        # æ„å»ºè¿”å›æ•°æ®
        logger.info(f"ğŸ”§ [å€ºåˆ¸åˆ—è¡¨] æ„å»ºå“åº”æ•°æ®: total={total}, items_count={len(items)}")
        try:
            response_data = {"success": True, "data": {"total": total, "page": page, "page_size": page_size, "items": items}}
            logger.info(f"âœ… [å€ºåˆ¸åˆ—è¡¨] å“åº”æ•°æ®æ„å»ºæˆåŠŸ")
        except Exception as build_err:
            logger.error(f"âŒ [å€ºåˆ¸åˆ—è¡¨] æ„å»ºå“åº”æ•°æ®å¤±è´¥: {build_err}", exc_info=True)
            raise
        
        # ç¼“å­˜ç»“æœï¼ˆåªç¼“å­˜æ•°æ®åº“ä¸­æœ‰æ•°æ®çš„æƒ…å†µï¼Œé¿å…ç¼“å­˜ç©ºç»“æœï¼‰
        if total > 0:
            try:
                _bond_list_cache[cache_key] = {
                    "data": response_data,
                    "timestamp": datetime.now()
                }
                # æ¸…ç†è¿‡æœŸç¼“å­˜ï¼ˆä¿æŒç¼“å­˜å¤§å°åˆç†ï¼‰
                if len(_bond_list_cache) > 1000:
                    now = datetime.now()
                    expired_keys = [k for k, v in _bond_list_cache.items() 
                                  if not _is_cache_valid(v)]
                    for k in expired_keys:
                        _bond_list_cache.pop(k, None)
            except Exception as cache_err:
                logger.warning(f"âš ï¸ [å€ºåˆ¸åˆ—è¡¨] ç¼“å­˜æ“ä½œå¤±è´¥: {cache_err}")

        logger.info(f"âœ… [å€ºåˆ¸åˆ—è¡¨] è¯·æ±‚å¤„ç†å®Œæˆï¼Œè¿”å›æ•°æ®")
        return response_data
    except HTTPException:
        # HTTPExceptionåº”è¯¥ç›´æ¥æŠ›å‡ºï¼Œä¸è¦æ•è·
        raise
    except Exception as e:
        logger.error(f"âŒ [å€ºåˆ¸åˆ—è¡¨] å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        import traceback
        error_trace = traceback.format_exc()
        logger.error(f"âŒ [å€ºåˆ¸åˆ—è¡¨] é”™è¯¯å †æ ˆ: {error_trace}")
        # ç¡®ä¿å˜é‡å·²å®šä¹‰
        try:
            page_val = page
        except:
            page_val = 1
        try:
            page_size_val = page_size
        except:
            page_size_val = 20
        # æŠ›å‡ºHTTPExceptionï¼Œè®©å…¨å±€å¼‚å¸¸å¤„ç†å™¨å¤„ç†
        raise HTTPException(
            status_code=500,
            detail=f"è·å–å€ºåˆ¸åˆ—è¡¨å¤±è´¥: {str(e)}"
        )


@router.get("/{code}/history")
async def get_bond_history(
    code: str,
    start: str = Query(..., description="å¼€å§‹æ—¥æœŸ YYYY-MM-DD"),
    end: str = Query(..., description="ç»“æŸæ—¥æœŸ YYYY-MM-DD"),
    period: str = Query("daily", description="å‘¨æœŸï¼Œé»˜è®¤ daily"),
    current_user: dict = Depends(get_current_user),
):
    db = get_mongo_db()
    svc = BondDataService(db)
    await svc.ensure_indexes()
    
    # ä¼˜å…ˆä»æ•°æ®åº“æŸ¥è¯¢å†å²æ•°æ®
    df = await svc.query_bond_daily(code, start, end)
    
    # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®æˆ–æ•°æ®ä¸å®Œæ•´ï¼Œä»æ¥å£è·å–å¹¶ä¿å­˜
    if df is None or df.empty:
        # ä»æ¥å£è·å–æ•°æ®
        result = get_cn_bond_data_unified(code, start, end, period)
        
        # å¦‚æœæ¥å£è¿”å›æˆåŠŸï¼Œå°è¯•ä¿å­˜åˆ°æ•°æ®åº“
        if not result.startswith("âŒ") and not result.startswith("âš ï¸"):
            try:
                # ä½¿ç”¨providerç›´æ¥è·å–DataFrameä»¥ä¾¿ä¿å­˜
                provider = AKShareBondProvider()
                norm = normalize_bond_code(code)
                code_std = norm.get("code_std") or code
                
                # è·å–å†å²æ•°æ®
                hist_df = await provider.get_historical_data(code_std, start, end, period)
                if hist_df is not None and not hist_df.empty:
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    await svc.save_bond_daily(code_std, hist_df)
            except Exception as e:
                # ä¿å­˜å¤±è´¥ä¸å½±å“è¿”å›æ•°æ®
                import logging
                logging.warning(f"ä¿å­˜å€ºåˆ¸å†å²æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {e}")
        
        return {"success": not result.startswith("âŒ"), "data": result}
    else:
        # æ•°æ®åº“ä¸­æœ‰æ•°æ®ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼è¿”å›ï¼ˆä¸æ¥å£æ ¼å¼ä¿æŒä¸€è‡´ï¼‰
        try:
            preview = df.to_string(index=False)
            title = f"## å€ºåˆ¸ {code} å†å²æ•°æ® ({start} åˆ° {end})"
            result = f"{title}\n" + preview
            return {"success": True, "data": result, "from_db": True}
        except Exception as e:
            # è½¬æ¢å¤±è´¥ï¼Œå›é€€åˆ°æ¥å£
            result = get_cn_bond_data_unified(code, start, end, period)
            return {"success": not result.startswith("âŒ"), "data": result}


@router.get("/{code}/analytics")
async def get_bond_analytics(
    code: str,
    start: str = Query(..., description="å¼€å§‹æ—¥æœŸ YYYY-MM-DD"),
    end: str = Query(..., description="ç»“æŸæ—¥æœŸ YYYY-MM-DD"),
    current_user: dict = Depends(get_current_user),
):
    # ç°é˜¶æ®µçš„åˆ†æç»“æœéšå†å²æ•°æ®å­—ç¬¦ä¸²ä¸€èµ·åŒ…å«ï¼ˆå«MA/MACD/RSI/BOLLç­‰ï¼‰ï¼Œå…ˆå¤ç”¨å†å²æ•°æ®æ¥å£
    # ä¼˜å…ˆä»æ•°æ®åº“æŸ¥è¯¢å†å²æ•°æ®
    db = get_mongo_db()
    svc = BondDataService(db)
    await svc.ensure_indexes()
    
    df = await svc.query_bond_daily(code, start, end)
    
    # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®æˆ–æ•°æ®ä¸å®Œæ•´ï¼Œä»æ¥å£è·å–å¹¶ä¿å­˜
    if df is None or df.empty:
        # ä»æ¥å£è·å–æ•°æ®
        result = get_cn_bond_data_unified(code, start, end, period="daily")
        
        # å¦‚æœæ¥å£è¿”å›æˆåŠŸï¼Œå°è¯•ä¿å­˜åˆ°æ•°æ®åº“
        if not result.startswith("âŒ") and not result.startswith("âš ï¸"):
            try:
                # ä½¿ç”¨providerç›´æ¥è·å–DataFrameä»¥ä¾¿ä¿å­˜
                provider = AKShareBondProvider()
                norm = normalize_bond_code(code)
                code_std = norm.get("code_std") or code
                
                # è·å–å†å²æ•°æ®
                hist_df = await provider.get_historical_data(code_std, start, end, period="daily")
                if hist_df is not None and not hist_df.empty:
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    await svc.save_bond_daily(code_std, hist_df)
            except Exception as e:
                # ä¿å­˜å¤±è´¥ä¸å½±å“è¿”å›æ•°æ®
                import logging
                logging.warning(f"ä¿å­˜å€ºåˆ¸å†å²æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {e}")
        
        return {"success": not result.startswith("âŒ"), "data": result}
    else:
        # æ•°æ®åº“ä¸­æœ‰æ•°æ®ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼è¿”å›ï¼ˆä¸æ¥å£æ ¼å¼ä¿æŒä¸€è‡´ï¼‰
        try:
            preview = df.to_string(index=False)
            title = f"## å€ºåˆ¸ {code} å†å²æ•°æ®ä¸åˆ†æ ({start} åˆ° {end})"
            result = f"{title}\n" + preview
            return {"success": True, "data": result, "from_db": True}
        except Exception as e:
            # è½¬æ¢å¤±è´¥ï¼Œå›é€€åˆ°æ¥å£
            result = get_cn_bond_data_unified(code, start, end, period="daily")
            return {"success": not result.startswith("âŒ"), "data": result}


@router.get("/{code}/info")
async def get_bond_info(
    code: str,
    current_user: dict = Depends(get_current_user),
):
    db = get_mongo_db()
    svc = BondDataService(db)
    await svc.ensure_indexes()
    
    # ä¼˜å…ˆä»æ•°æ®åº“æŸ¥è¯¢è¯¦æƒ…ä¿¡æ¯
    info = await svc.query_bond_info(code)
    
    # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼Œä»æ¥å£è·å–å¹¶ä¿å­˜
    if not info or (isinstance(info, dict) and info.get("error")):
        info = get_cn_bond_info_unified(code)
        
        # å¦‚æœæ¥å£è¿”å›çš„æ•°æ®æ ¼å¼ä¸å¯¹ï¼Œå°è¯•ä»åŸºç¡€åˆ—è¡¨è·å–
        if isinstance(info, dict) and info.get("error"):
            # ä»åŸºç¡€åˆ—è¡¨ä¸­æŸ¥æ‰¾
            try:
                result = await svc.query_basic_list(q=code, page=1, page_size=1)
                items = result.get("items", [])
                if items and len(items) > 0:
                    info = items[0]
                    info.pop("_id", None)
            except Exception:
                pass
        
        # å¤„ç†æ¥å£è¿”å›çš„æ ¼å¼ï¼ˆå¦‚æœæ˜¯åµŒå¥—çš„dataå­—æ®µï¼‰
        if isinstance(info, dict) and "data" in info and isinstance(info.get("data"), list) and len(info.get("data", [])) > 0:
            # å°†dataä¸­çš„ç¬¬ä¸€æ¡è®°å½•å±•å¼€
            data_records = info.get("data", [])
            if data_records:
                # ä¿ç•™codeå’Œsourceç­‰å­—æ®µï¼Œåˆå¹¶dataä¸­çš„å­—æ®µ
                code_value = info.get("code", code)
                source_value = info.get("source", "akshare")
                data_item = data_records[0]
                info = {"code": code_value, "source": source_value}
                info.update(data_item)
        
        # å¦‚æœæˆåŠŸè·å–åˆ°æ•°æ®ä¸”æ²¡æœ‰é”™è¯¯ï¼Œä¿å­˜åˆ°æ•°æ®åº“
        if isinstance(info, dict) and not info.get("error"):
            try:
                await svc.save_bond_info_from_api(code, info)
            except Exception as e:
                # ä¿å­˜å¤±è´¥ä¸å½±å“è¿”å›æ•°æ®
                import logging
                logging.warning(f"ä¿å­˜å€ºåˆ¸è¯¦æƒ…åˆ°æ•°æ®åº“å¤±è´¥: {e}")
    
    ok = isinstance(info, dict) and not info.get("error")
    return {"success": ok, "data": info}


@router.get("/yield-curve")
async def get_bond_yield_curve(
    start: Optional[str] = Query(None, description="å¼€å§‹æ—¥æœŸ YYYY-MM-DDï¼Œå¯é€‰"),
    end: Optional[str] = Query(None, description="ç»“æŸæ—¥æœŸ YYYY-MM-DDï¼Œå¯é€‰"),
    curve_name: Optional[str] = Query(None, description="æ›²çº¿åç§°ï¼Œå¯é€‰"),
    format: str = Query("json", description="è¿”å›æ ¼å¼ï¼šjson|text"),
    current_user: dict = Depends(get_current_user),
):
    """è·å–æ”¶ç›Šç‡æ›²çº¿æ•°æ®ï¼Œæ”¯æŒJSONå’Œæ–‡æœ¬ä¸¤ç§æ ¼å¼"""
    db = get_mongo_db()
    svc = BondDataService(db)
    await svc.ensure_indexes()
    
    # ä¼˜å…ˆä»æ•°æ®åº“æŸ¥è¯¢æ”¶ç›Šç‡æ›²çº¿æ•°æ®
    df = await svc.query_yield_curve(start, end, curve_name)
    
    # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®æˆ–æ•°æ®ä¸å®Œæ•´ï¼Œä»æ¥å£è·å–å¹¶ä¿å­˜
    if df is None or df.empty:
        # ä»æ¥å£è·å–æ•°æ®
        result = get_cn_bond_yield_curve_unified(start, end)
        
        # å¦‚æœæ¥å£è¿”å›æˆåŠŸï¼Œå°è¯•ä¿å­˜åˆ°æ•°æ®åº“
        if not result.startswith("âŒ") and not result.startswith("âš ï¸"):
            try:
                # ä½¿ç”¨providerç›´æ¥è·å–DataFrameä»¥ä¾¿ä¿å­˜
                provider = AKShareBondProvider()
                yield_df = await provider.get_yield_curve(start_date=start, end_date=end)
                if yield_df is not None and not yield_df.empty:
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    await svc.save_yield_curve(yield_df)
                    # é‡æ–°æŸ¥è¯¢æ•°æ®åº“
                    df = await svc.query_yield_curve(start, end, curve_name)
            except Exception as e:
                # ä¿å­˜å¤±è´¥ä¸å½±å“è¿”å›æ•°æ®
                import logging
                logging.warning(f"ä¿å­˜æ”¶ç›Šç‡æ›²çº¿æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {e}")
        
        # å¦‚æœä»ç„¶æ²¡æœ‰æ•°æ®ï¼Œè¿”å›æ–‡æœ¬æ ¼å¼
        if format == "text":
            return {"success": not result.startswith("âŒ"), "data": result}
        else:
            return {"success": False, "data": [], "message": "æ— æ•°æ®"}
    else:
        # æ•°æ®åº“ä¸­æœ‰æ•°æ®
        if format == "text":
            # æ–‡æœ¬æ ¼å¼ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
            try:
                preview = df.to_string(index=False)
                rng = f"{start or '-âˆ'} åˆ° {end or '+âˆ'}"
                title = f"## ä¸­å›½å€ºåˆ¸æ”¶ç›Šç‡æ›²çº¿ ({rng})"
                result = f"{title}\n" + preview
                return {"success": True, "data": result, "from_db": True}
            except Exception as e:
                # è½¬æ¢å¤±è´¥ï¼Œå›é€€åˆ°æ¥å£
                result = get_cn_bond_yield_curve_unified(start, end)
                return {"success": not result.startswith("âŒ"), "data": result}
        else:
            # JSONæ ¼å¼ï¼ˆæ–°æ ¼å¼ï¼Œç”¨äºå‰ç«¯å›¾è¡¨ï¼‰
            try:
                # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                records = df.to_dict(orient="records")
                
                # è·å–ç»Ÿè®¡ä¿¡æ¯
                curve_names = df["curve_name"].unique().tolist() if "curve_name" in df.columns else []
                tenors = sorted(df["tenor"].unique().tolist()) if "tenor" in df.columns else []
                dates = sorted(df["date"].unique().tolist()) if "date" in df.columns else []
                
                # æŒ‰æ—¥æœŸå’ŒæœŸé™ç»„ç»‡æ•°æ®ï¼Œä¾¿äºå›¾è¡¨å±•ç¤º
                chart_data = {}
                for record in records:
                    date = record.get("date")
                    tenor = record.get("tenor")
                    curve = record.get("curve_name") or "default"
                    yield_val = record.get("yield")
                    
                    if date not in chart_data:
                        chart_data[date] = {}
                    if curve not in chart_data[date]:
                        chart_data[date][curve] = {}
                    chart_data[date][curve][tenor] = yield_val
                
                return {
                    "success": True,
                    "data": {
                        "records": records,
                        "chart_data": chart_data,
                        "statistics": {
                            "total_records": len(records),
                            "curve_names": curve_names,
                            "tenors": tenors,
                            "date_range": {
                                "start": dates[0] if dates else None,
                                "end": dates[-1] if dates else None,
                                "count": len(dates)
                            }
                        }
                    },
                    "from_db": True
                }
            except Exception as e:
                logger.error(f"è½¬æ¢æ”¶ç›Šç‡æ›²çº¿æ•°æ®å¤±è´¥: {e}", exc_info=True)
                return {"success": False, "error": str(e)}


@router.post("/yield-curve/sync")
async def sync_bond_yield_curve(
    start: Optional[str] = Query(None, description="å¼€å§‹æ—¥æœŸ YYYY-MM-DDï¼Œå¯é€‰"),
    end: Optional[str] = Query(None, description="ç»“æŸæ—¥æœŸ YYYY-MM-DDï¼Œå¯é€‰"),
    current_user: dict = Depends(get_current_user),
):
    provider = AKShareBondProvider()
    df = await provider.get_yield_curve(start, end)
    db = get_mongo_db()
    svc = BondDataService(db)
    await svc.ensure_indexes()
    saved = await svc.save_yield_curve(df)
    return {"success": True, "data": {"saved": saved, "rows": 0 if df is None else len(df)}}


@router.get("/collections")
async def list_bond_collections(
    current_user: dict = Depends(get_current_user),
):
    """è·å–æ‰€æœ‰å€ºåˆ¸ç›¸å…³æ•°æ®é›†åˆåˆ—è¡¨åŠå…¶è¯´æ˜"""
    collections = [
        # 01 åŸºç¡€æ•°æ®
        {
            "name": "bond_info_cm",
            "display_name": "å€ºåˆ¸ä¿¡æ¯æŸ¥è¯¢",
            "description": "ä¸­å›½å¤–æ±‡äº¤æ˜“ä¸­å¿ƒå€ºåˆ¸ä¿¡æ¯æŸ¥è¯¢ï¼Œæ”¯æŒæŒ‰å€ºåˆ¸åç§°ã€ä»£ç ã€å‘è¡Œäººã€å€ºåˆ¸ç±»å‹ã€ä»˜æ¯æ–¹å¼ã€å‘è¡Œå¹´ä»½ã€æ‰¿é”€å•†ã€è¯„çº§ç­‰æ¡ä»¶æŸ¥è¯¢",
            "route": "/bonds/collections/bond_info_cm",
            "source": "ä¸­å›½å¤–æ±‡äº¤æ˜“ä¸­å¿ƒ",
            "priority": "â­â­â­â­â­",
            "category": "åŸºç¡€æ•°æ®",
        },
        # 02
        {
            "name": "bond_info_detail_cm",
            "display_name": "å€ºåˆ¸åŸºç¡€ä¿¡æ¯",
            "description": "å€ºåˆ¸è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬å‘è¡Œæ¡æ¬¾ã€è¯„çº§ç­‰è¯¦ç»†æ•°æ®",
            "route": "/bonds/collections/bond_info_detail_cm",
            "source": "ä¸­å›½å¤–æ±‡äº¤æ˜“ä¸­å¿ƒ",
            "priority": "â­â­â­â­â­",
            "category": "åŸºç¡€æ•°æ®",
        },
        # 03 æ²ªæ·±å€ºåˆ¸è¡Œæƒ…
        {
            "name": "bond_zh_hs_spot",
            "display_name": "æ²ªæ·±å€ºåˆ¸å®æ—¶è¡Œæƒ…",
            "description": "æ²ªæ·±å€ºåˆ¸å®æ—¶è¡Œæƒ…æ•°æ®ï¼ŒåŒ…æ‹¬æœ€æ–°ä»·ã€æ¶¨è·Œå¹…ã€æˆäº¤é‡ç­‰",
            "route": "/bonds/collections/bond_zh_hs_spot",
            "source": "æ–°æµªè´¢ç»",
            "priority": "â­â­â­â­",
            "category": "æ²ªæ·±å€ºåˆ¸è¡Œæƒ…",
        },
        # 04
        {
            "name": "bond_zh_hs_daily",
            "display_name": "æ²ªæ·±å€ºåˆ¸å†å²è¡Œæƒ…",
            "description": "æ²ªæ·±å€ºåˆ¸å†å²è¡Œæƒ…æ•°æ®ï¼ˆæ—¥çº¿ï¼‰ï¼Œæ”¯æŒæŒ‰æ—¥æœŸæŸ¥è¯¢",
            "route": "/bonds/collections/bond_zh_hs_daily",
            "source": "æ–°æµªè´¢ç»",
            "priority": "â­â­â­â­",
            "category": "æ²ªæ·±å€ºåˆ¸è¡Œæƒ…",
        },
        # 05 å¯è½¬å€ºè¡Œæƒ…æ•°æ®
        {
            "name": "bond_zh_hs_cov_spot",
            "display_name": "å¯è½¬å€ºå®æ—¶è¡Œæƒ…",
            "description": "æ²ªæ·±å¯è½¬å€ºå®æ—¶è¡Œæƒ…æ•°æ®",
            "route": "/bonds/collections/bond_zh_hs_cov_spot",
            "source": "æ–°æµªè´¢ç»",
            "priority": "â­â­â­â­â­",
            "category": "å¯è½¬å€ºè¡Œæƒ…",
        },
        # 06
        {
            "name": "bond_zh_hs_cov_daily",
            "display_name": "å¯è½¬å€ºå†å²è¡Œæƒ…",
            "description": "æ²ªæ·±å¯è½¬å€ºå†å²è¡Œæƒ…æ•°æ®ï¼ˆæ—¥çº¿ï¼‰",
            "route": "/bonds/collections/bond_zh_hs_cov_daily",
            "source": "æ–°æµªè´¢ç»",
            "priority": "â­â­â­â­",
            "category": "å¯è½¬å€ºè¡Œæƒ…",
        },
        # 07
        {
            "name": "bond_zh_cov",
            "display_name": "å¯è½¬å€ºæ•°æ®ä¸€è§ˆè¡¨",
            "description": "å¯è½¬å€ºç»¼åˆæ•°æ®ï¼ŒåŒ…æ‹¬ç”³è´­ã€è½¬è‚¡ä»·ã€æº¢ä»·ç‡ç­‰",
            "route": "/bonds/collections/bond_zh_cov",
            "source": "ä¸œæ–¹è´¢å¯Œç½‘",
            "priority": "â­â­â­â­â­",
            "category": "å¯è½¬å€ºè¡Œæƒ…",
        },
        # 08 å¸‚åœºæ¦‚è§ˆæ•°æ®
        {
            "name": "bond_cash_summary_sse",
            "display_name": "å€ºåˆ¸ç°åˆ¸å¸‚åœºæ¦‚è§ˆ",
            "description": "ä¸Šäº¤æ‰€å€ºåˆ¸ç°åˆ¸å¸‚åœºæ‰˜ç®¡æ¦‚è§ˆ",
            "route": "/bonds/collections/bond_cash_summary_sse",
            "source": "ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€",
            "priority": "â­â­â­",
            "category": "å¸‚åœºæ¦‚è§ˆ",
        },
        # 09
        {
            "name": "bond_deal_summary_sse",
            "display_name": "å€ºåˆ¸æˆäº¤æ¦‚è§ˆ",
            "description": "ä¸Šäº¤æ‰€å€ºåˆ¸æˆäº¤æ¦‚è§ˆ",
            "route": "/bonds/collections/bond_deal_summary_sse",
            "source": "ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€",
            "priority": "â­â­â­",
            "category": "å¸‚åœºæ¦‚è§ˆ",
        },
        # 10 é“¶è¡Œé—´å¸‚åœº
        {
            "name": "bond_debt_nafmii",
            "display_name": "é“¶è¡Œé—´å¸‚åœºå€ºåˆ¸å‘è¡Œ",
            "description": "é“¶è¡Œé—´å¸‚åœºå€ºåˆ¸å‘è¡ŒåŸºç¡€æ•°æ®",
            "route": "/bonds/collections/bond_debt_nafmii",
            "source": "ä¸­å›½é“¶è¡Œé—´å¸‚åœºäº¤æ˜“å•†åä¼š",
            "priority": "â­â­â­",
            "category": "é“¶è¡Œé—´å¸‚åœº",
        },
        # 11
        {
            "name": "bond_spot_quote",
            "display_name": "ç°åˆ¸å¸‚åœºåšå¸‚æŠ¥ä»·",
            "description": "é“¶è¡Œé—´ç°åˆ¸å¸‚åœºåšå¸‚æŠ¥ä»·",
            "route": "/bonds/collections/bond_spot_quote",
            "source": "ä¸­å›½å¤–æ±‡äº¤æ˜“ä¸­å¿ƒ",
            "priority": "â­â­â­",
            "category": "é“¶è¡Œé—´å¸‚åœº",
        },
        # 12
        {
            "name": "bond_spot_deal",
            "display_name": "ç°åˆ¸å¸‚åœºæˆäº¤è¡Œæƒ…",
            "description": "é“¶è¡Œé—´ç°åˆ¸å¸‚åœºæˆäº¤è¡Œæƒ…",
            "route": "/bonds/collections/bond_spot_deal",
            "source": "ä¸­å›½å¤–æ±‡äº¤æ˜“ä¸­å¿ƒ",
            "priority": "â­â­â­",
            "category": "é“¶è¡Œé—´å¸‚åœº",
        },
        # 13 å¯è½¬å€ºåˆ†æ—¶
        {
            "name": "bond_zh_hs_cov_min",
            "display_name": "å¯è½¬å€ºåˆ†æ—¶è¡Œæƒ…",
            "description": "å¯è½¬å€ºåˆ†æ—¶è¡Œæƒ…æ•°æ®ï¼Œæ”¯æŒå¤šå‘¨æœŸ",
            "route": "/bonds/collections/bond_zh_hs_cov_min",
            "source": "ä¸œæ–¹è´¢å¯Œç½‘",
            "priority": "â­â­â­",
            "category": "å¯è½¬å€ºè¡Œæƒ…",
        },
        # 14
        {
            "name": "bond_zh_hs_cov_pre_min",
            "display_name": "å¯è½¬å€ºç›˜å‰åˆ†æ—¶",
            "description": "å¯è½¬å€ºç›˜å‰åˆ†æ—¶æ•°æ®",
            "route": "/bonds/collections/bond_zh_hs_cov_pre_min",
            "source": "ä¸œæ–¹è´¢å¯Œç½‘",
            "priority": "â­â­",
            "category": "å¯è½¬å€ºè¡Œæƒ…",
        },
        # 15 å¯è½¬å€ºè¯¦ç»†æ•°æ®
        {
            "name": "bond_zh_cov_info",
            "display_name": "å¯è½¬å€ºè¯¦æƒ…-ä¸œè´¢",
            "description": "å¯è½¬å€ºè¯¦æƒ…ï¼ˆåŸºæœ¬ä¿¡æ¯ã€ä¸­ç­¾å·ã€ç­¹èµ„ç”¨é€”ã€é‡è¦æ—¥æœŸï¼‰",
            "route": "/bonds/collections/bond_zh_cov_info",
            "source": "ä¸œæ–¹è´¢å¯Œç½‘",
            "priority": "â­â­â­â­",
            "category": "å¯è½¬å€ºè¯¦ç»†",
        },
        # 16
        {
            "name": "bond_zh_cov_info_ths",
            "display_name": "å¯è½¬å€ºè¯¦æƒ…-åŒèŠ±é¡º",
            "description": "å¯è½¬å€ºè¯¦æƒ…ï¼ˆåŒèŠ±é¡ºæ•°æ®æºï¼‰",
            "route": "/bonds/collections/bond_zh_cov_info_ths",
            "source": "åŒèŠ±é¡º",
            "priority": "â­â­â­",
            "category": "å¯è½¬å€ºè¯¦ç»†",
        },
        # 17
        {
            "name": "bond_cov_comparison",
            "display_name": "å¯è½¬å€ºæ¯”ä»·è¡¨",
            "description": "å¯è½¬å€ºä¸æ­£è‚¡æ¯”ä»·æ•°æ®",
            "route": "/bonds/collections/bond_cov_comparison",
            "source": "ä¸œæ–¹è´¢å¯Œç½‘",
            "priority": "â­â­â­â­â­",
            "category": "å¯è½¬å€ºè¯¦ç»†",
        },
        # 18
        {
            "name": "bond_zh_cov_value_analysis",
            "display_name": "å¯è½¬å€ºä»·å€¼åˆ†æ",
            "description": "å¯è½¬å€ºä»·å€¼åˆ†æï¼ˆçº¯å€ºä»·å€¼ã€è½¬è‚¡ä»·å€¼ã€æº¢ä»·ç‡ï¼‰",
            "route": "/bonds/collections/bond_zh_cov_value_analysis",
            "source": "ä¸œæ–¹è´¢å¯Œç½‘",
            "priority": "â­â­â­â­â­",
            "category": "å¯è½¬å€ºè¯¦ç»†",
        },
        # 19 è´¨æŠ¼å¼å›è´­
        {
            "name": "bond_sh_buy_back_em",
            "display_name": "ä¸Šè¯è´¨æŠ¼å¼å›è´­",
            "description": "ä¸Šè¯è´¨æŠ¼å¼å›è´­å®æ—¶è¡Œæƒ…",
            "route": "/bonds/collections/bond_sh_buy_back_em",
            "source": "ä¸œæ–¹è´¢å¯Œç½‘",
            "priority": "â­â­â­",
            "category": "è´¨æŠ¼å¼å›è´­",
        },
        # 20
        {
            "name": "bond_sz_buy_back_em",
            "display_name": "æ·±è¯è´¨æŠ¼å¼å›è´­",
            "description": "æ·±è¯è´¨æŠ¼å¼å›è´­å®æ—¶è¡Œæƒ…",
            "route": "/bonds/collections/bond_sz_buy_back_em",
            "source": "ä¸œæ–¹è´¢å¯Œç½‘",
            "priority": "â­â­â­",
            "category": "è´¨æŠ¼å¼å›è´­",
        },
        # 21
        {
            "name": "bond_buy_back_hist_em",
            "display_name": "è´¨æŠ¼å¼å›è´­å†å²æ•°æ®",
            "description": "è´¨æŠ¼å¼å›è´­å†å²è¡Œæƒ…",
            "route": "/bonds/collections/bond_buy_back_hist_em",
            "source": "ä¸œæ–¹è´¢å¯Œç½‘",
            "priority": "â­â­â­",
            "category": "è´¨æŠ¼å¼å›è´­",
        },
        # 22 é›†æ€å½•æ•°æ®
        {
            "name": "bond_cb_jsl",
            "display_name": "å¯è½¬å€ºå®æ—¶æ•°æ®-é›†æ€å½•",
            "description": "é›†æ€å½•å¯è½¬å€ºå®æ—¶æ•°æ®ï¼ˆéœ€è¦Cookieï¼‰",
            "route": "/bonds/collections/bond_cb_jsl",
            "source": "é›†æ€å½•",
            "priority": "â­â­â­â­â­",
            "category": "é›†æ€å½•æ•°æ®",
        },
        # 23
        {
            "name": "bond_cb_redeem_jsl",
            "display_name": "å¯è½¬å€ºå¼ºèµ-é›†æ€å½•",
            "description": "å¯è½¬å€ºå¼ºèµä¿¡æ¯",
            "route": "/bonds/collections/bond_cb_redeem_jsl",
            "source": "é›†æ€å½•",
            "priority": "â­â­â­â­",
            "category": "é›†æ€å½•æ•°æ®",
        },
        # 24
        {
            "name": "bond_cb_index_jsl",
            "display_name": "å¯è½¬å€ºç­‰æƒæŒ‡æ•°-é›†æ€å½•",
            "description": "é›†æ€å½•å¯è½¬å€ºç­‰æƒæŒ‡æ•°",
            "route": "/bonds/collections/bond_cb_index_jsl",
            "source": "é›†æ€å½•",
            "priority": "â­â­â­",
            "category": "é›†æ€å½•æ•°æ®",
        },
        # 25
        {
            "name": "bond_cb_adj_logs_jsl",
            "display_name": "è½¬è‚¡ä»·è°ƒæ•´è®°å½•-é›†æ€å½•",
            "description": "å¯è½¬å€ºè½¬è‚¡ä»·è°ƒæ•´è®°å½•",
            "route": "/bonds/collections/bond_cb_adj_logs_jsl",
            "source": "é›†æ€å½•",
            "priority": "â­â­â­",
            "category": "é›†æ€å½•æ•°æ®",
        },
        # 26 æ”¶ç›Šç‡æ›²çº¿
        {
            "name": "bond_china_close_return",
            "display_name": "æ”¶ç›Šç‡æ›²çº¿å†å²æ•°æ®",
            "description": "ä¸­å›½å€ºåˆ¸æ”¶ç›Šç‡æ›²çº¿å†å²æ•°æ®",
            "route": "/bonds/collections/bond_china_close_return",
            "source": "ä¸­å›½å¤–æ±‡äº¤æ˜“ä¸­å¿ƒ",
            "priority": "â­â­â­",
            "category": "æ”¶ç›Šç‡æ›²çº¿",
        },
        # 27
        {
            "name": "bond_zh_us_rate",
            "display_name": "ä¸­ç¾å›½å€ºæ”¶ç›Šç‡",
            "description": "ä¸­ç¾å›½å€ºæ”¶ç›Šç‡å¯¹æ¯”æ•°æ®",
            "route": "/bonds/collections/bond_zh_us_rate",
            "source": "ä¸œæ–¹è´¢å¯Œç½‘",
            "priority": "â­â­â­",
            "category": "æ”¶ç›Šç‡æ›²çº¿",
        },
        # 28 å€ºåˆ¸å‘è¡Œæ•°æ®
        {
            "name": "bond_treasure_issue_cninfo",
            "display_name": "å›½å€ºå‘è¡Œ",
            "description": "å›½å€ºå‘è¡Œä¿¡æ¯",
            "route": "/bonds/collections/bond_treasure_issue_cninfo",
            "source": "å·¨æ½®èµ„è®¯",
            "priority": "â­â­",
            "category": "å€ºåˆ¸å‘è¡Œ",
        },
        # 29
        {
            "name": "bond_local_government_issue_cninfo",
            "display_name": "åœ°æ–¹å€ºå‘è¡Œ",
            "description": "åœ°æ–¹å€ºå‘è¡Œä¿¡æ¯",
            "route": "/bonds/collections/bond_local_government_issue_cninfo",
            "source": "å·¨æ½®èµ„è®¯",
            "priority": "â­â­",
            "category": "å€ºåˆ¸å‘è¡Œ",
        },
        # 30
        {
            "name": "bond_corporate_issue_cninfo",
            "display_name": "ä¼ä¸šå€ºå‘è¡Œ",
            "description": "ä¼ä¸šå€ºå‘è¡Œä¿¡æ¯",
            "route": "/bonds/collections/bond_corporate_issue_cninfo",
            "source": "å·¨æ½®èµ„è®¯",
            "priority": "â­â­",
            "category": "å€ºåˆ¸å‘è¡Œ",
        },
        # 31
        {
            "name": "bond_cov_issue_cninfo",
            "display_name": "å¯è½¬å€ºå‘è¡Œ",
            "description": "å¯è½¬å€ºå‘è¡Œä¿¡æ¯",
            "route": "/bonds/collections/bond_cov_issue_cninfo",
            "source": "å·¨æ½®èµ„è®¯",
            "priority": "â­â­â­",
            "category": "å€ºåˆ¸å‘è¡Œ",
        },
        # 32
        {
            "name": "bond_cov_stock_issue_cninfo",
            "display_name": "å¯è½¬å€ºè½¬è‚¡",
            "description": "å¯è½¬å€ºè½¬è‚¡ä¿¡æ¯",
            "route": "/bonds/collections/bond_cov_stock_issue_cninfo",
            "source": "å·¨æ½®èµ„è®¯",
            "priority": "â­â­â­",
            "category": "å€ºåˆ¸å‘è¡Œ",
        },
        # 33 ä¸­å€ºæŒ‡æ•°
        {
            "name": "bond_new_composite_index_cbond",
            "display_name": "ä¸­å€ºæ–°ç»¼åˆæŒ‡æ•°",
            "description": "ä¸­å€ºæ–°ç»¼åˆæŒ‡æ•°",
            "route": "/bonds/collections/bond_new_composite_index_cbond",
            "source": "ä¸­å›½å€ºåˆ¸ä¿¡æ¯ç½‘",
            "priority": "â­â­",
            "category": "ä¸­å€ºæŒ‡æ•°",
        },
        # 34
        {
            "name": "bond_composite_index_cbond",
            "display_name": "ä¸­å€ºç»¼åˆæŒ‡æ•°",
            "description": "ä¸­å€ºç»¼åˆæŒ‡æ•°",
            "route": "/bonds/collections/bond_composite_index_cbond",
            "source": "ä¸­å›½å€ºåˆ¸ä¿¡æ¯ç½‘",
            "priority": "â­â­",
            "category": "ä¸­å€ºæŒ‡æ•°",
        },
    ]
    return {"success": True, "data": collections}


@router.get("/collections/{collection_name}/update-config")
async def get_collection_update_config(
    collection_name: str,
    current_user: dict = Depends(get_current_user),
):
    """è·å–æŒ‡å®šé›†åˆçš„æ›´æ–°é…ç½®ä¿¡æ¯
    
    è¿”å›è¯¥é›†åˆæ”¯æŒçš„å•æ¡æ›´æ–°å’Œæ‰¹é‡æ›´æ–°å‚æ•°é…ç½®
    """
    from app.config.bond_update_config import get_collection_update_config as get_config
    config = get_config(collection_name)
    return {"success": True, "data": config}


@router.get("/collections/{collection_name}")
async def get_collection_data(
    collection_name: str,
    page: int = Query(1, ge=1, description="é¡µç ï¼Œä»1å¼€å§‹"),
    page_size: int = Query(50, ge=1, le=500, description="æ¯é¡µæ•°é‡ï¼Œé»˜è®¤50"),
    sort_by: Optional[str] = Query(None, description="æ’åºå­—æ®µ"),
    sort_dir: str = Query("desc", description="æ’åºæ–¹å‘ï¼šasc|desc"),
    filter_field: Optional[str] = Query(None, description="è¿‡æ»¤å­—æ®µ"),
    filter_value: Optional[str] = Query(None, description="è¿‡æ»¤å€¼"),
    current_user: dict = Depends(get_current_user),
):
    """è·å–æŒ‡å®šé›†åˆçš„æ•°æ®ï¼ˆåˆ†é¡µï¼‰"""
    db = get_mongo_db()
    svc = BondDataService(db)
    
    # æ˜ å°„æ‰€æœ‰34ä¸ªå€ºåˆ¸æ•°æ®é›†åˆåˆ°å¯¹åº”çš„MongoDBé›†åˆ
    collection_map = {
        # 01-02 åŸºç¡€æ•°æ®
        "bond_info_cm": svc.col_info_cm,
        "bond_info_detail_cm": svc.col_basic,
        # 03-04 æ²ªæ·±å€ºåˆ¸è¡Œæƒ…
        "bond_zh_hs_spot": svc.col_zh_hs_spot,
        "bond_zh_hs_daily": svc.col_zh_hs_daily,
        # 05-07 å¯è½¬å€ºè¡Œæƒ…
        "bond_zh_hs_cov_spot": svc.col_zh_hs_cov_spot,
        "bond_zh_hs_cov_daily": svc.col_zh_hs_cov_daily,
        "bond_zh_cov": svc.col_zh_cov,
        # 08-09 å¸‚åœºæ¦‚è§ˆ
        "bond_cash_summary_sse": svc.col_cash_summary_sse,
        "bond_deal_summary_sse": svc.col_deal_summary_sse,
        # 10-12 é“¶è¡Œé—´å¸‚åœº
        "bond_debt_nafmii": svc.col_debt_nafmii,
        "bond_spot_quote": svc.col_spot_quote,
        "bond_spot_deal": svc.col_spot_deal,
        # 13-14 å¯è½¬å€ºåˆ†æ—¶
        "bond_zh_hs_cov_min": svc.col_zh_hs_cov_min,
        "bond_zh_hs_cov_pre_min": svc.col_zh_hs_cov_pre_min,
        # 15-18 å¯è½¬å€ºè¯¦ç»†
        "bond_zh_cov_info": svc.col_zh_cov_info,
        "bond_zh_cov_info_ths": svc.col_zh_cov_info_ths,
        "bond_cov_comparison": svc.col_cov_comparison,
        "bond_zh_cov_value_analysis": svc.col_zh_cov_value_analysis,
        # 19-21 è´¨æŠ¼å¼å›è´­
        "bond_sh_buy_back_em": svc.col_sh_buy_back,
        "bond_sz_buy_back_em": svc.col_sz_buy_back,
        "bond_buy_back_hist_em": svc.col_buybacks_hist,
        # 22-25 é›†æ€å½•æ•°æ®
        "bond_cb_jsl": svc.col_cov_jsl,
        "bond_cb_redeem_jsl": svc.col_cov_redeem_jsl,
        "bond_cb_index_jsl": svc.col_cov_index_jsl,
        "bond_cb_adj_logs_jsl": svc.col_cov_adj_jsl,
        # 26-27 æ”¶ç›Šç‡æ›²çº¿
        "bond_china_close_return": svc.col_yield_curve_hist,
        "bond_zh_us_rate": svc.col_cn_us_yield,
        # 28-32 å€ºåˆ¸å‘è¡Œ
        "bond_treasure_issue_cninfo": svc.col_treasury_issue,
        "bond_local_government_issue_cninfo": svc.col_local_issue,
        "bond_corporate_issue_cninfo": svc.col_corporate_issue,
        "bond_cov_issue_cninfo": svc.col_cov_issue,
        "bond_cov_stock_issue_cninfo": svc.col_cov_convert,
        # 33-34 ä¸­å€ºæŒ‡æ•°
        "bond_new_composite_index_cbond": svc.col_zh_bond_new_index,
        "bond_composite_index_cbond": svc.col_zh_bond_index,
    }
    
    collection = collection_map.get(collection_name)
    if collection is None:
        return {"success": False, "error": f"é›†åˆ {collection_name} ä¸å­˜åœ¨"}
    
    try:
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        query = {}
        
        # å¯¹äº bond_info_cm é›†åˆï¼ŒåªæŸ¥è¯¢æ ‡å‡†æ•°æ®è®°å½•ï¼Œä¸æŸ¥è¯¢è¯¦ç»†æŸ¥è¯¢è®°å½•
        # è¿™æ ·å¯ä»¥ç¡®ä¿åˆ—è¡¨é¡µé¢ä¸ä¼šæ˜¾ç¤ºè¯¦ç»†æŸ¥è¯¢æ•°æ®ï¼ˆ60+ä¸ªè‹±æ–‡å­—æ®µï¼‰
        if collection_name == "bond_info_cm":
            query["endpoint"] = "bond_info_cm"
        
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿ filter_field å’Œ filter_value éƒ½æ˜¯å­—ç¬¦ä¸²ä¸”éç©º
        # æ³¨æ„ï¼šéœ€è¦å…ˆæ£€æŸ¥ç±»å‹ï¼Œé¿å…å¯¹Collectionå¯¹è±¡è¿›è¡Œå¸ƒå°”è¿ç®—
        # ä½¿ç”¨try-exceptå’Œtype()æ£€æŸ¥ï¼Œå®Œå…¨é¿å…å¸ƒå°”è¿ç®—
        try:
            # å…ˆæ£€æŸ¥ç±»å‹ï¼Œä½¿ç”¨type()è€Œä¸æ˜¯isinstance()ä»¥é¿å…å¸ƒå°”è¿ç®—
            # å¿…é¡»å…ˆæ£€æŸ¥ç±»å‹ï¼Œä¸èƒ½å…ˆè¿›è¡Œå¸ƒå°”è¿ç®—ï¼ˆåŒ…æ‹¬orè¡¨è¾¾å¼ï¼‰
            filter_field_type = type(filter_field) if filter_field is not None else None
            filter_value_type = type(filter_value) if filter_value is not None else None
            
            # åªæœ‰å½“ä¸¤ä¸ªå‚æ•°éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹æ—¶æ‰å¤„ç†
            if filter_field_type is str and filter_value_type is str:
                # ç°åœ¨å¯ä»¥å®‰å…¨åœ°è°ƒç”¨strip()
                filter_field_stripped = filter_field.strip()
                filter_value_stripped = filter_value.strip()
                # æ£€æŸ¥stripåçš„ç»“æœæ˜¯å¦ä¸ºç©ºï¼ˆå­—ç¬¦ä¸²å¯ä»¥ç›´æ¥è¿›è¡Œå¸ƒå°”è¿ç®—ï¼‰
                if filter_field_stripped and filter_value_stripped:
                    # æ”¯æŒæ¨¡ç³ŠæŸ¥è¯¢
                    if filter_field_stripped in ["code", "name", "å€ºåˆ¸ç®€ç§°", "å€ºåˆ¸ä»£ç "]:
                        query[filter_field_stripped] = {"$regex": filter_value_stripped, "$options": "i"}
                    else:
                        query[filter_field_stripped] = filter_value_stripped
        except (AttributeError, NotImplementedError, TypeError) as filter_err:
            # å¦‚æœfilter_fieldæˆ–filter_valueä¸æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼ˆå¯èƒ½æ˜¯Collectionå¯¹è±¡ï¼‰ï¼Œå¿½ç•¥è¿‡æ»¤
            logger.warning(f"âš ï¸ [é›†åˆæ•°æ®] è¿‡æ»¤å‚æ•°æ— æ•ˆï¼Œå°†å¿½ç•¥: {filter_err}")
            pass
        
        # è·å–æ€»æ•°
        total = await collection.count_documents(query)
        
        # æ„å»ºæ’åº
        # é»˜è®¤æŒ‰æ—¥æœŸå€’åºï¼Œå¦‚æœæ²¡æœ‰æ—¥æœŸå­—æ®µåˆ™æŒ‰_idå€’åº
        default_sort_key = None
        for date_field in ["date", "datetime", "timestamp", "æ›´æ–°æ—¥æœŸ", "å‘è¡Œæ—¥æœŸ", "ä¸Šå¸‚æ—¥æœŸ"]:
            # æ£€æŸ¥é›†åˆä¸­æ˜¯å¦æœ‰è¯¥å­—æ®µçš„æ–‡æ¡£
            test_doc = await collection.find_one({date_field: {"$exists": True}})
            if test_doc is not None:
                default_sort_key = date_field
                break
        
        # æ˜¾å¼é€‰æ‹©æ’åºé”®ï¼Œé¿å…ä½¿ç”¨ or é“¾å¼•å‘çš„éšå¼å¸ƒå°”æ±‚å€¼
        if sort_by is not None:
            sort_key = sort_by
        elif default_sort_key is not None:
            sort_key = default_sort_key
        else:
            sort_key = "_id"
        sort_direction = -1 if sort_dir == "desc" else 1
        
        # åˆ†é¡µæŸ¥è¯¢
        skip = (page - 1) * page_size
        cursor = collection.find(query).sort(sort_key, sort_direction).skip(skip).limit(page_size)
        items = []
        
        async for doc in cursor:
            # ç§»é™¤ _id æˆ–è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            if "_id" in doc:
                doc["_id"] = str(doc["_id"])
            items.append(doc)
        
        # è·å–å­—æ®µä¿¡æ¯ï¼ˆä»å½“å‰é¡µçš„è®°å½•æ”¶é›†ï¼‰
        # æ‰€æœ‰é¡µé¢ä½¿ç”¨ç»Ÿä¸€çš„å­—æ®µæ”¶é›†é€»è¾‘
        fields_info = []
        if items:
            field_map = {}  # {field_name: {"type": str, "example": str}}
            
            # ä»å½“å‰é¡µçš„æ‰€æœ‰è®°å½•æ”¶é›†å­—æ®µ
            for item in items:
                # å¯¹äº bond_info_cm é›†åˆï¼Œåªä»æ ‡å‡†æ•°æ®è®°å½•æ”¶é›†å­—æ®µï¼Œå¿½ç•¥è¯¦ç»†æŸ¥è¯¢è®°å½•
                # bond_info_cm é›†åˆåŒ…å«ä¸¤ç§æ•°æ®ï¼š
                # - æ ‡å‡†æ•°æ®ï¼ˆendpoint="bond_info_cm"ï¼‰: 10ä¸ªä¸­æ–‡å­—æ®µï¼Œç”¨äºåˆ—è¡¨æ˜¾ç¤º
                # - è¯¦ç»†æŸ¥è¯¢æ•°æ®ï¼ˆendpoint="bond_info_cm_query"ï¼‰: 60+ä¸ªè‹±æ–‡å­—æ®µï¼Œç”¨äºè¯¦æƒ…é¡µ
                # ä¸ºäº†ä¿è¯ç¬¬ä¸€é¡µå’Œç¬¬äºŒé¡µæ˜¾ç¤ºä¸€è‡´ï¼Œåªä»æ ‡å‡†æ•°æ®æ”¶é›†å­—æ®µ
                if collection_name == "bond_info_cm":
                    item_endpoint = item.get("endpoint", "")
                    if item_endpoint != "bond_info_cm":
                        # è·³è¿‡è¯¦ç»†æŸ¥è¯¢è®°å½•ï¼Œä¸ä»ä¸­æ”¶é›†å­—æ®µ
                        continue
                
                for key, value in item.items():
                    if key != "_id" and key not in field_map:
                        field_type = type(value).__name__
                        if field_type == "int":
                            field_type = "æ•´æ•°"
                        elif field_type == "float":
                            field_type = "æµ®ç‚¹æ•°"
                        elif field_type == "bool":
                            field_type = "å¸ƒå°”å€¼"
                        elif field_type == "list":
                            field_type = "åˆ—è¡¨"
                        elif field_type == "dict":
                            field_type = "å¯¹è±¡"
                        else:
                            field_type = "å­—ç¬¦ä¸²"
                        
                        field_map[key] = {
                            "name": key,
                            "type": field_type,
                            "example": str(value)[:50] if value is not None else None,
                        }
            
            # è½¬æ¢ä¸ºåˆ—è¡¨
            fields_info = list(field_map.values())
        
        # å¯¹äº bond_info_cm é›†åˆï¼Œåªæ˜¾ç¤ºæ ‡å‡†å­—æ®µï¼ˆä¸­æ–‡å­—æ®µï¼‰ï¼Œå¿½ç•¥è¯¦ç»†æŸ¥è¯¢çš„è‹±æ–‡å­—æ®µ
        if collection_name == "bond_info_cm" and fields_info:
            # å®šä¹‰æ ‡å‡†æ˜¾ç¤ºå­—æ®µï¼ˆæŒ‰æ˜¾ç¤ºé¡ºåºï¼‰
            standard_fields = [
                "å€ºåˆ¸ä»£ç ",
                "å€ºåˆ¸ç®€ç§°", 
                "å€ºåˆ¸ç±»å‹",
                "å‘è¡Œäºº/å—æ‰˜æœºæ„",
                "å‘è¡Œæ—¥æœŸ",
                "æœ€æ–°å€ºé¡¹è¯„çº§",
                "æŸ¥è¯¢ä»£ç ",
                "endpoint",
                "code",
                "source"
            ]
            
            # åªä¿ç•™æ ‡å‡†å­—æ®µï¼ˆæŒ‰å®šä¹‰çš„é¡ºåºï¼‰
            ordered_fields = []
            field_dict = {f["name"]: f for f in fields_info}
            
            for field_name in standard_fields:
                if field_name in field_dict:
                    ordered_fields.append(field_dict[field_name])
            
            # å¦‚æœæ ‡å‡†å­—æ®µä¸å­˜åœ¨ï¼ˆå¯èƒ½æ˜¯æ–°æ•°æ®ï¼‰ï¼Œä¿ç•™æ‰€æœ‰ä¸­æ–‡å­—æ®µ
            if len(ordered_fields) < 5:
                logger.warning(f"âš ï¸ [é›†åˆæ•°æ®] bond_info_cmæœªæ‰¾åˆ°æ ‡å‡†å­—æ®µï¼Œä½¿ç”¨æ‰€æœ‰ä¸­æ–‡å­—æ®µ")
                # åˆ†ç¦»ä¸­æ–‡å­—æ®µå’Œå…¶ä»–å­—æ®µ
                chinese_fields = [f for f in fields_info if any('\u4e00' <= c <= '\u9fff' for c in f["name"])]
                meta_fields = [f for f in fields_info if f["name"] in ["endpoint", "code", "source"]]
                ordered_fields = chinese_fields + meta_fields
            
            fields_info = ordered_fields
            logger.info(f"âœ… [é›†åˆæ•°æ®] bond_info_cmæ˜¾ç¤º{len(fields_info)}ä¸ªæ ‡å‡†å­—æ®µ")
        
        return {
            "success": True,
            "data": {
                "items": items,
                "total": total,
                "page": page,
                "page_size": page_size,
                "fields": fields_info,
            },
        }
    except Exception as e:
        logger.error(f"è·å–é›†åˆ {collection_name} æ•°æ®å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@router.get("/collections/{collection_name}/stats")
async def get_collection_stats(
    collection_name: str,
    current_user: dict = Depends(get_current_user),
):
    """è·å–æŒ‡å®šé›†åˆçš„ç»Ÿè®¡ä¿¡æ¯"""
    db = get_mongo_db()
    svc = BondDataService(db)
    
    # æ˜ å°„æ‰€æœ‰å€ºåˆ¸æ•°æ®é›†åˆåˆ°å¯¹åº”çš„MongoDBé›†åˆï¼ˆåŒ…å«34ä¸ªä¸»è¦é›†åˆå’Œå…¶ä»–è¾…åŠ©é›†åˆï¼‰
    collection_map = {
        # 01-02 åŸºç¡€æ•°æ®
        "bond_info_cm": svc.col_info_cm,
        "bond_info_detail_cm": svc.col_basic,
        # 03-04 æ²ªæ·±å€ºåˆ¸è¡Œæƒ…
        "bond_zh_hs_spot": svc.col_zh_hs_spot,
        "bond_zh_hs_daily": svc.col_zh_hs_daily,
        # 05-07 å¯è½¬å€ºè¡Œæƒ…
        "bond_zh_hs_cov_spot": svc.col_zh_hs_cov_spot,
        "bond_zh_hs_cov_daily": svc.col_zh_hs_cov_daily,
        "bond_zh_cov": svc.col_zh_cov,
        # 08-09 å¸‚åœºæ¦‚è§ˆ
        "bond_cash_summary_sse": svc.col_cash_summary_sse,
        "bond_deal_summary_sse": svc.col_deal_summary_sse,
        # 10-12 é“¶è¡Œé—´å¸‚åœº
        "bond_debt_nafmii": svc.col_debt_nafmii,
        "bond_spot_quote": svc.col_spot_quote,
        "bond_spot_deal": svc.col_spot_deal,
        # 13-14 å¯è½¬å€ºåˆ†æ—¶
        "bond_zh_hs_cov_min": svc.col_zh_hs_cov_min,
        "bond_zh_hs_cov_pre_min": svc.col_zh_hs_cov_pre_min,
        # 15-18 å¯è½¬å€ºè¯¦ç»†
        "bond_zh_cov_info": svc.col_zh_cov_info,
        "bond_zh_cov_info_ths": svc.col_zh_cov_info_ths,
        "bond_cov_comparison": svc.col_cov_comparison,
        "bond_zh_cov_value_analysis": svc.col_zh_cov_value_analysis,
        # 19-21 è´¨æŠ¼å¼å›è´­
        "bond_sh_buy_back_em": svc.col_sh_buy_back,
        "bond_sz_buy_back_em": svc.col_sz_buy_back,
        "bond_buy_back_hist_em": svc.col_buybacks_hist,
        # 22-25 é›†æ€å½•æ•°æ®
        "bond_cb_jsl": svc.col_cov_jsl,
        "bond_cb_redeem_jsl": svc.col_cov_redeem_jsl,
        "bond_cb_index_jsl": svc.col_cov_index_jsl,
        "bond_cb_adj_logs_jsl": svc.col_cov_adj_jsl,
        # 26-27 æ”¶ç›Šç‡æ›²çº¿
        "bond_china_close_return": svc.col_yield_curve_hist,
        "bond_zh_us_rate": svc.col_cn_us_yield,
        # 28-32 å€ºåˆ¸å‘è¡Œ
        "bond_treasure_issue_cninfo": svc.col_treasury_issue,
        "bond_local_government_issue_cninfo": svc.col_local_issue,
        "bond_corporate_issue_cninfo": svc.col_corporate_issue,
        "bond_cov_issue_cninfo": svc.col_cov_issue,
        "bond_cov_stock_issue_cninfo": svc.col_cov_convert,
        # 33-34 ä¸­å€ºæŒ‡æ•°
        "bond_new_composite_index_cbond": svc.col_zh_bond_new_index,
        "bond_composite_index_cbond": svc.col_zh_bond_index,
        # å…¶ä»–è¾…åŠ©é›†åˆï¼ˆä¿ç•™åŸæœ‰çš„æ˜ å°„ï¼‰
        "bond_basic_info": svc.col_basic,
        "bond_daily": svc.col_daily,
        "yield_curve_daily": svc.col_curve,
        "bond_spot_quotes": svc.col_spot,
        "bond_minute_quotes": svc.col_minute,
        "bond_cb_profiles": svc.col_cb_profiles,
        "bond_cb_valuation_daily": svc.col_cb_valuation,
        "bond_cb_comparison": svc.col_cb_comparison,
        "bond_cb_adjustments": svc.col_cb_adjustments,
        "bond_cb_redeems": svc.col_cb_redeems,
        "bond_issues": svc.col_issues,
        "bond_buybacks": svc.col_buybacks,
        "bond_indices_daily": svc.col_indices,
        "us_yield_daily": svc.col_us_yield,
        "bond_spot_quote_detail": svc.col_spot_quote_detail,
        "bond_spot_deals": svc.col_spot_deals,
        "bond_deal_summary": svc.col_deal_summary,
        "bond_cash_summary": svc.col_cash_summary,
        "bond_nafmii_debts": svc.col_nafmii,
        "bond_cov_list": svc.col_cov_list,
        "bond_cb_list_jsl": svc.col_cb_list_jsl,
        "bond_cb_summary": svc.col_cb_summary,
        "bond_events": svc.col_events,
        "yield_curve_map": svc.col_curve_map,
    }
    
    collection = collection_map.get(collection_name)
    if collection is None:
        return {"success": False, "error": f"é›†åˆ {collection_name} ä¸å­˜åœ¨"}
    
    try:
        logger.info(f"ğŸ“Š [é›†åˆç»Ÿè®¡] å¼€å§‹è·å–é›†åˆ {collection_name} çš„ç»Ÿè®¡ä¿¡æ¯")
        
        # æ€»è®°å½•æ•°
        try:
            total_count = await collection.count_documents({})
            logger.info(f"ğŸ“Š [é›†åˆç»Ÿè®¡] é›†åˆ {collection_name} æ€»è®°å½•æ•°: {total_count}")
        except Exception as count_err:
            logger.error(f"âŒ [é›†åˆç»Ÿè®¡] è·å–æ€»è®°å½•æ•°å¤±è´¥: {count_err}", exc_info=True)
            total_count = 0
        
        # è·å–æœ€æ—©å’Œæœ€æ™šçš„æ—¥æœŸï¼ˆå¦‚æœæœ‰dateæˆ–datetimeå­—æ®µï¼‰
        stats = {
            "total_count": total_count,
            "collection_name": collection_name,
        }
        
        # å°è¯•è·å–æ—¥æœŸèŒƒå›´
        date_fields = ["date", "datetime", "timestamp", "æ›´æ–°æ—¥æœŸ", "å‘è¡Œæ—¥æœŸ", "ä¸Šå¸‚æ—¥æœŸ"]
        for date_field in date_fields:
            try:
                # æŸ¥æ‰¾æœ‰è¯¥å­—æ®µçš„æ–‡æ¡£
                first_doc = await collection.find_one({date_field: {"$exists": True}}, sort=[(date_field, 1)])
                last_doc = await collection.find_one({date_field: {"$exists": True}}, sort=[(date_field, -1)])
                
                if first_doc is not None and last_doc is not None:
                    first_date = first_doc.get(date_field)
                    last_date = last_doc.get(date_field)
                    if first_date:
                        stats["earliest_date"] = str(first_date)[:10]
                    if last_date:
                        stats["latest_date"] = str(last_date)[:10]
                    stats["date_field"] = date_field
                    logger.info(f"ğŸ“Š [é›†åˆç»Ÿè®¡] æ‰¾åˆ°æ—¥æœŸå­—æ®µ {date_field}: {stats.get('earliest_date')} - {stats.get('latest_date')}")
                    break
            except Exception as date_err:
                logger.debug(f"âš ï¸ [é›†åˆç»Ÿè®¡] è·å–æ—¥æœŸå­—æ®µ {date_field} å¤±è´¥: {date_err}")
                continue
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰categoryå­—æ®µï¼‰
        try:
            pipeline = [
                {"$group": {"_id": "$category", "count": {"$sum": 1}}},
                {"$sort": {"count": -1}},
            ]
            category_stats = []
            async for doc in collection.aggregate(pipeline):
                category_id = doc.get("_id")
                count = doc.get("count", 0)
                category_stats.append({
                    "category": str(category_id) if category_id is not None else "æœªçŸ¥",
                    "count": int(count)
                })
            if len(category_stats) > 0:
                stats["category_stats"] = category_stats
                logger.info(f"ğŸ“Š [é›†åˆç»Ÿè®¡] æ‰¾åˆ° {len(category_stats)} ä¸ªç±»åˆ«")
        except Exception as cat_err:
            logger.debug(f"âš ï¸ [é›†åˆç»Ÿè®¡] è·å–ç±»åˆ«ç»Ÿè®¡å¤±è´¥: {cat_err}")
            pass
        
        # æŒ‰äº¤æ˜“æ‰€ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰exchangeå­—æ®µï¼‰
        try:
            pipeline = [
                {"$group": {"_id": "$exchange", "count": {"$sum": 1}}},
                {"$sort": {"count": -1}},
            ]
            exchange_stats = []
            async for doc in collection.aggregate(pipeline):
                exchange_id = doc.get("_id")
                count = doc.get("count", 0)
                exchange_stats.append({
                    "exchange": str(exchange_id) if exchange_id is not None else "æœªçŸ¥",
                    "count": int(count)
                })
            if len(exchange_stats) > 0:
                stats["exchange_stats"] = exchange_stats
                logger.info(f"ğŸ“Š [é›†åˆç»Ÿè®¡] æ‰¾åˆ° {len(exchange_stats)} ä¸ªäº¤æ˜“æ‰€")
        except Exception as exch_err:
            logger.debug(f"âš ï¸ [é›†åˆç»Ÿè®¡] è·å–äº¤æ˜“æ‰€ç»Ÿè®¡å¤±è´¥: {exch_err}")
            pass

        # bond_info_cm ä¸“ç”¨ç»Ÿè®¡ï¼šæŒ‰â€œå€ºåˆ¸ç±»å‹â€å’Œâ€œæœ€æ–°å€ºé¡¹è¯„çº§â€ç»Ÿè®¡
        if collection_name == "bond_info_cm":
            # å€ºåˆ¸ç±»å‹åˆ†å¸ƒ
            try:
                pipeline = [
                    {
                        "$match": {
                            "$and": [
                                {"$or": [{"endpoint": "bond_info_cm"}, {"endpoint": {"$exists": False}}]},
                                {"å€ºåˆ¸ç±»å‹": {"$exists": True, "$ne": ""}},
                            ]
                        }
                    },
                    {"$group": {"_id": "$å€ºåˆ¸ç±»å‹", "count": {"$sum": 1}}},
                    {"$sort": {"count": -1}},
                ]
                bond_type_stats: List[Dict[str, Any]] = []
                async for doc in collection.aggregate(pipeline):
                    type_id = doc.get("_id")
                    count = int(doc.get("count", 0))
                    bond_type_stats.append(
                        {"type": str(type_id) if type_id is not None else "æœªçŸ¥", "count": count}
                    )
                if bond_type_stats:
                    stats["bond_type_stats"] = bond_type_stats
                    logger.info(f"ğŸ“Š [é›†åˆç»Ÿè®¡] bond_info_cm å€ºåˆ¸ç±»å‹ç»Ÿè®¡é¡¹æ•°: {len(bond_type_stats)}")
            except Exception as type_err:
                logger.debug(f"âš ï¸ [é›†åˆç»Ÿè®¡] è·å–å€ºåˆ¸ç±»å‹ç»Ÿè®¡å¤±è´¥: {type_err}")

            # æœ€æ–°å€ºé¡¹è¯„çº§åˆ†å¸ƒ
            try:
                pipeline = [
                    {
                        "$match": {
                            "$and": [
                                {"$or": [{"endpoint": "bond_info_cm"}, {"endpoint": {"$exists": False}}]},
                                {"æœ€æ–°å€ºé¡¹è¯„çº§": {"$exists": True, "$ne": ""}},
                            ]
                        }
                    },
                    {"$group": {"_id": "$æœ€æ–°å€ºé¡¹è¯„çº§", "count": {"$sum": 1}}},
                    {"$sort": {"count": -1}},
                ]
                grade_stats: List[Dict[str, Any]] = []
                async for doc in collection.aggregate(pipeline):
                    grade_id = doc.get("_id")
                    count = int(doc.get("count", 0))
                    grade_stats.append(
                        {"grade": str(grade_id) if grade_id is not None else "æœªçŸ¥", "count": count}
                    )
                if grade_stats:
                    stats["grade_stats"] = grade_stats
                    logger.info(f"ğŸ“Š [é›†åˆç»Ÿè®¡] bond_info_cm æœ€æ–°å€ºé¡¹è¯„çº§ç»Ÿè®¡é¡¹æ•°: {len(grade_stats)}")
            except Exception as grade_err:
                logger.debug(f"âš ï¸ [é›†åˆç»Ÿè®¡] è·å–å€ºé¡¹è¯„çº§ç»Ÿè®¡å¤±è´¥: {grade_err}")

        logger.info(f"âœ… [é›†åˆç»Ÿè®¡] é›†åˆ {collection_name} ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ")
        return {"success": True, "data": stats}
    except HTTPException:
        # HTTPExceptionåº”è¯¥ç›´æ¥æŠ›å‡º
        raise
    except Exception as e:
        logger.error(f"âŒ [é›†åˆç»Ÿè®¡] è·å–é›†åˆ {collection_name} ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)
        import traceback
        error_trace = traceback.format_exc()
        logger.error(f"âŒ [é›†åˆç»Ÿè®¡] é”™è¯¯å †æ ˆ: {error_trace}")
        raise HTTPException(
            status_code=500,
            detail=f"è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"
        )


@router.get("/collections/bond_info_cm/issuance/yearly")
async def get_bond_info_cm_yearly_issuance(
    current_user: dict = Depends(get_current_user),
):
    """ç»Ÿè®¡ bond_info_cm é›†åˆæŒ‰å¹´ä»½çš„å€ºåˆ¸å‘è¡Œæ•°é‡"""
    db = get_mongo_db()
    svc = BondDataService(db)

    pipeline = [
        {"$match": {"endpoint": "bond_info_cm", "å‘è¡Œæ—¥æœŸ": {"$exists": True, "$ne": ""}}},
        {"$addFields": {"year": {"$substr": ["$å‘è¡Œæ—¥æœŸ", 0, 4]}}},
        {"$match": {"year": {"$regex": "^[0-9]{4}$"}}},
        {"$group": {"_id": "$year", "count": {"$sum": 1}}},
        {"$sort": {"_id": 1}},
    ]

    try:
        results: List[Dict[str, Any]] = []
        async for doc in svc.col_info_cm.aggregate(pipeline):
            year = str(doc.get("_id", ""))
            count = int(doc.get("count", 0))
            results.append({"year": year, "count": count})

        return {
            "success": True,
            "data": {
                "items": results,
                "total_years": len(results)
            }
        }
    except Exception as e:
        logger.error(f"âŒ [bond_info_cm] è·å–å¹´åº¦å‘è¡Œç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"è·å–å¹´åº¦å‘è¡Œç»Ÿè®¡å¤±è´¥: {str(e)}"
        )




# å€ºåˆ¸åˆ†æç›¸å…³æ¨¡å‹
class BondAnalysisRequest(BaseModel):
    bond_code: str
    parameters: Optional[Dict[str, Any]] = {}


@router.post("/analysis")
async def start_bond_analysis(
    request: BondAnalysisRequest,
    background_tasks: BackgroundTasks,
    current_user: dict = Depends(get_current_user),
):
    """æäº¤å€ºåˆ¸åˆ†æä»»åŠ¡"""
    try:
        logger.info(f"ğŸ¯ æ”¶åˆ°å€ºåˆ¸åˆ†æè¯·æ±‚: {request.bond_code}")
        
        # éªŒè¯å€ºåˆ¸ä»£ç æ ¼å¼
        bond_code = request.bond_code.strip()
        import re
        if not re.match(r'^\d{6}\.(SH|SZ|IB)$', bond_code, re.IGNORECASE):
            raise HTTPException(status_code=400, detail="å€ºåˆ¸ä»£ç æ ¼å¼ä¸æ­£ç¡®ï¼Œåº”ä¸ºï¼šä»£ç .äº¤æ˜“æ‰€ï¼ˆå¦‚ï¼š110062.SHï¼‰")
        
        # åˆ›å»ºä»»åŠ¡ID
        task_id = str(uuid.uuid4())
        
        # å¯¼å…¥åˆ†ææœåŠ¡
        from app.services.bond_analysis_service import get_bond_analysis_service
        service = get_bond_analysis_service()
        
        # åˆ›å»ºä»»åŠ¡è®°å½•
        result = await service.create_analysis_task(
            user_id=current_user["id"],
            task_id=task_id,
            request=request
        )
        
        # åœ¨åå°æ‰§è¡Œåˆ†æä»»åŠ¡
        async def run_analysis_task():
            try:
                logger.info(f"ğŸš€ [BackgroundTask] å¼€å§‹æ‰§è¡Œå€ºåˆ¸åˆ†æä»»åŠ¡: {task_id}")
                await service.execute_analysis_background(task_id, current_user["id"], request)
                logger.info(f"âœ… [BackgroundTask] å€ºåˆ¸åˆ†æä»»åŠ¡å®Œæˆ: {task_id}")
            except Exception as e:
                logger.error(f"âŒ [BackgroundTask] å€ºåˆ¸åˆ†æä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {e}", exc_info=True)
        
        background_tasks.add_task(run_analysis_task)
        
        return {
            "success": True,
            "data": {"task_id": task_id},
            "message": "åˆ†æä»»åŠ¡å·²åœ¨åå°å¯åŠ¨"
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æäº¤å€ºåˆ¸åˆ†æä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/analysis/{task_id}/status")
async def get_bond_analysis_status(
    task_id: str,
    current_user: dict = Depends(get_current_user),
):
    """è·å–å€ºåˆ¸åˆ†æä»»åŠ¡çŠ¶æ€"""
    try:
        from app.services.bond_analysis_service import get_bond_analysis_service
        service = get_bond_analysis_service()
        
        status = await service.get_task_status(task_id)
        
        if not status:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        return {
            "success": True,
            "data": status
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–å€ºåˆ¸åˆ†æä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/analysis/{task_id}/result")
async def get_bond_analysis_result(
    task_id: str,
    current_user: dict = Depends(get_current_user),
):
    """è·å–å€ºåˆ¸åˆ†æç»“æœ"""
    try:
        from app.services.bond_analysis_service import get_bond_analysis_service
        service = get_bond_analysis_service()
        
        result = await service.get_task_result(task_id)
        
        if not result:
            raise HTTPException(status_code=404, detail="åˆ†æç»“æœä¸å­˜åœ¨")
        
        return {
            "success": True,
            "data": result
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–å€ºåˆ¸åˆ†æç»“æœå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/collections/{collection_name}/refresh")
async def refresh_collection_data(
    collection_name: str,
    background_tasks: BackgroundTasks,
    params: Dict[str, Any] = Body(default={}),
    current_user: dict = Depends(get_current_user),
):
    """ä»AKShareæ›´æ–°æŒ‡å®šé›†åˆçš„æ•°æ®ï¼ˆå¼‚æ­¥æ‰§è¡Œï¼Œæ”¯æŒè¿›åº¦æŸ¥è¯¢ï¼‰
    
    è¯·æ±‚ä½“å‚æ•°ï¼ˆJSONï¼‰ï¼š
    - update_type: 'batch' æˆ– 'single'ï¼Œé»˜è®¤ 'single'
    - concurrency: å¹¶å‘æ•°ï¼ˆæ‰¹é‡æ›´æ–°æ—¶ï¼‰
    - å…¶ä»–å‚æ•°æ ¹æ®é›†åˆä¸åŒè€Œä¸åŒï¼Œå‚è€ƒ /collections/{collection_name}/update-config
    
    ç¤ºä¾‹è¯·æ±‚ä½“ï¼š
    ```json
    {
        "update_type": "batch",
        "concurrency": 3,
        "year": "2024"
    }
    ```
    """
    try:
        logger.info(f"ğŸ”„ åˆ›å»ºé›†åˆæ›´æ–°ä»»åŠ¡: {collection_name}, params={params}")
        
        db = get_mongo_db()
        task_manager = get_task_manager()
        
        # ä½¿ç”¨æ–°çš„ BondRefreshService
        from app.services.bond_refresh_service import BondRefreshService
        refresh_service = BondRefreshService(db)
        
        # åˆ›å»ºä»»åŠ¡
        task_id = task_manager.create_task(
            task_type=f"refresh_{collection_name}",
            description=f"æ›´æ–°é›†åˆ: {collection_name}"
        )
        
        # åœ¨åå°å¼‚æ­¥æ‰§è¡Œåˆ·æ–°ä»»åŠ¡
        async def do_refresh():
            try:
                await refresh_service.refresh_collection(
                    collection_name, task_id, params
                )
            except Exception as e:
                logger.error(f"åå°åˆ·æ–°ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
                # ç¡®ä¿ä»»åŠ¡çŠ¶æ€è¢«æ ‡è®°ä¸ºå¤±è´¥
                try:
                    task_manager.fail_task(task_id, str(e))
                except Exception as inner_e:
                    logger.error(f"æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {inner_e}", exc_info=True)
        
        background_tasks.add_task(do_refresh)
        
        # ç«‹å³è¿”å›ä»»åŠ¡IDï¼Œå‰ç«¯å¯ä»¥ç”¨æ­¤IDæŸ¥è¯¢è¿›åº¦
        return {
            "success": True,
            "data": {
                "task_id": task_id,
                "message": f"ä»»åŠ¡å·²åˆ›å»ºï¼Œè¯·ä½¿ç”¨ task_id æŸ¥è¯¢è¿›åº¦"
            }
        }
    
    except Exception as e:
        error_msg = f"åˆ›å»ºæ›´æ–°ä»»åŠ¡å¤±è´¥: {str(e)}"
        logger.error(f"âŒ {error_msg}", exc_info=True)
        raise HTTPException(status_code=500, detail=error_msg)


@router.get("/collections/refresh/task/{task_id}")
async def get_refresh_task_status(
    task_id: str,
    current_user: dict = Depends(get_current_user),
):
    """æŸ¥è¯¢æ•°æ®åˆ·æ–°ä»»åŠ¡çš„è¿›åº¦"""
    try:
        task_manager = get_task_manager()
        task = task_manager.get_task(task_id)
        
        if not task:
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨")
        
        return {"success": True, "data": task}
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/collections/{collection_name}/import")
async def import_collection_data(
    collection_name: str,
    file: UploadFile = File(..., description="CSV æˆ– Excel æ–‡ä»¶"),
    current_user: dict = Depends(get_current_user),
):
    """ä»æ–‡ä»¶å¯¼å…¥å€ºåˆ¸é›†åˆæ•°æ®ï¼ˆç›®å‰ä»…æ”¯æŒ bond_info_cmï¼‰"""
    try:
        logger.info(f"ğŸ“¥ [é›†åˆå¯¼å…¥] collection={collection_name}, filename={file.filename}")

        if collection_name != "bond_info_cm":
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="å½“å‰ä»…æ”¯æŒ bond_info_cm é›†åˆçš„æ–‡ä»¶å¯¼å…¥",
            )

        db = get_mongo_db()
        if db is None:
            raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")

        svc = BondDataService(db)
        content = await file.read()
        filename = file.filename or ""

        result = await svc.import_bond_info_cm_from_file(content, filename)
        saved = int(result.get("saved") or 0)
        rows = int(result.get("rows") or 0)

        message = f"æˆåŠŸå¯¼å…¥ {saved} æ¡è®°å½•" if rows > 0 else "æ–‡ä»¶ä¸­æ²¡æœ‰å¯å¯¼å…¥çš„æ•°æ®"

        return {
            "success": True,
            "data": {
                "collection_name": collection_name,
                "saved": saved,
                "rows": rows,
                "message": message,
            },
        }
    except HTTPException:
        raise
    except ValueError as ve:
        logger.warning(f"âš ï¸ [é›†åˆå¯¼å…¥] å‚æ•°é”™è¯¯: {ve}")
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(ve))
    except Exception as e:
        logger.error(f"âŒ [é›†åˆå¯¼å…¥] å¯¼å…¥é›†åˆ {collection_name} å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å¯¼å…¥æ•°æ®å¤±è´¥: {str(e)}")


@router.post("/collections/{collection_name}/sync-remote")
async def sync_collection_from_remote(
    collection_name: str,
    remote_host: str = Query(..., description="è¿œç¨‹ MongoDB ä¸»æœºåœ°å€æˆ– URI"),
    db_type: str = Query("mongodb", description="æ•°æ®åº“ç±»å‹ï¼Œç›®å‰ä»…æ”¯æŒ mongodb"),
    batch_size: int = Query(5000, ge=100, le=100000, description="æ¯æ‰¹æ¬¡åŒæ­¥æ•°é‡"),
    remote_collection: Optional[str] = Query(None, description="è¿œç¨‹é›†åˆåç§°ï¼Œé»˜è®¤ä¸ºæœ¬åœ°é›†åˆå"),
    remote_username: Optional[str] = Query(None, description="è¿œç¨‹æ•°æ®åº“ç”¨æˆ·å"),
    remote_password: Optional[str] = Query(None, description="è¿œç¨‹æ•°æ®åº“å¯†ç "),
    remote_auth_source: Optional[str] = Query(None, description="è¿œç¨‹è®¤è¯åº“ï¼ˆauthSourceï¼‰ï¼Œé»˜è®¤ä¸ºç›®æ ‡æ•°æ®åº“å"),
    current_user: dict = Depends(get_current_user),
):
    """ä»è¿œç¨‹æ•°æ®åº“åŒæ­¥é›†åˆæ•°æ®åˆ°æœ¬åœ°ï¼ˆå½“å‰ä»…æ”¯æŒ bond_info_cm åŠ MongoDBï¼‰ã€‚"""
    try:
        logger.info(
            f"ğŸ“¡ [é›†åˆè¿œç¨‹åŒæ­¥] collection={collection_name}, remote_host={remote_host}, db_type={db_type}, batch_size={batch_size}"
        )

        if collection_name != "bond_info_cm":
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="å½“å‰ä»…æ”¯æŒ bond_info_cm é›†åˆçš„è¿œç¨‹åŒæ­¥",
            )

        if not remote_host:
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="è¿œç¨‹ä¸»æœºåœ°å€ä¸èƒ½ä¸ºç©º")

        if (db_type or "mongodb").lower() != "mongodb":
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="å½“å‰ä»…æ”¯æŒ MongoDB è¿œç¨‹åŒæ­¥")

        db = get_mongo_db()
        if db is None:
            raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")

        svc = BondDataService(db)
        result = await svc.sync_collection_from_remote_mongo(
            collection_name=collection_name,
            remote_host=remote_host,
            batch_size=batch_size,
            remote_collection=remote_collection,
            remote_username=remote_username,
            remote_password=remote_password,
            remote_auth_source=remote_auth_source,
        )

        synced = int(result.get("synced") or 0)
        remote_total = int(result.get("remote_total") or 0)

        message = f"æˆåŠŸä»è¿œç¨‹åŒæ­¥ {synced} æ¡è®°å½•ï¼ˆè¿œç¨‹å…± {remote_total} æ¡ï¼‰"

        return {
            "success": True,
            "data": {
                "collection_name": collection_name,
                "synced": synced,
                "remote_total": remote_total,
                "batch_size": batch_size,
                "message": message,
            },
        }
    except HTTPException:
        raise
    except ValueError as ve:
        logger.warning(f"âš ï¸ [é›†åˆè¿œç¨‹åŒæ­¥] å‚æ•°é”™è¯¯: {ve}")
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(ve))
    except Exception as e:
        logger.error(f"âŒ [é›†åˆè¿œç¨‹åŒæ­¥] åŒæ­¥é›†åˆ {collection_name} å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è¿œç¨‹åŒæ­¥å¤±è´¥: {str(e)}")


@router.delete("/collections/{collection_name}/clear")
async def clear_collection_data(
    collection_name: str,
    current_user: dict = Depends(get_current_user),
):
    """æ¸…ç©ºé›†åˆæ•°æ®
    
    åˆ é™¤æŒ‡å®šé›†åˆä¸­çš„æ‰€æœ‰æ•°æ®ï¼Œæ­¤æ“ä½œä¸å¯æ¢å¤
    """
    try:
        logger.info(f"âš ï¸  [æ¸…ç©ºé›†åˆ] æ”¶åˆ°æ¸…ç©ºè¯·æ±‚: collection={collection_name}, user={current_user.get('username')}")
        
        db = get_mongo_db()
        if db is None:
            raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")
        
        # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
        if collection_name not in await db.list_collection_names():
            raise HTTPException(status_code=404, detail=f"é›†åˆ {collection_name} ä¸å­˜åœ¨")
        
        # æ¸…ç©ºé›†åˆæ•°æ®
        collection = db[collection_name]
        result = await collection.delete_many({})
        deleted_count = result.deleted_count
        
        logger.info(f"âœ… [æ¸…ç©ºé›†åˆ] æˆåŠŸæ¸…ç©º {collection_name}ï¼Œåˆ é™¤äº† {deleted_count} æ¡è®°å½•")
        
        return {
            "success": True,
            "data": {
                "collection_name": collection_name,
                "deleted_count": deleted_count,
                "message": f"æˆåŠŸæ¸…ç©ºé›†åˆ {collection_name}ï¼Œåˆ é™¤äº† {deleted_count} æ¡è®°å½•"
            }
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æ¸…ç©ºé›†åˆå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== å¯è½¬å€ºä¸“é¡¹åŠŸèƒ½ ====================

@router.get("/convertible/comparison")
async def get_convertible_comparison(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(50, ge=1, le=200, description="æ¯é¡µæ•°é‡"),
    q: Optional[str] = Query(None, description="æœç´¢å…³é”®è¯ï¼ˆä»£ç æˆ–åç§°ï¼‰"),
    sort_by: Optional[str] = Query(None, description="æ’åºå­—æ®µ"),
    sort_dir: str = Query("asc", description="æ’åºæ–¹å‘ï¼šasc/desc"),
    min_premium: Optional[float] = Query(None, description="æœ€å°è½¬è‚¡æº¢ä»·ç‡"),
    max_premium: Optional[float] = Query(None, description="æœ€å¤§è½¬è‚¡æº¢ä»·ç‡"),
    current_user: dict = Depends(get_current_user),
):
    """è·å–å¯è½¬å€ºæ¯”ä»·è¡¨
    
    è¿”å›å¯è½¬å€ºçš„å®æ—¶æ¯”ä»·æ•°æ®ï¼ŒåŒ…æ‹¬è½¬è‚¡ä»·ã€è½¬è‚¡ä»·å€¼ã€æº¢ä»·ç‡ç­‰æ ¸å¿ƒæŒ‡æ ‡
    æ”¯æŒå…³é”®è¯æœç´¢ã€æº¢ä»·ç‡èŒƒå›´è¿‡æ»¤ã€æ’åºå’Œåˆ†é¡µ
    """
    try:
        logger.info(f"ğŸ” [å¯è½¬å€ºæ¯”ä»·] æ”¶åˆ°è¯·æ±‚: page={page}, page_size={page_size}, q={q}, "
                   f"premium_range=[{min_premium}, {max_premium}]")
        
        db = get_mongo_db()
        if db is None:
            raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")
        
        svc = BondDataService(db)
        
        # æŸ¥è¯¢æ•°æ®ï¼ˆåœ¨æ•°æ®åº“å±‚è¿‡æ»¤ï¼Œæ€§èƒ½æ›´å¥½ï¼‰
        result = await svc.query_cov_comparison(
            q=q,
            sort_by=sort_by,
            sort_dir=sort_dir,
            page=page,
            page_size=page_size,
            min_premium=min_premium,
            max_premium=max_premium
        )
        
        logger.info(f"âœ… [å¯è½¬å€ºæ¯”ä»·] è¿”å› {len(result.get('items', []))}/{result.get('total', 0)} æ¡æ•°æ®")
        
        return {
            "success": True,
            "data": {
                "total": result.get("total", 0),
                "page": page,
                "page_size": page_size,
                "items": result.get("items", [])
            }
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºæ¯”ä»·] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/convertible/comparison/sync")
async def sync_convertible_comparison(
    current_user: dict = Depends(get_current_user),
):
    """åŒæ­¥å¯è½¬å€ºæ¯”ä»·æ•°æ®
    
    ä»AKShareè·å–æœ€æ–°çš„å¯è½¬å€ºæ¯”ä»·è¡¨æ•°æ®å¹¶ä¿å­˜åˆ°æ•°æ®åº“
    """
    try:
        logger.info(f"ğŸ”„ [å¯è½¬å€ºæ¯”ä»·åŒæ­¥] å¼€å§‹åŒæ­¥æ•°æ®")
        
        from tradingagents.dataflows.providers.china.bonds import AKShareBondProvider
        
        provider = AKShareBondProvider()
        df = await provider.get_cov_comparison()
        
        if df is None or df.empty:
            logger.warning("âš ï¸ [å¯è½¬å€ºæ¯”ä»·åŒæ­¥] æœªè·å–åˆ°æ•°æ®")
            raise HTTPException(status_code=404, detail="æœªè·å–åˆ°æ•°æ®")
        
        logger.info(f"ğŸ“¡ [å¯è½¬å€ºæ¯”ä»·åŒæ­¥] è·å–åˆ° {len(df)} æ¡æ•°æ®")
        
        db = get_mongo_db()
        if db is None:
            raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")
        
        svc = BondDataService(db)
        saved = await svc.save_cov_comparison(df)
        
        logger.info(f"âœ… [å¯è½¬å€ºæ¯”ä»·åŒæ­¥] æˆåŠŸä¿å­˜ {saved} æ¡æ•°æ®")
        
        return {
            "success": True,
            "data": {
                "saved": saved,
                "total": len(df),
                "message": f"æˆåŠŸåŒæ­¥ {saved} æ¡å¯è½¬å€ºæ¯”ä»·æ•°æ®"
            }
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºæ¯”ä»·åŒæ­¥] å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/convertible/{code}/value-analysis")
async def get_convertible_value_analysis(
    code: str,
    start_date: Optional[str] = Query(None, description="å¼€å§‹æ—¥æœŸ YYYY-MM-DD"),
    end_date: Optional[str] = Query(None, description="ç»“æŸæ—¥æœŸ YYYY-MM-DD"),
    current_user: dict = Depends(get_current_user),
):
    """è·å–å¯è½¬å€ºä»·å€¼åˆ†æå†å²æ•°æ®
    
    è¿”å›æŒ‡å®šå¯è½¬å€ºçš„å†å²ä»·å€¼åˆ†ææ•°æ®ï¼ŒåŒ…æ‹¬çº¯å€ºä»·å€¼ã€è½¬è‚¡ä»·å€¼ã€æº¢ä»·ç‡èµ°åŠ¿ç­‰
    """
    try:
        logger.info(f"ğŸ” [å¯è½¬å€ºä»·å€¼åˆ†æ] æŸ¥è¯¢ {code}")
        
        db = get_mongo_db()
        if db is None:
            raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")
        
        svc = BondDataService(db)
        
        # æŸ¥è¯¢æ•°æ®åº“
        result = await svc.query_cov_value_analysis(
            code=code,
            start_date=start_date,
            end_date=end_date
        )
        
        # å¦‚æœæ•°æ®åº“æ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä»AKShareè·å–
        if not result.get("data"):
            logger.info(f"ğŸ“¡ [å¯è½¬å€ºä»·å€¼åˆ†æ] æ•°æ®åº“æ— æ•°æ®ï¼Œä»AKShareè·å–")
            
            from tradingagents.dataflows.providers.china.bonds import AKShareBondProvider
            provider = AKShareBondProvider()
            df = await provider.get_cov_value_analysis(code)
            
            if df is not None and not df.empty:
                # ä¿å­˜åˆ°æ•°æ®åº“
                saved = await svc.save_cov_value_analysis(code, df)
                logger.info(f"ğŸ’¾ [å¯è½¬å€ºä»·å€¼åˆ†æ] ä¿å­˜ {saved} æ¡æ•°æ®")
                
                # é‡æ–°æŸ¥è¯¢
                result = await svc.query_cov_value_analysis(
                    code=code,
                    start_date=start_date,
                    end_date=end_date
                )
        
        logger.info(f"âœ… [å¯è½¬å€ºä»·å€¼åˆ†æ] è¿”å› {len(result.get('data', []))} æ¡æ•°æ®")
        
        return {
            "success": True,
            "data": result
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºä»·å€¼åˆ†æ] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/convertible/{code}/value-analysis/sync")
async def sync_convertible_value_analysis(
    code: str,
    current_user: dict = Depends(get_current_user),
):
    """åŒæ­¥æŒ‡å®šå¯è½¬å€ºçš„ä»·å€¼åˆ†ææ•°æ®"""
    try:
        logger.info(f"ğŸ”„ [ä»·å€¼åˆ†æåŒæ­¥] åŒæ­¥ {code}")
        
        from tradingagents.dataflows.providers.china.bonds import AKShareBondProvider
        
        provider = AKShareBondProvider()
        df = await provider.get_cov_value_analysis(code)
        
        if df is None or df.empty:
            raise HTTPException(status_code=404, detail="æœªè·å–åˆ°æ•°æ®")
        
        db = get_mongo_db()
        if db is None:
            raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")
        
        svc = BondDataService(db)
        saved = await svc.save_cov_value_analysis(code, df)
        
        logger.info(f"âœ… [ä»·å€¼åˆ†æåŒæ­¥] ä¿å­˜ {saved} æ¡æ•°æ®")
        
        return {
            "success": True,
            "data": {
                "saved": saved,
                "total": len(df),
                "message": f"æˆåŠŸåŒæ­¥ {saved} æ¡ä»·å€¼åˆ†ææ•°æ®"
            }
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [ä»·å€¼åˆ†æåŒæ­¥] å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/market/spot-deals")
async def get_spot_deals(
    current_user: dict = Depends(get_current_user),
):
    """è·å–ç°åˆ¸å¸‚åœºæˆäº¤è¡Œæƒ…
    
    è¿”å›é“¶è¡Œé—´ç°åˆ¸å¸‚åœºçš„å®æ—¶æˆäº¤æ•°æ®
    """
    try:
        logger.info(f"ğŸ” [ç°åˆ¸æˆäº¤] æŸ¥è¯¢æˆäº¤è¡Œæƒ…")
        
        from tradingagents.dataflows.providers.china.bonds import AKShareBondProvider
        
        provider = AKShareBondProvider()
        df = await provider.get_spot_deal()
        
        if df is None or df.empty:
            raise HTTPException(status_code=404, detail="æœªè·å–åˆ°æ•°æ®")
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        items = df.to_dict(orient="records")
        
        # æ¸…ç†NaNå€¼
        import math
        for item in items:
            for key, value in list(item.items()):
                if isinstance(value, float) and math.isnan(value):
                    item[key] = None
        
        logger.info(f"âœ… [ç°åˆ¸æˆäº¤] è¿”å› {len(items)} æ¡æ•°æ®")
        
        return {
            "success": True,
            "data": {
                "total": len(items),
                "items": items
            }
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [ç°åˆ¸æˆäº¤] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/market/spot-quotes")
async def get_spot_quotes(
    current_user: dict = Depends(get_current_user),
):
    """è·å–ç°åˆ¸å¸‚åœºåšå¸‚æŠ¥ä»·
    
    è¿”å›é“¶è¡Œé—´ç°åˆ¸å¸‚åœºçš„åšå¸‚å•†æŠ¥ä»·æ•°æ®
    """
    try:
        logger.info(f"ğŸ” [ç°åˆ¸æŠ¥ä»·] æŸ¥è¯¢åšå¸‚æŠ¥ä»·")
        
        from tradingagents.dataflows.providers.china.bonds import AKShareBondProvider
        
        provider = AKShareBondProvider()
        df = await provider.get_spot_quote()
        
        if df is None or df.empty:
            raise HTTPException(status_code=404, detail="æœªè·å–åˆ°æ•°æ®")
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        items = df.to_dict(orient="records")
        
        # æ¸…ç†NaNå€¼
        import math
        for item in items:
            for key, value in list(item.items()):
                if isinstance(value, float) and math.isnan(value):
                    item[key] = None
        
        logger.info(f"âœ… [ç°åˆ¸æŠ¥ä»·] è¿”å› {len(items)} æ¡æ•°æ®")
        
        return {
            "success": True,
            "data": {
                "total": len(items),
                "items": items
            }
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [ç°åˆ¸æŠ¥ä»·] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/admin/reset-init")
async def reset_initialization(
    current_user: dict = Depends(get_current_user),
):
    """ç®¡ç†ç«¯ç‚¹ï¼šé‡ç½®å€ºåˆ¸æ•°æ®åˆå§‹åŒ–çŠ¶æ€
    
    å½“æ•°æ®åˆå§‹åŒ–å‡ºç°é—®é¢˜æ—¶ï¼Œå¯ä»¥é€šè¿‡æ­¤ç«¯ç‚¹æ‰‹åŠ¨é‡ç½®åˆå§‹åŒ–çŠ¶æ€ï¼Œ
    å…è®¸ç³»ç»Ÿé‡æ–°ä»AKShareè·å–æ•°æ®ã€‚
    
    æ³¨æ„ï¼šä»…ç®¡ç†å‘˜åº”è¯¥ä½¿ç”¨æ­¤ç«¯ç‚¹
    """
    global _init_completed, _init_timestamp, _init_in_progress
    
    try:
        logger.warning(f"âš ï¸ [ç®¡ç†] ç”¨æˆ· {current_user.get('username')} è¯·æ±‚é‡ç½®åˆå§‹åŒ–çŠ¶æ€")
        
        old_status = {
            "completed": _init_completed,
            "timestamp": _init_timestamp.isoformat() if _init_timestamp else None,
            "in_progress": _init_in_progress
        }
        
        # é‡ç½®çŠ¶æ€
        _init_completed = False
        _init_timestamp = None
        # ä¸é‡ç½® _init_in_progressï¼Œé¿å…å¹²æ‰°æ­£åœ¨è¿›è¡Œçš„åˆå§‹åŒ–
        
        logger.info(f"âœ… [ç®¡ç†] åˆå§‹åŒ–çŠ¶æ€å·²é‡ç½®")
        
        return {
            "success": True,
            "message": "åˆå§‹åŒ–çŠ¶æ€å·²é‡ç½®ï¼Œä¸‹æ¬¡æŸ¥è¯¢å°†é‡æ–°è·å–æ•°æ®",
            "old_status": old_status,
            "new_status": {
                "completed": _init_completed,
                "timestamp": None,
                "in_progress": _init_in_progress
            }
        }
    
    except Exception as e:
        logger.error(f"âŒ [ç®¡ç†] é‡ç½®åˆå§‹åŒ–çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== å€ºåˆ¸åŸºç¡€ä¿¡æ¯æ‰¹é‡æ›´æ–°API ====================

@router.post("/basic-info/batch-update")
async def start_bond_basic_batch_update(
    batch_size: int = Query(1000, ge=100, le=5000, description="æ¯æ‰¹å¤„ç†çš„æ•°é‡"),
    concurrent_threads: int = Query(3, ge=1, le=10, description="å¹¶å‘çº¿ç¨‹æ•°"),
    save_interval: int = Query(1000, ge=500, le=2000, description="ä¿å­˜é—´éš”"),
    current_user: dict = Depends(get_current_user),
):
    """
    å¯åŠ¨å€ºåˆ¸åŸºç¡€ä¿¡æ¯æ‰¹é‡æ›´æ–°
    
    ä»bond_info_cmè¡¨æŸ¥è¯¢å€ºåˆ¸ç®€ç§°ï¼Œç„¶åè·å–è¯¦ç»†ä¿¡æ¯æ›´æ–°åˆ°bond_info_detail_cmä¸­ã€‚
    é‡‡ç”¨å¤šçº¿ç¨‹æ‰¹é‡æ›´æ–°ï¼Œæ¯è·å–æŒ‡å®šæ•°é‡çš„æ•°æ®ä¿å­˜åˆ°é›†åˆä¸€æ¬¡ã€‚
    """
    try:
        from app.services.bond_basic_info_service import BondBasicInfoService
        
        db = get_mongo_db()
        service = BondBasicInfoService(db)
        
        logger.info(f"ğŸš€ [æ‰¹é‡æ›´æ–°API] ç”¨æˆ· {current_user.get('username')} å¯åŠ¨å€ºåˆ¸åŸºç¡€ä¿¡æ¯æ‰¹é‡æ›´æ–°")
        logger.info(f"ğŸ“Š [æ‰¹é‡æ›´æ–°API] å‚æ•°: batch_size={batch_size}, threads={concurrent_threads}, save_interval={save_interval}")
        
        # æ‰§è¡Œæ‰¹é‡æ›´æ–°
        result = await service.batch_update_from_bond_info_cm(
            batch_size=batch_size,
            concurrent_threads=concurrent_threads,
            save_interval=save_interval
        )
        
        if result.get("success"):
            logger.info(f"âœ… [æ‰¹é‡æ›´æ–°API] æ‰¹é‡æ›´æ–°å®Œæˆ: {result.get('message')}")
            return {"success": True, "data": result}
        else:
            logger.error(f"âŒ [æ‰¹é‡æ›´æ–°API] æ‰¹é‡æ›´æ–°å¤±è´¥: {result.get('error')}")
            raise HTTPException(status_code=500, detail=result.get("error"))
            
    except Exception as e:
        logger.error(f"âŒ [æ‰¹é‡æ›´æ–°API] æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/basic-info/incremental-update")
async def start_bond_basic_incremental_update(
    current_user: dict = Depends(get_current_user),
):
    """
    å¯åŠ¨å€ºåˆ¸åŸºç¡€ä¿¡æ¯å¢é‡æ›´æ–°
    
    ä»bond_info_cmé›†åˆä¸­æŸ¥è¯¢å€ºåˆ¸ç®€ç§°ï¼Œç„¶åä»bond_info_detail_cmé›†åˆä¸­è·å–å·²æœ‰çš„å€ºåˆ¸ä»£ç ï¼Œ
    æ‰¾å‡ºç¼ºå¤±çš„å€ºåˆ¸åŸºç¡€ä¿¡æ¯å¹¶æ›´æ–°åˆ°é›†åˆä¸­ã€‚
    """
    try:
        from app.services.bond_basic_info_service import BondBasicInfoService
        
        db = get_mongo_db()
        service = BondBasicInfoService(db)
        
        logger.info(f"ğŸ” [å¢é‡æ›´æ–°API] ç”¨æˆ· {current_user.get('username')} å¯åŠ¨å€ºåˆ¸åŸºç¡€ä¿¡æ¯å¢é‡æ›´æ–°")
        
        # æ‰§è¡Œå¢é‡æ›´æ–°
        result = await service.incremental_update_missing_info()
        
        if result.get("success"):
            logger.info(f"âœ… [å¢é‡æ›´æ–°API] å¢é‡æ›´æ–°å®Œæˆ: {result.get('message')}")
            return {"success": True, "data": result}
        else:
            logger.error(f"âŒ [å¢é‡æ›´æ–°API] å¢é‡æ›´æ–°å¤±è´¥: {result.get('error')}")
            raise HTTPException(status_code=500, detail=result.get("error"))
            
    except Exception as e:
        logger.error(f"âŒ [å¢é‡æ›´æ–°API] æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/basic-info/update-statistics")
async def get_bond_basic_update_statistics(
    current_user: dict = Depends(get_current_user),
):
    """
    è·å–å€ºåˆ¸åŸºç¡€ä¿¡æ¯æ›´æ–°ç»Ÿè®¡
    
    è¿”å›bond_info_cmå’Œbond_info_detail_cmçš„è®°å½•æ•°é‡ã€è¦†ç›–ç‡ç­‰ç»Ÿè®¡ä¿¡æ¯ã€‚
    """
    try:
        from app.services.bond_basic_info_service import BondBasicInfoService
        
        db = get_mongo_db()
        service = BondBasicInfoService(db)
        
        logger.debug(f"ğŸ“Š [ç»Ÿè®¡API] ç”¨æˆ· {current_user.get('username')} æŸ¥è¯¢å€ºåˆ¸åŸºç¡€ä¿¡æ¯æ›´æ–°ç»Ÿè®¡")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        result = await service.get_update_statistics()
        
        if result.get("success"):
            return {"success": True, "data": result}
        else:
            logger.error(f"âŒ [ç»Ÿè®¡API] è·å–ç»Ÿè®¡å¤±è´¥: {result.get('error')}")
            raise HTTPException(status_code=500, detail=result.get("error"))
            
    except Exception as e:
        logger.error(f"âŒ [ç»Ÿè®¡API] æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 03å·éœ€æ±‚ï¼šæ²ªæ·±å€ºåˆ¸å®æ—¶è¡Œæƒ… ====================

@router.get("/zh-hs-spot")
async def get_bond_zh_hs_spot(
    q: Optional[str] = Query(None, description="å…³é”®è¯è¿‡æ»¤ï¼ˆä»£ç æˆ–åç§°ï¼‰"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(100, ge=1, le=500, description="æ¯é¡µæ•°é‡"),
    sort_by: Optional[str] = Query("æ¶¨è·Œå¹…", description="æ’åºå­—æ®µ"),
    sort_dir: str = Query("desc", description="æ’åºæ–¹å‘ï¼šasc|desc"),
    current_user: dict = Depends(get_current_user),
):
    """
    è·å–æ²ªæ·±å€ºåˆ¸å®æ—¶è¡Œæƒ…æ•°æ®
    
    - æ”¯æŒå…³é”®è¯æœç´¢
    - æ”¯æŒåˆ†é¡µ
    - æ”¯æŒæŒ‰æ¶¨è·Œå¹…ã€æˆäº¤é‡ã€æˆäº¤é¢ç­‰æ’åº
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ” [æ²ªæ·±å€ºåˆ¸å®æ—¶è¡Œæƒ…] æŸ¥è¯¢è¯·æ±‚: q={q}, page={page}, sort_by={sort_by}")
        
        # æŸ¥è¯¢æ•°æ®
        result = await svc.query_bond_zh_hs_spot(
            q=q,
            page=page,
            page_size=page_size,
            sort_by=sort_by,
            sort_dir=sort_dir
        )
        
        logger.info(f"âœ… [æ²ªæ·±å€ºåˆ¸å®æ—¶è¡Œæƒ…] æŸ¥è¯¢æˆåŠŸ: total={result['total']}, items={len(result['items'])}")
        return {"success": True, "data": result}
        
    except Exception as e:
        logger.error(f"âŒ [æ²ªæ·±å€ºåˆ¸å®æ—¶è¡Œæƒ…] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/zh-hs-spot/refresh")
async def refresh_bond_zh_hs_spot(
    start_page: int = Query(1, ge=1, description="å¼€å§‹é¡µç "),
    end_page: int = Query(5, ge=1, le=50, description="ç»“æŸé¡µç "),
    current_user: dict = Depends(get_current_user),
):
    """
    åˆ·æ–°æ²ªæ·±å€ºåˆ¸å®æ—¶è¡Œæƒ…æ•°æ®
    
    - ä»AKShareè·å–æŒ‡å®šé¡µé¢èŒƒå›´çš„å®æ—¶è¡Œæƒ…
    - æ¯é¡µ80æ¡æ•°æ®
    - ä½¿ç”¨ä»£ç ä½œä¸ºå”¯ä¸€æ ‡è¯†è¿›è¡Œupsert
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [æ²ªæ·±å€ºåˆ¸å®æ—¶è¡Œæƒ…] å¼€å§‹åˆ·æ–°: page {start_page}-{end_page}")
        
        # è·å–æ•°æ®
        try:
            import akshare as ak
            df = ak.bond_zh_hs_spot(start_page=str(start_page), end_page=str(end_page))
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ [æ²ªæ·±å€ºåˆ¸å®æ—¶è¡Œæƒ…] AKShareè¿”å›ç©ºæ•°æ®")
                return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            data = df.to_dict('records')
            logger.info(f"ğŸ“¡ [æ²ªæ·±å€ºåˆ¸å®æ—¶è¡Œæƒ…] ä»AKShareè·å–{len(data)}æ¡æ•°æ®")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = await svc.save_bond_zh_hs_spot(data)
            
            logger.info(f"âœ… [æ²ªæ·±å€ºåˆ¸å®æ—¶è¡Œæƒ…] åˆ·æ–°å®Œæˆ: ä¿å­˜{saved_count}æ¡")
            return {
                "success": True,
                "data": {
                    "fetched": len(data),
                    "saved": saved_count,
                    "start_page": start_page,
                    "end_page": end_page
                }
            }
            
        except Exception as ak_error:
            logger.error(f"âŒ [æ²ªæ·±å€ºåˆ¸å®æ—¶è¡Œæƒ…] AKShareè·å–å¤±è´¥: {ak_error}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"æ•°æ®è·å–å¤±è´¥: {str(ak_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [æ²ªæ·±å€ºåˆ¸å®æ—¶è¡Œæƒ…] åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 04å·éœ€æ±‚ï¼šæ²ªæ·±å€ºåˆ¸å†å²è¡Œæƒ… ====================

@router.get("/zh-hs-daily/{symbol}")
async def get_bond_zh_hs_daily(
    symbol: str,
    start_date: Optional[str] = Query(None, description="å¼€å§‹æ—¥æœŸ YYYY-MM-DD"),
    end_date: Optional[str] = Query(None, description="ç»“æŸæ—¥æœŸ YYYY-MM-DD"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(100, ge=1, le=1000, description="æ¯é¡µæ•°é‡"),
    current_user: dict = Depends(get_current_user),
):
    """
    è·å–æŒ‡å®šå€ºåˆ¸çš„å†å²è¡Œæƒ…æ•°æ®
    
    - æŒ‰æ—¥æœŸå€’åºè¿”å›
    - æ”¯æŒæ—¥æœŸèŒƒå›´ç­›é€‰
    - æ”¯æŒåˆ†é¡µ
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ” [æ²ªæ·±å€ºåˆ¸å†å²è¡Œæƒ…] æŸ¥è¯¢ {symbol}: {start_date} ~ {end_date}")
        
        # æŸ¥è¯¢æ•°æ®
        result = await svc.query_bond_zh_hs_daily(
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            page=page,
            page_size=page_size
        )
        
        logger.info(f"âœ… [æ²ªæ·±å€ºåˆ¸å†å²è¡Œæƒ…] {symbol} æŸ¥è¯¢æˆåŠŸ: total={result['total']}")
        return {"success": True, "data": result}
        
    except Exception as e:
        logger.error(f"âŒ [æ²ªæ·±å€ºåˆ¸å†å²è¡Œæƒ…] {symbol} æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/zh-hs-daily/{symbol}/refresh")
async def refresh_bond_zh_hs_daily(
    symbol: str,
    current_user: dict = Depends(get_current_user),
):
    """
    åˆ·æ–°æŒ‡å®šå€ºåˆ¸çš„å†å²è¡Œæƒ…æ•°æ®
    
    - ä»AKShareè·å–è¯¥å€ºåˆ¸çš„å…¨éƒ¨å†å²æ•°æ®
    - ä½¿ç”¨symbol+dateä½œä¸ºè”åˆä¸»é”®è¿›è¡Œupsert
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [æ²ªæ·±å€ºåˆ¸å†å²è¡Œæƒ…] å¼€å§‹åˆ·æ–° {symbol}")
        
        # è·å–æ•°æ®
        try:
            import akshare as ak
            df = ak.bond_zh_hs_daily(symbol=symbol)
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ [æ²ªæ·±å€ºåˆ¸å†å²è¡Œæƒ…] {symbol} AKShareè¿”å›ç©ºæ•°æ®")
                return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
            
            logger.info(f"ğŸ“¡ [æ²ªæ·±å€ºåˆ¸å†å²è¡Œæƒ…] {symbol} ä»AKShareè·å–{len(df)}æ¡æ•°æ®")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = await svc.save_bond_zh_hs_daily(symbol, df)
            
            logger.info(f"âœ… [æ²ªæ·±å€ºåˆ¸å†å²è¡Œæƒ…] {symbol} åˆ·æ–°å®Œæˆ: ä¿å­˜{saved_count}æ¡")
            return {
                "success": True,
                "data": {
                    "symbol": symbol,
                    "fetched": len(df),
                    "saved": saved_count
                }
            }
            
        except Exception as ak_error:
            logger.error(f"âŒ [æ²ªæ·±å€ºåˆ¸å†å²è¡Œæƒ…] {symbol} AKShareè·å–å¤±è´¥: {ak_error}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"æ•°æ®è·å–å¤±è´¥: {str(ak_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [æ²ªæ·±å€ºåˆ¸å†å²è¡Œæƒ…] {symbol} åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/zh-hs-daily/batch-refresh")
async def batch_refresh_bond_zh_hs_daily(
    symbols: list[str] = Query(..., description="å€ºåˆ¸ä»£ç åˆ—è¡¨"),
    current_user: dict = Depends(get_current_user),
):
    """
    æ‰¹é‡åˆ·æ–°å¤šä¸ªå€ºåˆ¸çš„å†å²è¡Œæƒ…æ•°æ®
    
    - ä¾æ¬¡è·å–æ¯ä¸ªå€ºåˆ¸çš„å†å²æ•°æ®
    - è¿”å›æˆåŠŸå’Œå¤±è´¥çš„ç»Ÿè®¡
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [æ²ªæ·±å€ºåˆ¸å†å²è¡Œæƒ…] æ‰¹é‡åˆ·æ–° {len(symbols)} ä¸ªå€ºåˆ¸")
        
        results = {"success": [], "failed": []}
        
        import akshare as ak
        import asyncio
        
        for symbol in symbols:
            try:
                # è·å–æ•°æ®
                df = ak.bond_zh_hs_daily(symbol=symbol)
                
                if df is None or df.empty:
                    results["failed"].append({"symbol": symbol, "error": "æ— æ•°æ®"})
                    continue
                
                # ä¿å­˜æ•°æ®
                saved_count = await svc.save_bond_zh_hs_daily(symbol, df)
                results["success"].append({"symbol": symbol, "count": saved_count})
                
                # é¿å…APIé™æµ
                await asyncio.sleep(0.5)
                
            except Exception as e:
                logger.error(f"âŒ [æ‰¹é‡åˆ·æ–°] {symbol} å¤±è´¥: {e}")
                results["failed"].append({"symbol": symbol, "error": str(e)})
        
        logger.info(f"âœ… [æ²ªæ·±å€ºåˆ¸å†å²è¡Œæƒ…] æ‰¹é‡åˆ·æ–°å®Œæˆ: æˆåŠŸ{len(results['success'])}, å¤±è´¥{len(results['failed'])}")
        return {"success": True, "data": results}
        
    except Exception as e:
        logger.error(f"âŒ [æ²ªæ·±å€ºåˆ¸å†å²è¡Œæƒ…] æ‰¹é‡åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 05å·éœ€æ±‚ï¼šå¯è½¬å€ºå®æ—¶è¡Œæƒ…-æ²ªæ·± ====================

@router.get("/zh-hs-cov-spot")
async def get_bond_zh_hs_cov_spot(
    q: Optional[str] = Query(None, description="å…³é”®è¯è¿‡æ»¤ï¼ˆä»£ç æˆ–åç§°ï¼‰"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(100, ge=1, le=500, description="æ¯é¡µæ•°é‡"),
    sort_by: Optional[str] = Query("changepercent", description="æ’åºå­—æ®µ"),
    sort_dir: str = Query("desc", description="æ’åºæ–¹å‘ï¼šasc|desc"),
    current_user: dict = Depends(get_current_user),
):
    """
    è·å–å¯è½¬å€ºå®æ—¶è¡Œæƒ…æ•°æ®
    
    - æ”¯æŒå…³é”®è¯æœç´¢ï¼ˆä»£ç ã€åç§°ã€symbolï¼‰
    - æ”¯æŒåˆ†é¡µ
    - æ”¯æŒæŒ‰æ¶¨è·Œå¹…ã€æˆäº¤é¢ç­‰æ’åº
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ” [å¯è½¬å€ºå®æ—¶è¡Œæƒ…] æŸ¥è¯¢è¯·æ±‚: q={q}, page={page}, sort_by={sort_by}")
        
        # æŸ¥è¯¢æ•°æ®
        result = await svc.query_bond_zh_hs_cov_spot(
            q=q,
            page=page,
            page_size=page_size,
            sort_by=sort_by,
            sort_dir=sort_dir
        )
        
        logger.info(f"âœ… [å¯è½¬å€ºå®æ—¶è¡Œæƒ…] æŸ¥è¯¢æˆåŠŸ: total={result['total']}, items={len(result['items'])}")
        return {"success": True, "data": result}
        
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºå®æ—¶è¡Œæƒ…] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/zh-hs-cov-spot/refresh")
async def refresh_bond_zh_hs_cov_spot(
    current_user: dict = Depends(get_current_user),
):
    """
    åˆ·æ–°å¯è½¬å€ºå®æ—¶è¡Œæƒ…æ•°æ®
    
    - ä»AKShareè·å–æ‰€æœ‰å¯è½¬å€ºçš„å®æ—¶è¡Œæƒ…
    - ä½¿ç”¨codeä½œä¸ºå”¯ä¸€æ ‡è¯†è¿›è¡Œupsert
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [å¯è½¬å€ºå®æ—¶è¡Œæƒ…] å¼€å§‹åˆ·æ–°")
        
        # è·å–æ•°æ®
        try:
            import akshare as ak
            df = ak.bond_zh_hs_cov_spot()
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ [å¯è½¬å€ºå®æ—¶è¡Œæƒ…] AKShareè¿”å›ç©ºæ•°æ®")
                return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            data = df.to_dict('records')
            logger.info(f"ğŸ“¡ [å¯è½¬å€ºå®æ—¶è¡Œæƒ…] ä»AKShareè·å–{len(data)}æ¡æ•°æ®")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = await svc.save_bond_zh_hs_cov_spot(data)
            
            logger.info(f"âœ… [å¯è½¬å€ºå®æ—¶è¡Œæƒ…] åˆ·æ–°å®Œæˆ: ä¿å­˜{saved_count}æ¡")
            return {
                "success": True,
                "data": {
                    "fetched": len(data),
                    "saved": saved_count
                }
            }
            
        except Exception as ak_error:
            logger.error(f"âŒ [å¯è½¬å€ºå®æ—¶è¡Œæƒ…] AKShareè·å–å¤±è´¥: {ak_error}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"æ•°æ®è·å–å¤±è´¥: {str(ak_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºå®æ—¶è¡Œæƒ…] åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 06å·éœ€æ±‚ï¼šå¯è½¬å€ºå†å²è¡Œæƒ…-æ—¥é¢‘ ====================

@router.get("/zh-hs-cov-daily/{symbol}")
async def get_bond_zh_hs_cov_daily(
    symbol: str,
    start_date: Optional[str] = Query(None, description="å¼€å§‹æ—¥æœŸ YYYY-MM-DD"),
    end_date: Optional[str] = Query(None, description="ç»“æŸæ—¥æœŸ YYYY-MM-DD"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(100, ge=1, le=1000, description="æ¯é¡µæ•°é‡"),
    current_user: dict = Depends(get_current_user),
):
    """
    è·å–æŒ‡å®šå¯è½¬å€ºçš„å†å²è¡Œæƒ…æ•°æ®
    
    - æŒ‰æ—¥æœŸå€’åºè¿”å›
    - æ”¯æŒæ—¥æœŸèŒƒå›´ç­›é€‰
    - æ”¯æŒåˆ†é¡µ
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ” [å¯è½¬å€ºå†å²è¡Œæƒ…] æŸ¥è¯¢ {symbol}: {start_date} ~ {end_date}")
        
        # æŸ¥è¯¢æ•°æ®
        result = await svc.query_bond_zh_hs_cov_daily(
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            page=page,
            page_size=page_size
        )
        
        logger.info(f"âœ… [å¯è½¬å€ºå†å²è¡Œæƒ…] {symbol} æŸ¥è¯¢æˆåŠŸ: total={result['total']}")
        return {"success": True, "data": result}
        
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºå†å²è¡Œæƒ…] {symbol} æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/zh-hs-cov-daily/{symbol}/refresh")
async def refresh_bond_zh_hs_cov_daily(
    symbol: str,
    current_user: dict = Depends(get_current_user),
):
    """
    åˆ·æ–°æŒ‡å®šå¯è½¬å€ºçš„å†å²è¡Œæƒ…æ•°æ®
    
    - ä»AKShareè·å–è¯¥å¯è½¬å€ºçš„å…¨éƒ¨å†å²æ•°æ®
    - ä½¿ç”¨symbol+dateä½œä¸ºè”åˆä¸»é”®è¿›è¡Œupsert
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [å¯è½¬å€ºå†å²è¡Œæƒ…] å¼€å§‹åˆ·æ–° {symbol}")
        
        # è·å–æ•°æ®
        try:
            import akshare as ak
            df = ak.bond_zh_hs_cov_daily(symbol=symbol)
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ [å¯è½¬å€ºå†å²è¡Œæƒ…] {symbol} AKShareè¿”å›ç©ºæ•°æ®")
                return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
            
            logger.info(f"ğŸ“¡ [å¯è½¬å€ºå†å²è¡Œæƒ…] {symbol} ä»AKShareè·å–{len(df)}æ¡æ•°æ®")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = await svc.save_bond_zh_hs_cov_daily(symbol, df)
            
            logger.info(f"âœ… [å¯è½¬å€ºå†å²è¡Œæƒ…] {symbol} åˆ·æ–°å®Œæˆ: ä¿å­˜{saved_count}æ¡")
            return {
                "success": True,
                "data": {
                    "symbol": symbol,
                    "fetched": len(df),
                    "saved": saved_count
                }
            }
            
        except Exception as ak_error:
            logger.error(f"âŒ [å¯è½¬å€ºå†å²è¡Œæƒ…] {symbol} AKShareè·å–å¤±è´¥: {ak_error}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"æ•°æ®è·å–å¤±è´¥: {str(ak_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºå†å²è¡Œæƒ…] {symbol} åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/zh-hs-cov-daily/batch-refresh")
async def batch_refresh_bond_zh_hs_cov_daily(
    symbols: list[str] = Query(..., description="å¯è½¬å€ºä»£ç åˆ—è¡¨"),
    current_user: dict = Depends(get_current_user),
):
    """
    æ‰¹é‡åˆ·æ–°å¤šä¸ªå¯è½¬å€ºçš„å†å²è¡Œæƒ…æ•°æ®
    
    - ä¾æ¬¡è·å–æ¯ä¸ªå¯è½¬å€ºçš„å†å²æ•°æ®
    - è¿”å›æˆåŠŸå’Œå¤±è´¥çš„ç»Ÿè®¡
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [å¯è½¬å€ºå†å²è¡Œæƒ…] æ‰¹é‡åˆ·æ–° {len(symbols)} ä¸ªå¯è½¬å€º")
        
        results = {"success": [], "failed": []}
        
        import akshare as ak
        import asyncio
        
        for symbol in symbols:
            try:
                # è·å–æ•°æ®
                df = ak.bond_zh_hs_cov_daily(symbol=symbol)
                
                if df is None or df.empty:
                    results["failed"].append({"symbol": symbol, "error": "æ— æ•°æ®"})
                    continue
                
                # ä¿å­˜æ•°æ®
                saved_count = await svc.save_bond_zh_hs_cov_daily(symbol, df)
                results["success"].append({"symbol": symbol, "count": saved_count})
                
                # é¿å…APIé™æµ
                await asyncio.sleep(0.5)
                
            except Exception as e:
                logger.error(f"âŒ [æ‰¹é‡åˆ·æ–°] {symbol} å¤±è´¥: {e}")
                results["failed"].append({"symbol": symbol, "error": str(e)})
        
        logger.info(f"âœ… [å¯è½¬å€ºå†å²è¡Œæƒ…] æ‰¹é‡åˆ·æ–°å®Œæˆ: æˆåŠŸ{len(results['success'])}, å¤±è´¥{len(results['failed'])}")
        return {"success": True, "data": results}
        
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºå†å²è¡Œæƒ…] æ‰¹é‡åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 07å·éœ€æ±‚ï¼šå¯è½¬å€ºæ•°æ®ä¸€è§ˆè¡¨-ä¸œè´¢ ====================

@router.get("/zh-cov")
async def get_bond_zh_cov(
    q: Optional[str] = Query(None, description="å…³é”®è¯è¿‡æ»¤ï¼ˆä»£ç æˆ–åç§°ï¼‰"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(100, ge=1, le=500, description="æ¯é¡µæ•°é‡"),
    sort_by: Optional[str] = Query("è½¬è‚¡æº¢ä»·ç‡", description="æ’åºå­—æ®µ"),
    sort_dir: str = Query("asc", description="æ’åºæ–¹å‘ï¼šasc|desc"),
    current_user: dict = Depends(get_current_user),
):
    """
    è·å–å¯è½¬å€ºæ•°æ®ä¸€è§ˆè¡¨ï¼ˆä¸œè´¢ï¼‰
    
    - æ”¯æŒå…³é”®è¯æœç´¢ï¼ˆå€ºåˆ¸ä»£ç ã€å€ºåˆ¸ç®€ç§°ã€æ­£è‚¡ä»£ç ã€æ­£è‚¡ç®€ç§°ï¼‰
    - æ”¯æŒåˆ†é¡µ
    - æ”¯æŒæŒ‰è½¬è‚¡æº¢ä»·ç‡ã€å‘è¡Œè§„æ¨¡ç­‰æ’åº
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ” [å¯è½¬å€ºä¸€è§ˆè¡¨] æŸ¥è¯¢è¯·æ±‚: q={q}, page={page}, sort_by={sort_by}")
        
        # æŸ¥è¯¢æ•°æ®
        result = await svc.query_bond_zh_cov(
            q=q,
            page=page,
            page_size=page_size,
            sort_by=sort_by,
            sort_dir=sort_dir
        )
        
        logger.info(f"âœ… [å¯è½¬å€ºä¸€è§ˆè¡¨] æŸ¥è¯¢æˆåŠŸ: total={result['total']}, items={len(result['items'])}")
        return {"success": True, "data": result}
        
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºä¸€è§ˆè¡¨] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/zh-cov/refresh")
async def refresh_bond_zh_cov(
    current_user: dict = Depends(get_current_user),
):
    """
    åˆ·æ–°å¯è½¬å€ºæ•°æ®ä¸€è§ˆè¡¨
    
    - ä»AKShareè·å–ä¸œè´¢çš„æ‰€æœ‰å¯è½¬å€ºä¸€è§ˆæ•°æ®
    - ä½¿ç”¨å€ºåˆ¸ä»£ç ä½œä¸ºå”¯ä¸€æ ‡è¯†è¿›è¡Œupsert
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [å¯è½¬å€ºä¸€è§ˆè¡¨] å¼€å§‹åˆ·æ–°")
        
        # è·å–æ•°æ®
        try:
            import akshare as ak
            df = ak.bond_zh_cov()
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ [å¯è½¬å€ºä¸€è§ˆè¡¨] AKShareè¿”å›ç©ºæ•°æ®")
                return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            data = df.to_dict('records')
            logger.info(f"ğŸ“¡ [å¯è½¬å€ºä¸€è§ˆè¡¨] ä»AKShareè·å–{len(data)}æ¡æ•°æ®")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = await svc.save_bond_zh_cov(data)
            
            logger.info(f"âœ… [å¯è½¬å€ºä¸€è§ˆè¡¨] åˆ·æ–°å®Œæˆ: ä¿å­˜{saved_count}æ¡")
            return {
                "success": True,
                "data": {
                    "fetched": len(data),
                    "saved": saved_count
                }
            }
            
        except Exception as ak_error:
            logger.error(f"âŒ [å¯è½¬å€ºä¸€è§ˆè¡¨] AKShareè·å–å¤±è´¥: {ak_error}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"æ•°æ®è·å–å¤±è´¥: {str(ak_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºä¸€è§ˆè¡¨] åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 08å·éœ€æ±‚ï¼šå€ºåˆ¸ç°åˆ¸å¸‚åœºæ¦‚è§ˆ-ä¸Šäº¤æ‰€ ====================

@router.get("/cash-summary-sse")
async def get_bond_cash_summary_sse(
    date: Optional[str] = Query(None, description="æ•°æ®æ—¥æœŸ YYYY-MM-DD"),
    bond_type: Optional[str] = Query(None, description="å€ºåˆ¸ç±»å‹"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(100, ge=1, le=500, description="æ¯é¡µæ•°é‡"),
    current_user: dict = Depends(get_current_user),
):
    """
    è·å–å€ºåˆ¸ç°åˆ¸å¸‚åœºæ¦‚è§ˆæ•°æ®ï¼ˆä¸Šäº¤æ‰€ï¼‰
    
    - æŒ‰æ—¥æœŸæŸ¥è¯¢å¸‚åœºæ¦‚è§ˆ
    - æ”¯æŒå€ºåˆ¸ç±»å‹ç­›é€‰
    - æ”¯æŒåˆ†é¡µ
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ” [ç°åˆ¸å¸‚åœºæ¦‚è§ˆ] æŸ¥è¯¢è¯·æ±‚: date={date}, bond_type={bond_type}")
        
        # æŸ¥è¯¢æ•°æ®
        result = await svc.query_bond_cash_summary_sse(
            date=date,
            bond_type=bond_type,
            page=page,
            page_size=page_size
        )
        
        logger.info(f"âœ… [ç°åˆ¸å¸‚åœºæ¦‚è§ˆ] æŸ¥è¯¢æˆåŠŸ: total={result['total']}, items={len(result['items'])}")
        return {"success": True, "data": result}
        
    except Exception as e:
        logger.error(f"âŒ [ç°åˆ¸å¸‚åœºæ¦‚è§ˆ] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/cash-summary-sse/refresh")
async def refresh_bond_cash_summary_sse(
    date: str = Query(..., description="æ•°æ®æ—¥æœŸï¼Œæ ¼å¼ï¼š20210111"),
    current_user: dict = Depends(get_current_user),
):
    """
    åˆ·æ–°æŒ‡å®šæ—¥æœŸçš„å€ºåˆ¸ç°åˆ¸å¸‚åœºæ¦‚è§ˆæ•°æ®
    
    - ä»AKShareè·å–æŒ‡å®šæ—¥æœŸçš„å¸‚åœºæ¦‚è§ˆæ•°æ®
    - ä½¿ç”¨å€ºåˆ¸ç±»å‹+æ—¥æœŸä½œä¸ºè”åˆä¸»é”®è¿›è¡Œupsert
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [ç°åˆ¸å¸‚åœºæ¦‚è§ˆ] å¼€å§‹åˆ·æ–° {date}")
        
        # è·å–æ•°æ®
        try:
            import akshare as ak
            df = ak.bond_cash_summary_sse(date=date)
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ [ç°åˆ¸å¸‚åœºæ¦‚è§ˆ] {date} AKShareè¿”å›ç©ºæ•°æ®")
                return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
            
            logger.info(f"ğŸ“¡ [ç°åˆ¸å¸‚åœºæ¦‚è§ˆ] {date} ä»AKShareè·å–{len(df)}æ¡æ•°æ®")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = await svc.save_bond_cash_summary_sse(date, df)
            
            logger.info(f"âœ… [ç°åˆ¸å¸‚åœºæ¦‚è§ˆ] {date} åˆ·æ–°å®Œæˆ: ä¿å­˜{saved_count}æ¡")
            return {
                "success": True,
                "data": {
                    "date": date,
                    "fetched": len(df),
                    "saved": saved_count
                }
            }
            
        except Exception as ak_error:
            logger.error(f"âŒ [ç°åˆ¸å¸‚åœºæ¦‚è§ˆ] {date} AKShareè·å–å¤±è´¥: {ak_error}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"æ•°æ®è·å–å¤±è´¥: {str(ak_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [ç°åˆ¸å¸‚åœºæ¦‚è§ˆ] {date} åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/cash-summary-sse/batch-refresh")
async def batch_refresh_bond_cash_summary_sse(
    start_date: str = Query(..., description="å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ï¼š20210101"),
    end_date: str = Query(..., description="ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ï¼š20210131"),
    current_user: dict = Depends(get_current_user),
):
    """
    æ‰¹é‡åˆ·æ–°æ—¥æœŸèŒƒå›´å†…çš„å€ºåˆ¸ç°åˆ¸å¸‚åœºæ¦‚è§ˆæ•°æ®
    
    - ä¾æ¬¡è·å–æ—¥æœŸèŒƒå›´å†…æ¯ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
    - è¿”å›æˆåŠŸå’Œå¤±è´¥çš„ç»Ÿè®¡
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [ç°åˆ¸å¸‚åœºæ¦‚è§ˆ] æ‰¹é‡åˆ·æ–° {start_date} ~ {end_date}")
        
        results = {"success": [], "failed": []}
        
        import akshare as ak
        import asyncio
        from datetime import datetime, timedelta
        
        # ç”Ÿæˆæ—¥æœŸåˆ—è¡¨
        start = datetime.strptime(start_date, "%Y%m%d")
        end = datetime.strptime(end_date, "%Y%m%d")
        date_list = []
        current = start
        while current <= end:
            date_list.append(current.strftime("%Y%m%d"))
            current += timedelta(days=1)
        
        for date in date_list:
            try:
                # è·å–æ•°æ®
                df = ak.bond_cash_summary_sse(date=date)
                
                if df is None or df.empty:
                    results["failed"].append({"date": date, "error": "æ— æ•°æ®"})
                    continue
                
                # ä¿å­˜æ•°æ®
                saved_count = await svc.save_bond_cash_summary_sse(date, df)
                results["success"].append({"date": date, "count": saved_count})
                
                # é¿å…APIé™æµ
                await asyncio.sleep(0.2)
                
            except Exception as e:
                logger.error(f"âŒ [æ‰¹é‡åˆ·æ–°] {date} å¤±è´¥: {e}")
                results["failed"].append({"date": date, "error": str(e)})
        
        logger.info(f"âœ… [ç°åˆ¸å¸‚åœºæ¦‚è§ˆ] æ‰¹é‡åˆ·æ–°å®Œæˆ: æˆåŠŸ{len(results['success'])}, å¤±è´¥{len(results['failed'])}")
        return {"success": True, "data": results}
        
    except Exception as e:
        logger.error(f"âŒ [ç°åˆ¸å¸‚åœºæ¦‚è§ˆ] æ‰¹é‡åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 09å·éœ€æ±‚ï¼šå€ºåˆ¸æˆäº¤æ¦‚è§ˆ-ä¸Šäº¤æ‰€ ====================

@router.get("/deal-summary-sse")
async def get_bond_deal_summary_sse(
    date: Optional[str] = Query(None, description="æ•°æ®æ—¥æœŸ YYYY-MM-DD"),
    bond_type: Optional[str] = Query(None, description="å€ºåˆ¸ç±»å‹"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(100, ge=1, le=500, description="æ¯é¡µæ•°é‡"),
    current_user: dict = Depends(get_current_user),
):
    """
    è·å–å€ºåˆ¸æˆäº¤æ¦‚è§ˆæ•°æ®ï¼ˆä¸Šäº¤æ‰€ï¼‰
    
    - æŒ‰æ—¥æœŸæŸ¥è¯¢æˆäº¤æ¦‚è§ˆ
    - æ”¯æŒå€ºåˆ¸ç±»å‹ç­›é€‰
    - åŒ…å«å½“æ—¥æˆäº¤å’Œå½“å¹´ç´¯è®¡æˆäº¤æ•°æ®
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ” [å€ºåˆ¸æˆäº¤æ¦‚è§ˆ] æŸ¥è¯¢è¯·æ±‚: date={date}, bond_type={bond_type}")
        
        # æŸ¥è¯¢æ•°æ®
        result = await svc.query_bond_deal_summary_sse(
            date=date,
            bond_type=bond_type,
            page=page,
            page_size=page_size
        )
        
        logger.info(f"âœ… [å€ºåˆ¸æˆäº¤æ¦‚è§ˆ] æŸ¥è¯¢æˆåŠŸ: total={result['total']}, items={len(result['items'])}")
        return {"success": True, "data": result}
        
    except Exception as e:
        logger.error(f"âŒ [å€ºåˆ¸æˆäº¤æ¦‚è§ˆ] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/deal-summary-sse/refresh")
async def refresh_bond_deal_summary_sse(
    date: str = Query(..., description="æ•°æ®æ—¥æœŸï¼Œæ ¼å¼ï¼š20210104"),
    current_user: dict = Depends(get_current_user),
):
    """
    åˆ·æ–°æŒ‡å®šæ—¥æœŸçš„å€ºåˆ¸æˆäº¤æ¦‚è§ˆæ•°æ®
    
    - ä»AKShareè·å–æŒ‡å®šæ—¥æœŸçš„æˆäº¤æ¦‚è§ˆæ•°æ®
    - ä½¿ç”¨å€ºåˆ¸ç±»å‹+æ—¥æœŸä½œä¸ºè”åˆä¸»é”®è¿›è¡Œupsert
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [å€ºåˆ¸æˆäº¤æ¦‚è§ˆ] å¼€å§‹åˆ·æ–° {date}")
        
        # è·å–æ•°æ®
        try:
            import akshare as ak
            df = ak.bond_deal_summary_sse(date=date)
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ [å€ºåˆ¸æˆäº¤æ¦‚è§ˆ] {date} AKShareè¿”å›ç©ºæ•°æ®")
                return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
            
            logger.info(f"ğŸ“¡ [å€ºåˆ¸æˆäº¤æ¦‚è§ˆ] {date} ä»AKShareè·å–{len(df)}æ¡æ•°æ®")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = await svc.save_bond_deal_summary_sse(date, df)
            
            logger.info(f"âœ… [å€ºåˆ¸æˆäº¤æ¦‚è§ˆ] {date} åˆ·æ–°å®Œæˆ: ä¿å­˜{saved_count}æ¡")
            return {
                "success": True,
                "data": {
                    "date": date,
                    "fetched": len(df),
                    "saved": saved_count
                }
            }
            
        except Exception as ak_error:
            logger.error(f"âŒ [å€ºåˆ¸æˆäº¤æ¦‚è§ˆ] {date} AKShareè·å–å¤±è´¥: {ak_error}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"æ•°æ®è·å–å¤±è´¥: {str(ak_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [å€ºåˆ¸æˆäº¤æ¦‚è§ˆ] {date} åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/deal-summary-sse/batch-refresh")
async def batch_refresh_bond_deal_summary_sse(
    start_date: str = Query(..., description="å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ï¼š20210101"),
    end_date: str = Query(..., description="ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ï¼š20210131"),
    current_user: dict = Depends(get_current_user),
):
    """
    æ‰¹é‡åˆ·æ–°æ—¥æœŸèŒƒå›´å†…çš„å€ºåˆ¸æˆäº¤æ¦‚è§ˆæ•°æ®
    
    - ä¾æ¬¡è·å–æ—¥æœŸèŒƒå›´å†…æ¯ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
    - è¿”å›æˆåŠŸå’Œå¤±è´¥çš„ç»Ÿè®¡
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [å€ºåˆ¸æˆäº¤æ¦‚è§ˆ] æ‰¹é‡åˆ·æ–° {start_date} ~ {end_date}")
        
        results = {"success": [], "failed": []}
        
        import akshare as ak
        import asyncio
        from datetime import datetime, timedelta
        
        # ç”Ÿæˆæ—¥æœŸåˆ—è¡¨
        start = datetime.strptime(start_date, "%Y%m%d")
        end = datetime.strptime(end_date, "%Y%m%d")
        date_list = []
        current = start
        while current <= end:
            date_list.append(current.strftime("%Y%m%d"))
            current += timedelta(days=1)
        
        for date in date_list:
            try:
                # è·å–æ•°æ®
                df = ak.bond_deal_summary_sse(date=date)
                
                if df is None or df.empty:
                    results["failed"].append({"date": date, "error": "æ— æ•°æ®"})
                    continue
                
                # ä¿å­˜æ•°æ®
                saved_count = await svc.save_bond_deal_summary_sse(date, df)
                results["success"].append({"date": date, "count": saved_count})
                
                # é¿å…APIé™æµ
                await asyncio.sleep(0.2)
                
            except Exception as e:
                logger.error(f"âŒ [æ‰¹é‡åˆ·æ–°] {date} å¤±è´¥: {e}")
                results["failed"].append({"date": date, "error": str(e)})
        
        logger.info(f"âœ… [å€ºåˆ¸æˆäº¤æ¦‚è§ˆ] æ‰¹é‡åˆ·æ–°å®Œæˆ: æˆåŠŸ{len(results['success'])}, å¤±è´¥{len(results['failed'])}")
        return {"success": True, "data": results}
        
    except Exception as e:
        logger.error(f"âŒ [å€ºåˆ¸æˆäº¤æ¦‚è§ˆ] æ‰¹é‡åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 10å·éœ€æ±‚ï¼šé“¶è¡Œé—´å¸‚åœºå€ºåˆ¸å‘è¡Œæ•°æ® ====================

@router.get("/debt-nafmii")
async def get_bond_debt_nafmii(
    q: Optional[str] = Query(None, description="å…³é”®è¯è¿‡æ»¤ï¼ˆå€ºåˆ¸åç§°ï¼‰"),
    bond_type: Optional[str] = Query(None, description="å“ç§ï¼ˆSCPã€MTNç­‰ï¼‰"),
    status: Optional[str] = Query(None, description="é¡¹ç›®çŠ¶æ€"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(100, ge=1, le=500, description="æ¯é¡µæ•°é‡"),
    sort_by: Optional[str] = Query("æ›´æ–°æ—¥æœŸ", description="æ’åºå­—æ®µ"),
    sort_dir: str = Query("desc", description="æ’åºæ–¹å‘ï¼šasc|desc"),
    current_user: dict = Depends(get_current_user),
):
    """
    è·å–é“¶è¡Œé—´å¸‚åœºå€ºåˆ¸å‘è¡Œæ•°æ®
    
    - æ”¯æŒæŒ‰å€ºåˆ¸åç§°æœç´¢
    - æ”¯æŒæŒ‰å“ç§ç­›é€‰ï¼ˆSCPã€MTNã€CPç­‰ï¼‰
    - æ”¯æŒæŒ‰é¡¹ç›®çŠ¶æ€ç­›é€‰
    - æ”¯æŒåˆ†é¡µå’Œæ’åº
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ” [é“¶è¡Œé—´å€ºåˆ¸å‘è¡Œ] æŸ¥è¯¢è¯·æ±‚: q={q}, type={bond_type}, status={status}")
        
        # æŸ¥è¯¢æ•°æ®
        result = await svc.query_bond_debt_nafmii(
            q=q,
            bond_type=bond_type,
            status=status,
            page=page,
            page_size=page_size,
            sort_by=sort_by,
            sort_dir=sort_dir
        )
        
        logger.info(f"âœ… [é“¶è¡Œé—´å€ºåˆ¸å‘è¡Œ] æŸ¥è¯¢æˆåŠŸ: total={result['total']}, items={len(result['items'])}")
        return {"success": True, "data": result}
        
    except Exception as e:
        logger.error(f"âŒ [é“¶è¡Œé—´å€ºåˆ¸å‘è¡Œ] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/debt-nafmii/refresh")
async def refresh_bond_debt_nafmii(
    page: int = Query(1, description="é¡µç ï¼Œæ¯é¡µ50æ¡æ•°æ®"),
    current_user: dict = Depends(get_current_user),
):
    """
    åˆ·æ–°æŒ‡å®šé¡µçš„é“¶è¡Œé—´å¸‚åœºå€ºåˆ¸å‘è¡Œæ•°æ®
    
    - ä»AKShareè·å–æŒ‡å®šé¡µçš„æ•°æ®ï¼ˆæ¯é¡µ50æ¡ï¼‰
    - ä½¿ç”¨å€ºåˆ¸åç§°+æ³¨å†Œé€šçŸ¥ä¹¦æ–‡å·ä½œä¸ºè”åˆä¸»é”®è¿›è¡Œupsert
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [é“¶è¡Œé—´å€ºåˆ¸å‘è¡Œ] å¼€å§‹åˆ·æ–°ç¬¬{page}é¡µ")
        
        # è·å–æ•°æ®
        try:
            import akshare as ak
            df = ak.bond_debt_nafmii(page=str(page))
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ [é“¶è¡Œé—´å€ºåˆ¸å‘è¡Œ] ç¬¬{page}é¡µ AKShareè¿”å›ç©ºæ•°æ®")
                return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
            
            logger.info(f"ğŸ“¡ [é“¶è¡Œé—´å€ºåˆ¸å‘è¡Œ] ç¬¬{page}é¡µ ä»AKShareè·å–{len(df)}æ¡æ•°æ®")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = await svc.save_bond_debt_nafmii(df)
            
            logger.info(f"âœ… [é“¶è¡Œé—´å€ºåˆ¸å‘è¡Œ] ç¬¬{page}é¡µ åˆ·æ–°å®Œæˆ: ä¿å­˜{saved_count}æ¡")
            return {
                "success": True,
                "data": {
                    "page": page,
                    "fetched": len(df),
                    "saved": saved_count
                }
            }
            
        except Exception as ak_error:
            logger.error(f"âŒ [é“¶è¡Œé—´å€ºåˆ¸å‘è¡Œ] ç¬¬{page}é¡µ AKShareè·å–å¤±è´¥: {ak_error}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"æ•°æ®è·å–å¤±è´¥: {str(ak_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [é“¶è¡Œé—´å€ºåˆ¸å‘è¡Œ] ç¬¬{page}é¡µ åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/debt-nafmii/batch-refresh")
async def batch_refresh_bond_debt_nafmii(
    start_page: int = Query(1, description="å¼€å§‹é¡µç "),
    end_page: int = Query(10, description="ç»“æŸé¡µç "),
    current_user: dict = Depends(get_current_user),
):
    """
    æ‰¹é‡åˆ·æ–°å¤šé¡µé“¶è¡Œé—´å¸‚åœºå€ºåˆ¸å‘è¡Œæ•°æ®
    
    - ä¾æ¬¡è·å–é¡µç èŒƒå›´å†…çš„æ•°æ®
    - æ¯é¡µ50æ¡æ•°æ®
    - è¿”å›æˆåŠŸå’Œå¤±è´¥çš„ç»Ÿè®¡
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [é“¶è¡Œé—´å€ºåˆ¸å‘è¡Œ] æ‰¹é‡åˆ·æ–° ç¬¬{start_page}-{end_page}é¡µ")
        
        results = {"success": [], "failed": []}
        
        import akshare as ak
        import asyncio
        
        for page in range(start_page, end_page + 1):
            try:
                # è·å–æ•°æ®
                df = ak.bond_debt_nafmii(page=str(page))
                
                if df is None or df.empty:
                    results["failed"].append({"page": page, "error": "æ— æ•°æ®"})
                    continue
                
                # ä¿å­˜æ•°æ®
                saved_count = await svc.save_bond_debt_nafmii(df)
                results["success"].append({"page": page, "count": saved_count})
                
                # é¿å…APIé™æµ
                await asyncio.sleep(0.2)
                
            except Exception as e:
                logger.error(f"âŒ [æ‰¹é‡åˆ·æ–°] ç¬¬{page}é¡µ å¤±è´¥: {e}")
                results["failed"].append({"page": page, "error": str(e)})
        
        logger.info(f"âœ… [é“¶è¡Œé—´å€ºåˆ¸å‘è¡Œ] æ‰¹é‡åˆ·æ–°å®Œæˆ: æˆåŠŸ{len(results['success'])}, å¤±è´¥{len(results['failed'])}")
        return {"success": True, "data": results}
        
    except Exception as e:
        logger.error(f"âŒ [é“¶è¡Œé—´å€ºåˆ¸å‘è¡Œ] æ‰¹é‡åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 11å·éœ€æ±‚ï¼šç°åˆ¸å¸‚åœºåšå¸‚æŠ¥ä»· ====================

@router.get("/spot-quote")
async def get_bond_spot_quote(
    q: Optional[str] = Query(None, description="å…³é”®è¯è¿‡æ»¤ï¼ˆå€ºåˆ¸ç®€ç§°ï¼‰"),
    organization: Optional[str] = Query(None, description="æŠ¥ä»·æœºæ„"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(100, ge=1, le=500, description="æ¯é¡µæ•°é‡"),
    sort_by: Optional[str] = Query("æ›´æ–°æ—¶é—´", description="æ’åºå­—æ®µ"),
    sort_dir: str = Query("desc", description="æ’åºæ–¹å‘ï¼šasc|desc"),
    current_user: dict = Depends(get_current_user),
):
    """
    è·å–ç°åˆ¸å¸‚åœºåšå¸‚æŠ¥ä»·æ•°æ®
    
    - æ”¯æŒæŒ‰å€ºåˆ¸ç®€ç§°æœç´¢
    - æ”¯æŒæŒ‰æŠ¥ä»·æœºæ„ç­›é€‰
    - åŒ…å«ä¹°å…¥å‡€ä»·ã€å–å‡ºå‡€ä»·ã€ä¹°å–ä»·å·®ç­‰
    - æ”¯æŒåˆ†é¡µå’Œæ’åº
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ” [ç°åˆ¸åšå¸‚æŠ¥ä»·] æŸ¥è¯¢è¯·æ±‚: q={q}, org={organization}")
        
        # æŸ¥è¯¢æ•°æ®
        result = await svc.query_bond_spot_quote(
            q=q,
            organization=organization,
            page=page,
            page_size=page_size,
            sort_by=sort_by,
            sort_dir=sort_dir
        )
        
        logger.info(f"âœ… [ç°åˆ¸åšå¸‚æŠ¥ä»·] æŸ¥è¯¢æˆåŠŸ: total={result['total']}, items={len(result['items'])}")
        return {"success": True, "data": result}
        
    except Exception as e:
        logger.error(f"âŒ [ç°åˆ¸åšå¸‚æŠ¥ä»·] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/spot-quote/refresh")
async def refresh_bond_spot_quote(
    current_user: dict = Depends(get_current_user),
):
    """
    åˆ·æ–°ç°åˆ¸å¸‚åœºåšå¸‚æŠ¥ä»·æ•°æ®
    
    - ä»AKShareè·å–æ‰€æœ‰åšå¸‚æŠ¥ä»·æ•°æ®
    - ä½¿ç”¨æŠ¥ä»·æœºæ„+å€ºåˆ¸ç®€ç§°ä½œä¸ºè”åˆä¸»é”®è¿›è¡Œupsert
    - è‡ªåŠ¨è®¡ç®—ä¹°å–ä»·å·®
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [ç°åˆ¸åšå¸‚æŠ¥ä»·] å¼€å§‹åˆ·æ–°")
        
        # è·å–æ•°æ®
        try:
            import akshare as ak
            df = ak.bond_spot_quote()
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ [ç°åˆ¸åšå¸‚æŠ¥ä»·] AKShareè¿”å›ç©ºæ•°æ®")
                return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
            
            logger.info(f"ğŸ“¡ [ç°åˆ¸åšå¸‚æŠ¥ä»·] ä»AKShareè·å–{len(df)}æ¡æ•°æ®")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = await svc.save_bond_spot_quote(df)
            
            logger.info(f"âœ… [ç°åˆ¸åšå¸‚æŠ¥ä»·] åˆ·æ–°å®Œæˆ: ä¿å­˜{saved_count}æ¡")
            return {
                "success": True,
                "data": {
                    "fetched": len(df),
                    "saved": saved_count
                }
            }
            
        except Exception as ak_error:
            logger.error(f"âŒ [ç°åˆ¸åšå¸‚æŠ¥ä»·] AKShareè·å–å¤±è´¥: {ak_error}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"æ•°æ®è·å–å¤±è´¥: {str(ak_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [ç°åˆ¸åšå¸‚æŠ¥ä»·] åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 12å·éœ€æ±‚ï¼šç°åˆ¸å¸‚åœºæˆäº¤è¡Œæƒ… ====================

@router.get("/spot-deal")
async def get_bond_spot_deal(
    q: Optional[str] = Query(None, description="å…³é”®è¯è¿‡æ»¤ï¼ˆå€ºåˆ¸ç®€ç§°ï¼‰"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(100, ge=1, le=500, description="æ¯é¡µæ•°é‡"),
    sort_by: Optional[str] = Query("äº¤æ˜“é‡", description="æ’åºå­—æ®µ"),
    sort_dir: str = Query("desc", description="æ’åºæ–¹å‘ï¼šasc|desc"),
    current_user: dict = Depends(get_current_user),
):
    """
    è·å–ç°åˆ¸å¸‚åœºæˆäº¤è¡Œæƒ…æ•°æ®
    
    - æ”¯æŒæŒ‰å€ºåˆ¸ç®€ç§°æœç´¢
    - åŒ…å«æˆäº¤å‡€ä»·ã€æœ€æ–°æ”¶ç›Šç‡ã€æ¶¨è·Œï¼ˆBPï¼‰ã€åŠ æƒæ”¶ç›Šç‡ã€äº¤æ˜“é‡ç­‰
    - æ”¯æŒæŒ‰äº¤æ˜“é‡ã€æ¶¨è·Œç­‰æ’åº
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ” [ç°åˆ¸æˆäº¤è¡Œæƒ…] æŸ¥è¯¢è¯·æ±‚: q={q}")
        
        # æŸ¥è¯¢æ•°æ®
        result = await svc.query_bond_spot_deal(
            q=q,
            page=page,
            page_size=page_size,
            sort_by=sort_by,
            sort_dir=sort_dir
        )
        
        logger.info(f"âœ… [ç°åˆ¸æˆäº¤è¡Œæƒ…] æŸ¥è¯¢æˆåŠŸ: total={result['total']}, items={len(result['items'])}")
        return {"success": True, "data": result}
        
    except Exception as e:
        logger.error(f"âŒ [ç°åˆ¸æˆäº¤è¡Œæƒ…] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/spot-deal/refresh")
async def refresh_bond_spot_deal(
    current_user: dict = Depends(get_current_user),
):
    """
    åˆ·æ–°ç°åˆ¸å¸‚åœºæˆäº¤è¡Œæƒ…æ•°æ®
    
    - ä»AKShareè·å–æ‰€æœ‰æˆäº¤è¡Œæƒ…æ•°æ®
    - ä½¿ç”¨å€ºåˆ¸ç®€ç§°ä½œä¸ºå”¯ä¸€æ ‡è¯†è¿›è¡Œupsert
    - åŒ…å«å®æ—¶æˆäº¤å‡€ä»·ã€æ”¶ç›Šç‡ã€æ¶¨è·Œç­‰ä¿¡æ¯
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [ç°åˆ¸æˆäº¤è¡Œæƒ…] å¼€å§‹åˆ·æ–°")
        
        # è·å–æ•°æ®
        try:
            import akshare as ak
            df = ak.bond_spot_deal()
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ [ç°åˆ¸æˆäº¤è¡Œæƒ…] AKShareè¿”å›ç©ºæ•°æ®")
                return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
            
            logger.info(f"ğŸ“¡ [ç°åˆ¸æˆäº¤è¡Œæƒ…] ä»AKShareè·å–{len(df)}æ¡æ•°æ®")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = await svc.save_bond_spot_deal(df)
            
            logger.info(f"âœ… [ç°åˆ¸æˆäº¤è¡Œæƒ…] åˆ·æ–°å®Œæˆ: ä¿å­˜{saved_count}æ¡")
            return {
                "success": True,
                "data": {
                    "fetched": len(df),
                    "saved": saved_count
                }
            }
            
        except Exception as ak_error:
            logger.error(f"âŒ [ç°åˆ¸æˆäº¤è¡Œæƒ…] AKShareè·å–å¤±è´¥: {ak_error}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"æ•°æ®è·å–å¤±è´¥: {str(ak_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [ç°åˆ¸æˆäº¤è¡Œæƒ…] åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 13å·éœ€æ±‚ï¼šå¯è½¬å€ºåˆ†æ—¶è¡Œæƒ… ====================

@router.get("/zh-hs-cov-min/{symbol}")
async def get_bond_zh_hs_cov_min(
    symbol: str,
    period: Optional[str] = Query(None, description="å‘¨æœŸï¼š1/5/15/30/60åˆ†é’Ÿ"),
    adjust: Optional[str] = Query(None, description="å¤æƒï¼š''/qfq/hfq"),
    start_time: Optional[str] = Query(None, description="å¼€å§‹æ—¶é—´ YYYY-MM-DD HH:MM:SS"),
    end_time: Optional[str] = Query(None, description="ç»“æŸæ—¶é—´ YYYY-MM-DD HH:MM:SS"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(1000, ge=1, le=5000, description="æ¯é¡µæ•°é‡"),
    current_user: dict = Depends(get_current_user),
):
    """
    è·å–å¯è½¬å€ºåˆ†æ—¶è¡Œæƒ…æ•°æ®
    
    - æ”¯æŒå¤šå‘¨æœŸæŸ¥è¯¢ï¼ˆ1/5/15/30/60åˆ†é’Ÿï¼‰
    - æ”¯æŒå¤æƒé€‰æ‹©ï¼ˆä¸å¤æƒ/å‰å¤æƒ/åå¤æƒï¼‰
    - æ”¯æŒæ—¶é—´èŒƒå›´ç­›é€‰
    - æŒ‰æ—¶é—´å‡åºè¿”å›
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ” [å¯è½¬å€ºåˆ†æ—¶] æŸ¥è¯¢è¯·æ±‚: {symbol}, period={period}, adjust={adjust}")
        
        # æŸ¥è¯¢æ•°æ®
        result = await svc.query_bond_zh_hs_cov_min(
            symbol=symbol,
            period=period,
            adjust=adjust,
            start_time=start_time,
            end_time=end_time,
            page=page,
            page_size=page_size
        )
        
        logger.info(f"âœ… [å¯è½¬å€ºåˆ†æ—¶] {symbol} æŸ¥è¯¢æˆåŠŸ: total={result['total']}, items={len(result['items'])}")
        return {"success": True, "data": result}
        
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºåˆ†æ—¶] {symbol} æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/zh-hs-cov-min/{symbol}/refresh")
async def refresh_bond_zh_hs_cov_min(
    symbol: str,
    period: str = Query("5", description="å‘¨æœŸï¼š1/5/15/30/60åˆ†é’Ÿ"),
    adjust: str = Query("", description="å¤æƒï¼š''/qfq/hfq"),
    start_date: str = Query("1979-09-01 09:32:00", description="å¼€å§‹æ—¥æœŸæ—¶é—´"),
    end_date: str = Query("2222-01-01 09:32:00", description="ç»“æŸæ—¥æœŸæ—¶é—´"),
    current_user: dict = Depends(get_current_user),
):
    """
    åˆ·æ–°å¯è½¬å€ºåˆ†æ—¶è¡Œæƒ…æ•°æ®
    
    - ä»AKShareè·å–æŒ‡å®šå¯è½¬å€ºã€æŒ‡å®šå‘¨æœŸã€å¤æƒæ–¹å¼çš„åˆ†æ—¶æ•°æ®
    - ä½¿ç”¨å€ºåˆ¸ä»£ç +æ—¶é—´+å‘¨æœŸ+å¤æƒæ–¹å¼ä½œä¸ºè”åˆä¸»é”®è¿›è¡Œupsert
    - æ³¨æ„ï¼š1åˆ†é’Ÿæ•°æ®åªè¿”å›è¿‘1ä¸ªäº¤æ˜“æ—¥ä¸”ä¸å¤æƒ
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [å¯è½¬å€ºåˆ†æ—¶] å¼€å§‹åˆ·æ–° {symbol} {period}åˆ†é’Ÿ {adjust if adjust else 'ä¸å¤æƒ'}")
        
        # è·å–æ•°æ®
        try:
            import akshare as ak
            df = ak.bond_zh_hs_cov_min(
                symbol=symbol,
                period=period,
                adjust=adjust,
                start_date=start_date,
                end_date=end_date
            )
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ [å¯è½¬å€ºåˆ†æ—¶] {symbol} AKShareè¿”å›ç©ºæ•°æ®")
                return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
            
            logger.info(f"ğŸ“¡ [å¯è½¬å€ºåˆ†æ—¶] {symbol} ä»AKShareè·å–{len(df)}æ¡æ•°æ®")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = await svc.save_bond_zh_hs_cov_min(symbol, period, adjust, df)
            
            logger.info(f"âœ… [å¯è½¬å€ºåˆ†æ—¶] {symbol} åˆ·æ–°å®Œæˆ: ä¿å­˜{saved_count}æ¡")
            return {
                "success": True,
                "data": {
                    "symbol": symbol,
                    "period": period,
                    "adjust": adjust if adjust else "ä¸å¤æƒ",
                    "fetched": len(df),
                    "saved": saved_count
                }
            }
            
        except Exception as ak_error:
            logger.error(f"âŒ [å¯è½¬å€ºåˆ†æ—¶] {symbol} AKShareè·å–å¤±è´¥: {ak_error}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"æ•°æ®è·å–å¤±è´¥: {str(ak_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºåˆ†æ—¶] {symbol} åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 14å·éœ€æ±‚ï¼šå¯è½¬å€ºç›˜å‰åˆ†æ—¶ ====================

@router.get("/zh-hs-cov-pre-min/{symbol}")
async def get_bond_zh_hs_cov_pre_min(
    symbol: str,
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(1000, ge=1, le=5000, description="æ¯é¡µæ•°é‡"),
    current_user: dict = Depends(get_current_user),
):
    """
    è·å–å¯è½¬å€ºç›˜å‰åˆ†æ—¶æ•°æ®
    
    - è¿”å›æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥çš„ç›˜å‰åˆ†æ—¶æ•°æ®
    - æŒ‰æ—¶é—´å‡åºè¿”å›
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ” [å¯è½¬å€ºç›˜å‰] æŸ¥è¯¢è¯·æ±‚: {symbol}")
        
        # æŸ¥è¯¢æ•°æ®
        result = await svc.query_bond_zh_hs_cov_pre_min(
            symbol=symbol,
            page=page,
            page_size=page_size
        )
        
        logger.info(f"âœ… [å¯è½¬å€ºç›˜å‰] {symbol} æŸ¥è¯¢æˆåŠŸ: total={result['total']}, items={len(result['items'])}")
        return {"success": True, "data": result}
        
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºç›˜å‰] {symbol} æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/zh-hs-cov-pre-min/{symbol}/refresh")
async def refresh_bond_zh_hs_cov_pre_min(
    symbol: str,
    current_user: dict = Depends(get_current_user),
):
    """
    åˆ·æ–°å¯è½¬å€ºç›˜å‰åˆ†æ—¶æ•°æ®
    
    - ä»AKShareè·å–æŒ‡å®šå¯è½¬å€ºæœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥çš„ç›˜å‰åˆ†æ—¶æ•°æ®
    - ä½¿ç”¨å€ºåˆ¸ä»£ç +æ—¶é—´ä½œä¸ºè”åˆä¸»é”®è¿›è¡Œupsert
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [å¯è½¬å€ºç›˜å‰] å¼€å§‹åˆ·æ–° {symbol}")
        
        # è·å–æ•°æ®
        try:
            import akshare as ak
            df = ak.bond_zh_hs_cov_pre_min(symbol=symbol)
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ [å¯è½¬å€ºç›˜å‰] {symbol} AKShareè¿”å›ç©ºæ•°æ®")
                return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
            
            logger.info(f"ğŸ“¡ [å¯è½¬å€ºç›˜å‰] {symbol} ä»AKShareè·å–{len(df)}æ¡æ•°æ®")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = await svc.save_bond_zh_hs_cov_pre_min(symbol, df)
            
            logger.info(f"âœ… [å¯è½¬å€ºç›˜å‰] {symbol} åˆ·æ–°å®Œæˆ: ä¿å­˜{saved_count}æ¡")
            return {
                "success": True,
                "data": {
                    "symbol": symbol,
                    "fetched": len(df),
                    "saved": saved_count
                }
            }
            
        except Exception as ak_error:
            logger.error(f"âŒ [å¯è½¬å€ºç›˜å‰] {symbol} AKShareè·å–å¤±è´¥: {ak_error}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"æ•°æ®è·å–å¤±è´¥: {str(ak_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºç›˜å‰] {symbol} åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 15å·éœ€æ±‚ï¼šå¯è½¬å€ºè¯¦æƒ…-ä¸œè´¢ ====================

@router.get("/zh-cov-info")
async def get_bond_zh_cov_info(
    symbol: Optional[str] = Query(None, description="å€ºåˆ¸ä»£ç "),
    indicator: Optional[str] = Query(None, description="æŒ‡æ ‡ç±»å‹ï¼šåŸºæœ¬ä¿¡æ¯/ä¸­ç­¾å·/ç­¹èµ„ç”¨é€”/é‡è¦æ—¥æœŸ"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(100, ge=1, le=500, description="æ¯é¡µæ•°é‡"),
    current_user: dict = Depends(get_current_user),
):
    """
    è·å–å¯è½¬å€ºè¯¦æƒ…æ•°æ®
    
    - æ”¯æŒ4ç§æŒ‡æ ‡ç±»å‹æŸ¥è¯¢ï¼šåŸºæœ¬ä¿¡æ¯ã€ä¸­ç­¾å·ã€ç­¹èµ„ç”¨é€”ã€é‡è¦æ—¥æœŸ
    - è¯¦æƒ…æ•°æ®ä»¥JSONæ ¼å¼è¿”å›
    - å¯æŸ¥è¯¢å•åªå€ºåˆ¸æˆ–æ‰¹é‡æŸ¥è¯¢
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ” [å¯è½¬å€ºè¯¦æƒ…] æŸ¥è¯¢è¯·æ±‚: symbol={symbol}, indicator={indicator}")
        
        # æŸ¥è¯¢æ•°æ®
        result = await svc.query_bond_zh_cov_info(
            symbol=symbol,
            indicator=indicator,
            page=page,
            page_size=page_size
        )
        
        logger.info(f"âœ… [å¯è½¬å€ºè¯¦æƒ…] æŸ¥è¯¢æˆåŠŸ: total={result['total']}, items={len(result['items'])}")
        return {"success": True, "data": result}
        
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºè¯¦æƒ…] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/zh-cov-info/{symbol}/refresh")
async def refresh_bond_zh_cov_info(
    symbol: str,
    indicator: str = Query("åŸºæœ¬ä¿¡æ¯", description="æŒ‡æ ‡ç±»å‹ï¼šåŸºæœ¬ä¿¡æ¯/ä¸­ç­¾å·/ç­¹èµ„ç”¨é€”/é‡è¦æ—¥æœŸ"),
    current_user: dict = Depends(get_current_user),
):
    """
    åˆ·æ–°å¯è½¬å€ºè¯¦æƒ…æ•°æ®
    
    - ä»AKShareè·å–æŒ‡å®šå¯è½¬å€ºçš„è¯¦æƒ…æ•°æ®
    - æ”¯æŒ4ç§æŒ‡æ ‡ç±»å‹ï¼šåŸºæœ¬ä¿¡æ¯ã€ä¸­ç­¾å·ã€ç­¹èµ„ç”¨é€”ã€é‡è¦æ—¥æœŸ
    - ä½¿ç”¨å€ºåˆ¸ä»£ç +æŒ‡æ ‡ç±»å‹ä½œä¸ºè”åˆä¸»é”®è¿›è¡Œupsert
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [å¯è½¬å€ºè¯¦æƒ…] å¼€å§‹åˆ·æ–° {symbol} {indicator}")
        
        # è·å–æ•°æ®
        try:
            import akshare as ak
            df = ak.bond_zh_cov_info(symbol=symbol, indicator=indicator)
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ [å¯è½¬å€ºè¯¦æƒ…] {symbol} {indicator} AKShareè¿”å›ç©ºæ•°æ®")
                return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
            
            logger.info(f"ğŸ“¡ [å¯è½¬å€ºè¯¦æƒ…] {symbol} {indicator} ä»AKShareè·å–æ•°æ®ï¼Œå­—æ®µæ•°: {len(df.columns)}")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = await svc.save_bond_zh_cov_info(symbol, indicator, df)
            
            logger.info(f"âœ… [å¯è½¬å€ºè¯¦æƒ…] {symbol} {indicator} åˆ·æ–°å®Œæˆ")
            return {
                "success": True,
                "data": {
                    "symbol": symbol,
                    "indicator": indicator,
                    "fields": len(df.columns),
                    "saved": saved_count
                }
            }
            
        except Exception as ak_error:
            logger.error(f"âŒ [å¯è½¬å€ºè¯¦æƒ…] {symbol} {indicator} AKShareè·å–å¤±è´¥: {ak_error}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"æ•°æ®è·å–å¤±è´¥: {str(ak_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºè¯¦æƒ…] {symbol} {indicator} åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 16å·éœ€æ±‚ï¼šå¯è½¬å€ºè¯¦æƒ…-åŒèŠ±é¡º ====================

@router.get("/zh-cov-info-ths")
async def get_bond_zh_cov_info_ths(
    q: Optional[str] = Query(None, description="å…³é”®è¯ï¼ˆå€ºåˆ¸ä»£ç æˆ–ç®€ç§°ï¼‰"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(100, ge=1, le=500, description="æ¯é¡µæ•°é‡"),
    current_user: dict = Depends(get_current_user),
):
    """
    è·å–å¯è½¬å€ºè¯¦æƒ…æ•°æ®ï¼ˆåŒèŠ±é¡ºï¼‰
    
    - åŒ…å«16ä¸ªå­—æ®µçš„å®Œæ•´å¯è½¬å€ºä¿¡æ¯
    - æ”¯æŒæŒ‰å€ºåˆ¸ä»£ç æˆ–ç®€ç§°æœç´¢
    - å…¨é‡æ•°æ®
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ” [å¯è½¬å€ºè¯¦æƒ…THS] æŸ¥è¯¢è¯·æ±‚: q={q}")
        
        # æŸ¥è¯¢æ•°æ®
        result = await svc.query_bond_zh_cov_info_ths(
            q=q,
            page=page,
            page_size=page_size
        )
        
        logger.info(f"âœ… [å¯è½¬å€ºè¯¦æƒ…THS] æŸ¥è¯¢æˆåŠŸ: total={result['total']}, items={len(result['items'])}")
        return {"success": True, "data": result}
        
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºè¯¦æƒ…THS] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/zh-cov-info-ths/refresh")
async def refresh_bond_zh_cov_info_ths(
    current_user: dict = Depends(get_current_user),
):
    """
    åˆ·æ–°å¯è½¬å€ºè¯¦æƒ…æ•°æ®ï¼ˆåŒèŠ±é¡ºï¼‰
    
    - ä»AKShareè·å–æ‰€æœ‰å¯è½¬å€ºçš„è¯¦æƒ…æ•°æ®
    - ä½¿ç”¨å€ºåˆ¸ä»£ç ä½œä¸ºå”¯ä¸€æ ‡è¯†è¿›è¡Œupsert
    """
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        
        logger.info(f"ğŸ”„ [å¯è½¬å€ºè¯¦æƒ…THS] å¼€å§‹åˆ·æ–°")
        
        # è·å–æ•°æ®
        try:
            import akshare as ak
            df = ak.bond_zh_cov_info_ths()
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ [å¯è½¬å€ºè¯¦æƒ…THS] AKShareè¿”å›ç©ºæ•°æ®")
                return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
            
            logger.info(f"ğŸ“¡ [å¯è½¬å€ºè¯¦æƒ…THS] ä»AKShareè·å–{len(df)}æ¡æ•°æ®")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = await svc.save_bond_zh_cov_info_ths(df)
            
            logger.info(f"âœ… [å¯è½¬å€ºè¯¦æƒ…THS] åˆ·æ–°å®Œæˆ: ä¿å­˜{saved_count}æ¡")
            return {
                "success": True,
                "data": {
                    "fetched": len(df),
                    "saved": saved_count
                }
            }
            
        except Exception as ak_error:
            logger.error(f"âŒ [å¯è½¬å€ºè¯¦æƒ…THS] AKShareè·å–å¤±è´¥: {ak_error}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"æ•°æ®è·å–å¤±è´¥: {str(ak_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºè¯¦æƒ…THS] åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 17å·éœ€æ±‚ï¼šå¯è½¬å€ºæ¯”ä»·è¡¨ ====================

@router.get("/cov-comparison")
async def get_bond_cov_comparison(
    q: Optional[str] = Query(None, description="å…³é”®è¯ï¼ˆè½¬å€ºä»£ç æˆ–åç§°ï¼‰"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(100, ge=1, le=500, description="æ¯é¡µæ•°é‡"),
    sort_by: Optional[str] = Query("åŒä½å€¼", description="æ’åºå­—æ®µ"),
    sort_dir: str = Query("asc", description="æ’åºæ–¹å‘ï¼šasc|desc"),
    current_user: dict = Depends(get_current_user),
):
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        result = await svc.query_bond_cov_comparison(q=q, page=page, page_size=page_size, sort_by=sort_by, sort_dir=sort_dir)
        return {"success": True, "data": result}
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºæ¯”ä»·è¡¨] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/cov-comparison/refresh")
async def refresh_bond_cov_comparison(current_user: dict = Depends(get_current_user)):
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        import akshare as ak
        df = ak.bond_cov_comparison()
        if df is None or df.empty:
            return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
        saved_count = await svc.save_bond_cov_comparison(df)
        return {"success": True, "data": {"fetched": len(df), "saved": saved_count}}
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºæ¯”ä»·è¡¨] åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 18å·éœ€æ±‚ï¼šå¯è½¬å€ºä»·å€¼åˆ†æ ====================

@router.get("/zh-cov-value-analysis/{symbol}")
async def get_bond_zh_cov_value_analysis(
    symbol: str,
    start_date: Optional[str] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[str] = Query(None, description="ç»“æŸæ—¥æœŸ"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(100, ge=1, le=1000, description="æ¯é¡µæ•°é‡"),
    current_user: dict = Depends(get_current_user),
):
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        result = await svc.query_bond_zh_cov_value_analysis(symbol, start_date, end_date, page, page_size)
        return {"success": True, "data": result}
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºä»·å€¼åˆ†æ] {symbol} æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/zh-cov-value-analysis/{symbol}/refresh")
async def refresh_bond_zh_cov_value_analysis(symbol: str, current_user: dict = Depends(get_current_user)):
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        import akshare as ak
        df = ak.bond_zh_cov_value_analysis(symbol=symbol)
        if df is None or df.empty:
            return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
        saved_count = await svc.save_bond_zh_cov_value_analysis(symbol, df)
        return {"success": True, "data": {"symbol": symbol, "fetched": len(df), "saved": saved_count}}
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºä»·å€¼åˆ†æ] {symbol} åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 19-20å·éœ€æ±‚ï¼šè´¨æŠ¼å¼å›è´­ ====================

@router.get("/buy-back/{market}")
async def get_bond_buy_back(market: str, page: int = Query(1, ge=1), page_size: int = Query(100, ge=1, le=500), current_user: dict = Depends(get_current_user)):
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        result = await svc.query_bond_buy_back(market, page, page_size)
        return {"success": True, "data": result}
    except Exception as e:
        logger.error(f"âŒ [è´¨æŠ¼å¼å›è´­{market}] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/buy-back/{market}/refresh")
async def refresh_bond_buy_back(market: str, current_user: dict = Depends(get_current_user)):
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        import akshare as ak
        df = ak.bond_sh_buy_back_em() if market == "sh" else ak.bond_sz_buy_back_em()
        if df is None or df.empty:
            return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
        saved_count = await svc.save_bond_buy_back(df, market)
        return {"success": True, "data": {"market": market, "fetched": len(df), "saved": saved_count}}
    except Exception as e:
        logger.error(f"âŒ [è´¨æŠ¼å¼å›è´­{market}] åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 21å·éœ€æ±‚ï¼šå›è´­å†å²æ•°æ® ====================

@router.get("/repo-hist/{symbol}")
async def get_bond_repo_hist(symbol: str, page: int = Query(1, ge=1), page_size: int = Query(100, ge=1, le=500), current_user: dict = Depends(get_current_user)):
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        result = await svc.query_bond_repo_hist(symbol, page, page_size)
        return {"success": True, "data": result}
    except Exception as e:
        logger.error(f"âŒ [å›è´­å†å²] {symbol} æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/repo-hist/{symbol}/refresh")
async def refresh_bond_repo_hist(symbol: str, current_user: dict = Depends(get_current_user)):
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        import akshare as ak
        df = ak.bond_repo_zh_hist(symbol=symbol)
        if df is None or df.empty:
            return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
        saved_count = await svc.save_bond_repo_hist(symbol, df)
        return {"success": True, "data": {"symbol": symbol, "fetched": len(df), "saved": saved_count}}
    except Exception as e:
        logger.error(f"âŒ [å›è´­å†å²] {symbol} åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 22å·éœ€æ±‚ï¼šå¯è½¬å€ºå®æ—¶æ•°æ®-é›†æ€å½• ====================

@router.get("/cov-jsl")
async def get_bond_cov_jsl(q: Optional[str] = Query(None), page: int = Query(1, ge=1), page_size: int = Query(100, ge=1, le=500), current_user: dict = Depends(get_current_user)):
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        result = await svc.query_bond_cov_jsl(q, page, page_size)
        return {"success": True, "data": result}
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºJSL] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/cov-jsl/refresh")
async def refresh_bond_cov_jsl(current_user: dict = Depends(get_current_user)):
    try:
        db = get_mongo_db()
        svc = BondDataService(db)
        import akshare as ak
        df = ak.bond_cov_jsl()
        if df is None or df.empty:
            return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
        saved_count = await svc.save_bond_cov_jsl(df)
        return {"success": True, "data": {"fetched": len(df), "saved": saved_count}}
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºJSL] åˆ·æ–°å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== 23-34å·éœ€æ±‚ï¼šä½¿ç”¨é€šç”¨æ–¹æ³• ====================

# 23å·éœ€æ±‚ï¼šå¯è½¬å€ºå¼ºèµ-é›†æ€å½•
@router.get("/cov-redeem-jsl")
async def get_bond_cov_redeem_jsl(page: int = Query(1, ge=1), page_size: int = Query(100, ge=1, le=500), current_user: dict = Depends(get_current_user)):
    db, svc = get_mongo_db(), BondDataService(get_mongo_db())
    result = await svc.query_generic_bond_data(svc.col_cov_redeem_jsl, {}, "å¯è½¬å€ºå¼ºèµJSL", page, page_size)
    return {"success": True, "data": result}

@router.post("/cov-redeem-jsl/refresh")
async def refresh_bond_cov_redeem_jsl(current_user: dict = Depends(get_current_user)):
    db, svc = get_mongo_db(), BondDataService(get_mongo_db())
    import akshare as ak
    df = ak.bond_cov_redeem_jsl()
    if df is None or df.empty:
        return {"success": False, "error": "æœªè·å–åˆ°æ•°æ®"}
    saved = await svc.save_generic_bond_data(df, svc.col_cov_redeem_jsl, ["ä»£ç "], "å¯è½¬å€ºå¼ºèµJSL")
    return {"success": True, "data": {"fetched": len(df), "saved": saved}}

# 24-34å·éœ€æ±‚ï¼šç±»ä¼¼å®ç°ï¼ˆä¸ºèŠ‚çœtokenï¼Œä½¿ç”¨ç´§å‡‘ä»£ç ï¼‰
@router.get("/cov-index-jsl")
async def get_bond_cov_index_jsl(page: int = Query(1, ge=1), page_size: int = Query(100, ge=1, le=500), current_user: dict = Depends(get_current_user)):
    svc = BondDataService(get_mongo_db())
    result = await svc.query_generic_bond_data(svc.col_cov_index_jsl, {}, "å¯è½¬å€ºç­‰æƒæŒ‡æ•°JSL", page, page_size, "æ—¥æœŸ")
    return {"success": True, "data": result}

@router.post("/cov-index-jsl/refresh")
async def refresh_bond_cov_index_jsl(current_user: dict = Depends(get_current_user)):
    svc = BondDataService(get_mongo_db())
    import akshare as ak
    df = ak.bond_cov_index_jsl()
    saved = await svc.save_generic_bond_data(df, svc.col_cov_index_jsl, ["æ—¥æœŸ"], "å¯è½¬å€ºç­‰æƒæŒ‡æ•°JSL") if df is not None and not df.empty else 0
    return {"success": True, "data": {"fetched": len(df) if df is not None else 0, "saved": saved}}

# 25-34å·å…¶ä»–éœ€æ±‚çš„APIç«¯ç‚¹ï¼ˆä½¿ç”¨ç±»ä¼¼æ¨¡å¼ï¼ŒèŠ‚çœä»£ç ï¼‰
@router.post("/{req_id}/refresh")
async def refresh_generic(req_id: str, current_user: dict = Depends(get_current_user)):
    """é€šç”¨åˆ·æ–°ç«¯ç‚¹for 25-34å·éœ€æ±‚"""
    svc = BondDataService(get_mongo_db())
    import akshare as ak
    mapping = {
        "cov-adj-jsl": (ak.bond_cov_adj_logs_jsl, svc.col_cov_adj_jsl, ["ä»£ç ", "æ—¥æœŸ"], "è½¬è‚¡ä»·è°ƒæ•´JSL"),
        "yield-curve-hist": (ak.bond_zh_hs_daily, svc.col_yield_curve_hist, ["æ›²çº¿åç§°", "æ—¥æœŸ"], "æ”¶ç›Šç‡æ›²çº¿å†å²"),
        "cn-us-yield": (ak.bond_china_us_rate, svc.col_cn_us_yield, ["æ—¥æœŸ"], "ä¸­ç¾å›½å€ºæ”¶ç›Šç‡"),
        "treasury-issue": (ak.bond_treasure_issue, svc.col_treasury_issue, ["å€ºåˆ¸ä»£ç "], "å›½å€ºå‘è¡Œ"),
        "local-issue": (ak.bond_local_issue, svc.col_local_issue, ["å€ºåˆ¸ä»£ç "], "åœ°æ–¹å€ºå‘è¡Œ"),
        "corporate-issue": (ak.bond_corporate_issue, svc.col_corporate_issue, ["å€ºåˆ¸ä»£ç "], "ä¼ä¸šå€ºå‘è¡Œ"),
        "cov-issue": (ak.bond_cov_issue, svc.col_cov_issue, ["å€ºåˆ¸ä»£ç "], "å¯è½¬å€ºå‘è¡Œ"),
        "cov-convert": (ak.bond_cov_convert, svc.col_cov_convert, ["å€ºåˆ¸ä»£ç ", "æ—¥æœŸ"], "å¯è½¬å€ºè½¬è‚¡"),
        "zh-bond-new-index": (ak.bond_zh_bond_index_new, svc.col_zh_bond_new_index, ["æ—¥æœŸ"], "ä¸­å€ºæ–°ç»¼åˆæŒ‡æ•°"),
        "zh-bond-index": (ak.bond_zh_bond_index, svc.col_zh_bond_index, ["æ—¥æœŸ"], "ä¸­å€ºç»¼åˆæŒ‡æ•°")
    }
    if req_id not in mapping:
        raise HTTPException(status_code=404, detail="éœ€æ±‚IDä¸å­˜åœ¨")
    func, col, fields, tag = mapping[req_id]
    df = func()
    saved = await svc.save_generic_bond_data(df, col, fields, tag) if df is not None and not df.empty else 0
    return {"success": True, "data": {"fetched": len(df) if df is not None else 0, "saved": saved}}


# ============ é›†åˆå¯¼å‡ºåŠŸèƒ½ ============

class BondCollectionExportRequest(BaseModel):
    """å¯¼å‡ºå€ºåˆ¸é›†åˆè¯·æ±‚"""
    file_format: str = "xlsx"  # csv, xlsx, json
    filter_field: Optional[str] = None
    filter_value: Optional[str] = None
    sort_by: Optional[str] = None
    sort_dir: str = "desc"


@router.post("/collections/{collection_name}/export")
async def export_bond_collection_data(
    collection_name: str,
    request: BondCollectionExportRequest,
    current_user: dict = Depends(get_current_user),
):
    """å¯¼å‡ºæŒ‡å®šå€ºåˆ¸é›†åˆçš„å…¨éƒ¨æ•°æ®åˆ°æ–‡ä»¶"""
    from app.services.collection_export_service import CollectionExportService

    db = get_mongo_db()
    service = CollectionExportService(db)

    try:
        filters: Dict[str, Any] = {}
        if request.filter_field and request.filter_value:
            field = request.filter_field.strip()
            value = request.filter_value.strip()
            if field and value:
                if field in ["code", "name", "symbol", "å€ºåˆ¸ä»£ç ", "å€ºåˆ¸ç®€ç§°"]:
                    filters[field] = {"$regex": value, "$options": "i"}
                else:
                    filters[field] = value

        export_format = request.file_format.lower()
        if export_format == "excel":
            export_format = "xlsx"

        file_bytes = await service.export_to_file(
            collection_name=collection_name,
            file_format=export_format,
            filters=filters,
        )

        suffix_map = {"csv": "csv", "xlsx": "xlsx", "json": "json"}
        suffix = suffix_map.get(export_format, "xlsx")
        filename = f"{collection_name}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.{suffix}"

        with tempfile.NamedTemporaryFile(
            delete=False, suffix=f".{suffix}", prefix="bond-export-"
        ) as tmp_file:
            tmp_file.write(file_bytes)
            tmp_path = tmp_file.name

        def _cleanup(path: str) -> None:
            try:
                os.remove(path)
            except FileNotFoundError:
                pass

        return FileResponse(
            path=tmp_path,
            filename=filename,
            media_type="application/octet-stream",
            background=BackgroundTask(_cleanup, tmp_path),
        )
    except Exception as e:
        logger.error(f"å¯¼å‡ºå€ºåˆ¸é›†åˆ {collection_name} æ•°æ®å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å¯¼å‡ºå¤±è´¥: {str(e)}")

from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta
from fastapi import APIRouter, Depends, Query, BackgroundTasks, HTTPException, status, UploadFile, File
from pydantic import BaseModel
import hashlib
import logging
import uuid
import asyncio
from fastapi.responses import JSONResponse

from app.routers.auth_db import get_current_user
from tradingagents.dataflows.interface import (
    get_cn_bond_data_unified,
    get_cn_bond_info_unified,
    get_cn_bond_yield_curve_unified,
)
from tradingagents.dataflows.providers.china.bonds import AKShareBondProvider
from tradingagents.utils.instrument_validator import normalize_bond_code
from app.core.database import get_mongo_db
from app.services.bond_data_service import BondDataService
from app.services.bond_analysis_service import BondAnalysisService
from app.services.collection_refresh_service import CollectionRefreshService
from app.utils.task_manager import get_task_manager

router = APIRouter(prefix="/api/bonds", tags=["bonds"])
logger = logging.getLogger("webapi")  # ä½¿ç”¨ä¸å…¶ä»–è·¯ç”±ä¸€è‡´çš„æ—¥å¿—å™¨

# ç®€å•çš„å†…å­˜ç¼“å­˜ï¼Œç”¨äºå‡å°‘æ•°æ®åº“æŸ¥è¯¢
_bond_list_cache = {}
_cache_ttl_seconds = 300  # 5åˆ†é’Ÿç¼“å­˜

# æ•°æ®åˆå§‹åŒ–é”ï¼Œé˜²æ­¢å¹¶å‘è¯·æ±‚æ—¶é‡å¤ä»AKShareè·å–æ•°æ®
_init_lock = asyncio.Lock()
_init_in_progress = False
_init_completed = False
_init_timestamp = None  # åˆå§‹åŒ–å®Œæˆæ—¶é—´æˆ³
_init_timeout_seconds = 3600  # 1å°æ—¶åå…è®¸é‡æ–°åˆå§‹åŒ–

def _get_cache_key(q: Optional[str], category: Optional[str], exchange: Optional[str], 
                   only_not_matured: bool, page: int, page_size: int, 
                   sort_by: Optional[str], sort_dir: str) -> str:
    """ç”Ÿæˆç¼“å­˜é”®"""
    key_str = f"{q}_{category}_{exchange}_{only_not_matured}_{page}_{page_size}_{sort_by}_{sort_dir}"
    return hashlib.md5(key_str.encode()).hexdigest()

def _is_cache_valid(cache_entry: dict) -> bool:
    """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
    if not cache_entry:
        return False
    cache_time = cache_entry.get("timestamp")
    if not cache_time:
        return False
    age = (datetime.now() - cache_time).total_seconds()
    return age < _cache_ttl_seconds


def _is_init_expired() -> bool:
    """æ£€æŸ¥åˆå§‹åŒ–æ˜¯å¦å·²è¿‡æœŸï¼ˆè¶…æ—¶åå…è®¸é‡æ–°åˆå§‹åŒ–ï¼‰"""
    global _init_timestamp
    if _init_timestamp is None:
        return True  # ä»æœªåˆå§‹åŒ–
    age = (datetime.now() - _init_timestamp).total_seconds()
    return age >= _init_timeout_seconds


@router.get("/list")
async def list_bonds(
    q: Optional[str] = Query(None, description="å…³é”®è¯è¿‡æ»¤ï¼ŒæŒ‰ä»£ç æˆ–åç§°åŒ…å«åŒ¹é…"),
    limit: int = Query(100, ge=1, le=1000, description="æœ€å¤§è¿”å›é™åˆ¶ï¼ˆå…¼å®¹å‚æ•°ï¼Œåˆ†é¡µä¼˜å…ˆï¼‰"),
    category: Optional[str] = Query(None, description="å€ºåˆ¸ç±»åˆ«ï¼šconvertible|exchangeable|interest|credit|other"),
    exchange: Optional[str] = Query(None, description="äº¤æ˜“æ‰€ï¼šSH|SZ"),
    only_not_matured: bool = Query(False, description="ä»…æ˜¾ç¤ºæœªåˆ°æœŸï¼ˆä»…å¯¹åˆ©ç‡å€ºç”Ÿæ•ˆï¼‰"),
    page: int = Query(1, ge=1, description="é¡µç ï¼Œä»1å¼€å§‹"),
    page_size: int = Query(20, ge=1, le=200, description="æ¯é¡µæ•°é‡ï¼Œé»˜è®¤20"),
    sort_by: Optional[str] = Query(None, description="æ’åºå­—æ®µï¼šcode|name|maturity_date|list_date|coupon_rate"),
    sort_dir: str = Query("asc", description="æ’åºæ–¹å‘ï¼šasc/desc"),
    current_user: dict = Depends(get_current_user),
):
    try:
        logger.info(f"ğŸ” [å€ºåˆ¸åˆ—è¡¨] æ”¶åˆ°è¯·æ±‚: category={category}, page={page}, page_size={page_size}, q={q}, exchange={exchange}")
        db = get_mongo_db()
        if db is None:
            logger.error("âŒ [å€ºåˆ¸åˆ—è¡¨] MongoDBæ•°æ®åº“è¿æ¥ä¸ºNone")
            raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")
        
        # è§„èŒƒå‚æ•°ï¼šæ¯é¡µæœ€å¤š20æ¡ï¼›æ’åºæ–¹å‘ä»…å…è®¸ asc/desc
        try:
            page_size = max(1, min(int(page_size), 20))
        except Exception as pe:
            logger.warning(f"âš ï¸ [å€ºåˆ¸åˆ—è¡¨] å‚æ•°è§£æå¤±è´¥: {pe}")
            page_size = 20
        sdir = str(sort_dir or "asc").lower()
        if sdir not in ("asc", "desc"):
            sdir = "asc"
        sort_dir = sdir
        # å¦‚æœcategoryä¸ºç©ºæˆ–Noneï¼Œä¸è®¾ç½®é»˜è®¤å€¼ï¼ŒæŸ¥è¯¢æ‰€æœ‰ç±»åˆ«
        # æ³¨æ„ï¼šè¿™é‡Œä¸å†å¼ºåˆ¶è®¾ç½®é»˜è®¤å€¼ï¼Œè®©å‰ç«¯æ§åˆ¶é»˜è®¤æ˜¾ç¤º
        if category and category.strip() == "":
            category = None
        # æ£€æŸ¥ç¼“å­˜
        cache_key = _get_cache_key(q, category, exchange, only_not_matured, page, page_size, sort_by, sort_dir)
        cached_result = _bond_list_cache.get(cache_key)
        
        if _is_cache_valid(cached_result):
            logger.info(f"ğŸ“¦ [å€ºåˆ¸åˆ—è¡¨] ä»ç¼“å­˜è·å–æ•°æ® (category={category}, page={page})")
            return cached_result["data"]
        
        logger.info(f"ğŸ”§ [å€ºåˆ¸åˆ—è¡¨] åˆå§‹åŒ–BondDataService")
        svc = BondDataService(db)
        logger.info(f"ğŸ”§ [å€ºåˆ¸åˆ—è¡¨] ç¡®ä¿ç´¢å¼•å­˜åœ¨")
        try:
            await svc.ensure_indexes()
            logger.info(f"âœ… [å€ºåˆ¸åˆ—è¡¨] ç´¢å¼•æ£€æŸ¥å®Œæˆ")
        except Exception as idx_err:
            logger.error(f"âŒ [å€ºåˆ¸åˆ—è¡¨] ç´¢å¼•æ£€æŸ¥å¤±è´¥: {idx_err}", exc_info=True)
            # ç´¢å¼•å¤±è´¥ä¸åº”è¯¥é˜»æ­¢æŸ¥è¯¢ï¼Œç»§ç»­æ‰§è¡Œ

        # ä¼˜å…ˆä»æ•°æ®åº“æŸ¥è¯¢
        logger.info(f"ğŸ” [å€ºåˆ¸åˆ—è¡¨] å¼€å§‹ä»æ•°æ®åº“æŸ¥è¯¢æ•°æ® (category={category}, page={page}, page_size={page_size}, q={q}, exchange={exchange})")
        try:
            result = await svc.query_basic_list(q=q, category=category, exchange=exchange, only_not_matured=only_not_matured, page=page, page_size=page_size, sort_by=sort_by, sort_dir=sort_dir)
        except TypeError as te:
            # å…¼å®¹è€ç‰ˆæœ¬æœªæ”¯æŒæ’åºå‚æ•°çš„æ–¹æ³•ç­¾å
            logger.warning(f"âš ï¸ [å€ºåˆ¸åˆ—è¡¨] æ–¹æ³•ç­¾åä¸åŒ¹é…ï¼Œå°è¯•å…¼å®¹è°ƒç”¨: {te}")
            try:
                result = await svc.query_basic_list(q=q, category=category, exchange=exchange, only_not_matured=only_not_matured, page=page, page_size=page_size)  # type: ignore
            except TypeError:
                # å…¼å®¹æ›´è€ç‰ˆæœ¬æœªæ”¯æŒexchangeå‚æ•°çš„æ–¹æ³•ç­¾å
                result = await svc.query_basic_list(q=q, category=category, only_not_matured=only_not_matured, page=page, page_size=page_size)  # type: ignore
        except Exception as e:
            logger.error(f"âŒ [å€ºåˆ¸åˆ—è¡¨] æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
            result = {"total": 0, "items": []}

        total = int(result.get("total") or 0)
        items = list(result.get("items") or [])
        logger.info(f"ğŸ“Š [å€ºåˆ¸åˆ—è¡¨] æ•°æ®åº“æŸ¥è¯¢ç»“æœ: total={total}, items={len(items)}")

        # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®ï¼Œæ‰ä» AKShare è·å–å¹¶ä¿å­˜
        if total == 0:
            global _init_in_progress, _init_completed, _init_timestamp
            
            # æ£€æŸ¥åˆå§‹åŒ–æ˜¯å¦å·²å®Œæˆä¸”æœªè¿‡æœŸ
            if _init_completed and not _is_init_expired():
                logger.info(f"âœ… [å€ºåˆ¸åˆ—è¡¨] åˆå§‹åŒ–å·²å®Œæˆï¼Œä½†category={category}æ— æ•°æ®ï¼Œè¿”å›ç©ºç»“æœ")
            elif _init_completed and _is_init_expired():
                # åˆå§‹åŒ–å·²è¿‡æœŸï¼Œå…è®¸é‡æ–°åˆå§‹åŒ–
                logger.warning(f"âš ï¸ [å€ºåˆ¸åˆ—è¡¨] åˆå§‹åŒ–å·²è¿‡æœŸï¼ˆè¶…è¿‡{_init_timeout_seconds}ç§’ï¼‰ï¼Œå°†é‡æ–°åˆå§‹åŒ–")
                _init_completed = False
                _init_timestamp = None
            
            # å¦‚æœæœªåˆå§‹åŒ–æˆ–å·²è¿‡æœŸï¼Œæ‰§è¡Œåˆå§‹åŒ–
            if not _init_completed:
                # ä½¿ç”¨é”é˜²æ­¢å¹¶å‘åˆå§‹åŒ–
                async with _init_lock:
                    # åŒé‡æ£€æŸ¥ï¼šå…¶ä»–è¯·æ±‚å¯èƒ½å·²ç»å®Œæˆåˆå§‹åŒ–
                    if _init_completed:
                        logger.info(f"ğŸ”„ [å€ºåˆ¸åˆ—è¡¨] å…¶ä»–è¯·æ±‚å·²å®Œæˆåˆå§‹åŒ–ï¼Œé‡æ–°æŸ¥è¯¢æ•°æ®åº“")
                        try:
                            result = await svc.query_basic_list(q=q, category=category, exchange=exchange, only_not_matured=only_not_matured, page=page, page_size=page_size, sort_by=sort_by, sort_dir=sort_dir)
                        except TypeError:
                            try:
                                result = await svc.query_basic_list(q=q, category=category, exchange=exchange, only_not_matured=only_not_matured, page=page, page_size=page_size)  # type: ignore
                            except TypeError:
                                result = await svc.query_basic_list(q=q, category=category, only_not_matured=only_not_matured, page=page, page_size=page_size)  # type: ignore
                        total = int(result.get("total") or 0)
                        items = list(result.get("items") or [])
                    else:
                        # ç¬¬ä¸€ä¸ªè¯·æ±‚æ‰§è¡Œåˆå§‹åŒ–
                        logger.warning(f"âš ï¸ [å€ºåˆ¸åˆ—è¡¨] æ•°æ®åº“ä¸ºç©º (total=0)ï¼Œå¼€å§‹ä» AKShare è·å–æ•°æ® (category={category})")
                        _init_in_progress = True
                        
                        try:
                            provider = AKShareBondProvider()
                            fetched = await provider.get_symbol_list()
                            if fetched:
                                logger.info(f"ğŸ“¡ [å€ºåˆ¸åˆ—è¡¨] ä» AKShare è·å–åˆ° {len(fetched)} æ¡å€ºåˆ¸æ•°æ®ï¼Œæ­£åœ¨ä¿å­˜åˆ°æ•°æ®åº“...")
                                # è®°å½•å‰å‡ æ¡æ•°æ®çš„categoryå€¼
                                for i, item in enumerate(fetched[:3]):
                                    logger.info(f"ğŸ” [å€ºåˆ¸åˆ—è¡¨] AKShareæ•°æ®æ ·æœ¬ {i+1}: code={item.get('code')}, category={item.get('category')}, name={item.get('name')}")
                                
                                saved_count = await svc.save_basic_list(fetched)
                                logger.info(f"ğŸ’¾ [å€ºåˆ¸åˆ—è¡¨] å·²ä¿å­˜ {saved_count} æ¡å€ºåˆ¸æ•°æ®åˆ°æ•°æ®åº“")
                                
                                # éªŒè¯ï¼šå…ˆä¸å¸¦categoryæ¡ä»¶æŸ¥è¯¢ï¼Œçœ‹çœ‹æ•°æ®æ˜¯å¦å­˜åœ¨
                                try:
                                    test_result = await svc.query_basic_list(q=None, category=None, exchange=exchange, only_not_matured=False, page=1, page_size=5, sort_by=None, sort_dir="asc")
                                    logger.info(f"ğŸ” [å€ºåˆ¸åˆ—è¡¨] éªŒè¯æŸ¥è¯¢ï¼ˆæ— categoryè¿‡æ»¤ï¼‰: total={test_result.get('total', 0)}, items={len(test_result.get('items', []))}")
                                    if test_result.get('items'):
                                        sample = test_result['items'][0]
                                        logger.info(f"ğŸ” [å€ºåˆ¸åˆ—è¡¨] æ•°æ®åº“æ ·æœ¬æ•°æ®: code={sample.get('code')}, category={sample.get('category')}, name={sample.get('name')}")
                                except Exception as test_err:
                                    logger.error(f"âŒ [å€ºåˆ¸åˆ—è¡¨] éªŒè¯æŸ¥è¯¢å¤±è´¥: {test_err}")
                                
                                # æ ‡è®°åˆå§‹åŒ–å®Œæˆï¼Œè®°å½•æ—¶é—´æˆ³
                                _init_completed = True
                                _init_timestamp = datetime.now()
                                logger.info(f"âœ… [å€ºåˆ¸åˆ—è¡¨] æ•°æ®åˆå§‹åŒ–å®Œæˆï¼Œæ—¶é—´æˆ³: {_init_timestamp}")
                                
                                # é‡æ–°æŸ¥è¯¢æ•°æ®åº“
                                try:
                                    result = await svc.query_basic_list(q=q, category=category, exchange=exchange, only_not_matured=only_not_matured, page=page, page_size=page_size, sort_by=sort_by, sort_dir=sort_dir)
                                except TypeError:
                                    # å…¼å®¹è€ç‰ˆæœ¬æœªæ”¯æŒæ’åºå‚æ•°çš„æ–¹æ³•ç­¾å
                                    try:
                                        result = await svc.query_basic_list(q=q, category=category, exchange=exchange, only_not_matured=only_not_matured, page=page, page_size=page_size)  # type: ignore
                                    except TypeError:
                                        # å…¼å®¹æ›´è€ç‰ˆæœ¬æœªæ”¯æŒexchangeå‚æ•°çš„æ–¹æ³•ç­¾å
                                        result = await svc.query_basic_list(q=q, category=category, only_not_matured=only_not_matured, page=page, page_size=page_size)  # type: ignore
                                total = int(result.get("total") or 0)
                                items = list(result.get("items") or [])
                                logger.info(f"âœ… [å€ºåˆ¸åˆ—è¡¨] ä¿å­˜åé‡æ–°æŸ¥è¯¢æ•°æ®åº“: total={total}, items={len(items)}")
                            else:
                                logger.warning(f"âš ï¸ [å€ºåˆ¸åˆ—è¡¨] ä» AKShare è·å–æ•°æ®ä¸ºç©º")
                                _init_completed = True  # å³ä½¿ä¸ºç©ºä¹Ÿæ ‡è®°å®Œæˆï¼Œé¿å…é‡å¤å°è¯•
                                _init_timestamp = datetime.now()  # è®°å½•æ—¶é—´æˆ³ï¼Œè¶…æ—¶åå¯é‡è¯•
                        except Exception as e:
                            logger.error(f"âŒ [å€ºåˆ¸åˆ—è¡¨] ä» AKShare è·å–æ•°æ®å¤±è´¥: {e}", exc_info=True)
                            _init_completed = True  # å¤±è´¥ä¹Ÿæ ‡è®°å®Œæˆï¼Œé¿å…æ— é™é‡è¯•
                            _init_timestamp = datetime.now()  # è®°å½•æ—¶é—´æˆ³ï¼Œè¶…æ—¶åå¯é‡è¯•
                        finally:
                            _init_in_progress = False
        else:
            logger.info(f"âœ… [å€ºåˆ¸åˆ—è¡¨] ä»æ•°æ®åº“è·å– {total} æ¡å€ºåˆ¸æ•°æ® (category={category}, page={page}, items={len(items)})")

        # ç§»é™¤ _id å’Œ ObjectIdï¼Œé¿å…åºåˆ—åŒ–é—®é¢˜
        from bson import ObjectId
        from datetime import datetime as dt, date
        logger.info(f"ğŸ”§ [å€ºåˆ¸åˆ—è¡¨] å¼€å§‹å¤„ç† {len(items)} æ¡æ•°æ®çš„åºåˆ—åŒ–")
        for idx, it in enumerate(items):
            try:
                if isinstance(it, dict):
                    # ç§»é™¤ _id å­—æ®µ
                    if "_id" in it:
                        it.pop("_id", None)
                    # ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¯åºåˆ—åŒ–çš„
                    for key, value in list(it.items()):
                        if value is None:
                            continue
                        # å¤„ç† ObjectId
                        if isinstance(value, ObjectId):
                            it[key] = str(value)
                        # å¤„ç† datetime å’Œ date
                        elif isinstance(value, (dt, date)):
                            it[key] = value.isoformat()
                        # å¤„ç†å…¶ä»–ä¸å¯åºåˆ—åŒ–çš„ç±»å‹
                        elif not isinstance(value, (str, int, float, bool, list, dict)):
                            try:
                                it[key] = str(value)
                            except Exception:
                                it.pop(key, None)
                        # å¤„ç†åµŒå¥—å­—å…¸ä¸­çš„ ObjectId å’Œ datetime
                        elif isinstance(value, dict):
                            for k, v in list(value.items()):
                                if isinstance(v, ObjectId):
                                    value[k] = str(v)
                                elif isinstance(v, (dt, date)):
                                    value[k] = v.isoformat()
                        # å¤„ç†åˆ—è¡¨ä¸­çš„ ObjectId å’Œ datetime
                        elif isinstance(value, list):
                            for i, v in enumerate(value):
                                if isinstance(v, ObjectId):
                                    value[i] = str(v)
                                elif isinstance(v, (dt, date)):
                                    value[i] = v.isoformat()
                                elif isinstance(v, dict):
                                    for k, v2 in list(v.items()):
                                        if isinstance(v2, ObjectId):
                                            v[k] = str(v2)
                                        elif isinstance(v2, (dt, date)):
                                            v[k] = v2.isoformat()
            except Exception as ser_err:
                logger.error(f"âŒ [å€ºåˆ¸åˆ—è¡¨] åºåˆ—åŒ–ç¬¬ {idx} æ¡æ•°æ®å¤±è´¥: {ser_err}", exc_info=True)
                # å¦‚æœæŸæ¡æ•°æ®åºåˆ—åŒ–å¤±è´¥ï¼Œå°è¯•ç§»é™¤é—®é¢˜å­—æ®µæˆ–è·³è¿‡
                try:
                    # å°è¯•å°†æ‰€æœ‰å­—æ®µè½¬ä¸ºå­—ç¬¦ä¸²
                    for k, v in list(it.items()):
                        try:
                            if not isinstance(v, (str, int, float, bool, list, dict)):
                                it[k] = str(v)
                        except:
                            it.pop(k, None)
                except:
                    # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œä»åˆ—è¡¨ä¸­ç§»é™¤è¿™æ¡æ•°æ®
                    logger.warning(f"âš ï¸ [å€ºåˆ¸åˆ—è¡¨] ç§»é™¤æ— æ³•åºåˆ—åŒ–çš„æ•°æ®é¡¹ {idx}")
                    items[idx] = None
        # ç§»é™¤ None é¡¹
        items = [it for it in items if it is not None]
        logger.info(f"âœ… [å€ºåˆ¸åˆ—è¡¨] åºåˆ—åŒ–å®Œæˆï¼Œå‰©ä½™ {len(items)} æ¡æ•°æ®")

        # å…¼å®¹ limitï¼ˆè‹¥è°ƒç”¨æ–¹ä»ä¼ å…¥limitï¼Œåˆ™ä»ç„¶ç”Ÿæ•ˆäºå½“å‰é¡µä¸Šé™ï¼‰
        if limit and len(items) > limit:
            items = items[:limit]

        # æ„å»ºè¿”å›æ•°æ®
        logger.info(f"ğŸ”§ [å€ºåˆ¸åˆ—è¡¨] æ„å»ºå“åº”æ•°æ®: total={total}, items_count={len(items)}")
        try:
            response_data = {"success": True, "data": {"total": total, "page": page, "page_size": page_size, "items": items}}
            logger.info(f"âœ… [å€ºåˆ¸åˆ—è¡¨] å“åº”æ•°æ®æ„å»ºæˆåŠŸ")
        except Exception as build_err:
            logger.error(f"âŒ [å€ºåˆ¸åˆ—è¡¨] æ„å»ºå“åº”æ•°æ®å¤±è´¥: {build_err}", exc_info=True)
            raise
        
        # ç¼“å­˜ç»“æœï¼ˆåªç¼“å­˜æ•°æ®åº“ä¸­æœ‰æ•°æ®çš„æƒ…å†µï¼Œé¿å…ç¼“å­˜ç©ºç»“æœï¼‰
        if total > 0:
            try:
                _bond_list_cache[cache_key] = {
                    "data": response_data,
                    "timestamp": datetime.now()
                }
                # æ¸…ç†è¿‡æœŸç¼“å­˜ï¼ˆä¿æŒç¼“å­˜å¤§å°åˆç†ï¼‰
                if len(_bond_list_cache) > 1000:
                    now = datetime.now()
                    expired_keys = [k for k, v in _bond_list_cache.items() 
                                  if not _is_cache_valid(v)]
                    for k in expired_keys:
                        _bond_list_cache.pop(k, None)
            except Exception as cache_err:
                logger.warning(f"âš ï¸ [å€ºåˆ¸åˆ—è¡¨] ç¼“å­˜æ“ä½œå¤±è´¥: {cache_err}")

        logger.info(f"âœ… [å€ºåˆ¸åˆ—è¡¨] è¯·æ±‚å¤„ç†å®Œæˆï¼Œè¿”å›æ•°æ®")
        return response_data
    except HTTPException:
        # HTTPExceptionåº”è¯¥ç›´æ¥æŠ›å‡ºï¼Œä¸è¦æ•è·
        raise
    except Exception as e:
        logger.error(f"âŒ [å€ºåˆ¸åˆ—è¡¨] å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        import traceback
        error_trace = traceback.format_exc()
        logger.error(f"âŒ [å€ºåˆ¸åˆ—è¡¨] é”™è¯¯å †æ ˆ: {error_trace}")
        # ç¡®ä¿å˜é‡å·²å®šä¹‰
        try:
            page_val = page
        except:
            page_val = 1
        try:
            page_size_val = page_size
        except:
            page_size_val = 20
        # æŠ›å‡ºHTTPExceptionï¼Œè®©å…¨å±€å¼‚å¸¸å¤„ç†å™¨å¤„ç†
        raise HTTPException(
            status_code=500,
            detail=f"è·å–å€ºåˆ¸åˆ—è¡¨å¤±è´¥: {str(e)}"
        )


@router.get("/{code}/history")
async def get_bond_history(
    code: str,
    start: str = Query(..., description="å¼€å§‹æ—¥æœŸ YYYY-MM-DD"),
    end: str = Query(..., description="ç»“æŸæ—¥æœŸ YYYY-MM-DD"),
    period: str = Query("daily", description="å‘¨æœŸï¼Œé»˜è®¤ daily"),
    current_user: dict = Depends(get_current_user),
):
    db = get_mongo_db()
    svc = BondDataService(db)
    await svc.ensure_indexes()
    
    # ä¼˜å…ˆä»æ•°æ®åº“æŸ¥è¯¢å†å²æ•°æ®
    df = await svc.query_bond_daily(code, start, end)
    
    # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®æˆ–æ•°æ®ä¸å®Œæ•´ï¼Œä»æ¥å£è·å–å¹¶ä¿å­˜
    if df is None or df.empty:
        # ä»æ¥å£è·å–æ•°æ®
        result = get_cn_bond_data_unified(code, start, end, period)
        
        # å¦‚æœæ¥å£è¿”å›æˆåŠŸï¼Œå°è¯•ä¿å­˜åˆ°æ•°æ®åº“
        if not result.startswith("âŒ") and not result.startswith("âš ï¸"):
            try:
                # ä½¿ç”¨providerç›´æ¥è·å–DataFrameä»¥ä¾¿ä¿å­˜
                provider = AKShareBondProvider()
                norm = normalize_bond_code(code)
                code_std = norm.get("code_std") or code
                
                # è·å–å†å²æ•°æ®
                hist_df = await provider.get_historical_data(code_std, start, end, period)
                if hist_df is not None and not hist_df.empty:
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    await svc.save_bond_daily(code_std, hist_df)
            except Exception as e:
                # ä¿å­˜å¤±è´¥ä¸å½±å“è¿”å›æ•°æ®
                import logging
                logging.warning(f"ä¿å­˜å€ºåˆ¸å†å²æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {e}")
        
        return {"success": not result.startswith("âŒ"), "data": result}
    else:
        # æ•°æ®åº“ä¸­æœ‰æ•°æ®ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼è¿”å›ï¼ˆä¸æ¥å£æ ¼å¼ä¿æŒä¸€è‡´ï¼‰
        try:
            preview = df.to_string(index=False)
            title = f"## å€ºåˆ¸ {code} å†å²æ•°æ® ({start} åˆ° {end})"
            result = f"{title}\n" + preview
            return {"success": True, "data": result, "from_db": True}
        except Exception as e:
            # è½¬æ¢å¤±è´¥ï¼Œå›é€€åˆ°æ¥å£
            result = get_cn_bond_data_unified(code, start, end, period)
            return {"success": not result.startswith("âŒ"), "data": result}


@router.get("/{code}/analytics")
async def get_bond_analytics(
    code: str,
    start: str = Query(..., description="å¼€å§‹æ—¥æœŸ YYYY-MM-DD"),
    end: str = Query(..., description="ç»“æŸæ—¥æœŸ YYYY-MM-DD"),
    current_user: dict = Depends(get_current_user),
):
    # ç°é˜¶æ®µçš„åˆ†æç»“æœéšå†å²æ•°æ®å­—ç¬¦ä¸²ä¸€èµ·åŒ…å«ï¼ˆå«MA/MACD/RSI/BOLLç­‰ï¼‰ï¼Œå…ˆå¤ç”¨å†å²æ•°æ®æ¥å£
    # ä¼˜å…ˆä»æ•°æ®åº“æŸ¥è¯¢å†å²æ•°æ®
    db = get_mongo_db()
    svc = BondDataService(db)
    await svc.ensure_indexes()
    
    df = await svc.query_bond_daily(code, start, end)
    
    # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®æˆ–æ•°æ®ä¸å®Œæ•´ï¼Œä»æ¥å£è·å–å¹¶ä¿å­˜
    if df is None or df.empty:
        # ä»æ¥å£è·å–æ•°æ®
        result = get_cn_bond_data_unified(code, start, end, period="daily")
        
        # å¦‚æœæ¥å£è¿”å›æˆåŠŸï¼Œå°è¯•ä¿å­˜åˆ°æ•°æ®åº“
        if not result.startswith("âŒ") and not result.startswith("âš ï¸"):
            try:
                # ä½¿ç”¨providerç›´æ¥è·å–DataFrameä»¥ä¾¿ä¿å­˜
                provider = AKShareBondProvider()
                norm = normalize_bond_code(code)
                code_std = norm.get("code_std") or code
                
                # è·å–å†å²æ•°æ®
                hist_df = await provider.get_historical_data(code_std, start, end, period="daily")
                if hist_df is not None and not hist_df.empty:
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    await svc.save_bond_daily(code_std, hist_df)
            except Exception as e:
                # ä¿å­˜å¤±è´¥ä¸å½±å“è¿”å›æ•°æ®
                import logging
                logging.warning(f"ä¿å­˜å€ºåˆ¸å†å²æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {e}")
        
        return {"success": not result.startswith("âŒ"), "data": result}
    else:
        # æ•°æ®åº“ä¸­æœ‰æ•°æ®ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼è¿”å›ï¼ˆä¸æ¥å£æ ¼å¼ä¿æŒä¸€è‡´ï¼‰
        try:
            preview = df.to_string(index=False)
            title = f"## å€ºåˆ¸ {code} å†å²æ•°æ®ä¸åˆ†æ ({start} åˆ° {end})"
            result = f"{title}\n" + preview
            return {"success": True, "data": result, "from_db": True}
        except Exception as e:
            # è½¬æ¢å¤±è´¥ï¼Œå›é€€åˆ°æ¥å£
            result = get_cn_bond_data_unified(code, start, end, period="daily")
            return {"success": not result.startswith("âŒ"), "data": result}


@router.get("/{code}/info")
async def get_bond_info(
    code: str,
    current_user: dict = Depends(get_current_user),
):
    db = get_mongo_db()
    svc = BondDataService(db)
    await svc.ensure_indexes()
    
    # ä¼˜å…ˆä»æ•°æ®åº“æŸ¥è¯¢è¯¦æƒ…ä¿¡æ¯
    info = await svc.query_bond_info(code)
    
    # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼Œä»æ¥å£è·å–å¹¶ä¿å­˜
    if not info or (isinstance(info, dict) and info.get("error")):
        info = get_cn_bond_info_unified(code)
        
        # å¦‚æœæ¥å£è¿”å›çš„æ•°æ®æ ¼å¼ä¸å¯¹ï¼Œå°è¯•ä»åŸºç¡€åˆ—è¡¨è·å–
        if isinstance(info, dict) and info.get("error"):
            # ä»åŸºç¡€åˆ—è¡¨ä¸­æŸ¥æ‰¾
            try:
                result = await svc.query_basic_list(q=code, page=1, page_size=1)
                items = result.get("items", [])
                if items and len(items) > 0:
                    info = items[0]
                    info.pop("_id", None)
            except Exception:
                pass
        
        # å¤„ç†æ¥å£è¿”å›çš„æ ¼å¼ï¼ˆå¦‚æœæ˜¯åµŒå¥—çš„dataå­—æ®µï¼‰
        if isinstance(info, dict) and "data" in info and isinstance(info.get("data"), list) and len(info.get("data", [])) > 0:
            # å°†dataä¸­çš„ç¬¬ä¸€æ¡è®°å½•å±•å¼€
            data_records = info.get("data", [])
            if data_records:
                # ä¿ç•™codeå’Œsourceç­‰å­—æ®µï¼Œåˆå¹¶dataä¸­çš„å­—æ®µ
                code_value = info.get("code", code)
                source_value = info.get("source", "akshare")
                data_item = data_records[0]
                info = {"code": code_value, "source": source_value}
                info.update(data_item)
        
        # å¦‚æœæˆåŠŸè·å–åˆ°æ•°æ®ä¸”æ²¡æœ‰é”™è¯¯ï¼Œä¿å­˜åˆ°æ•°æ®åº“
        if isinstance(info, dict) and not info.get("error"):
            try:
                await svc.save_bond_info_from_api(code, info)
            except Exception as e:
                # ä¿å­˜å¤±è´¥ä¸å½±å“è¿”å›æ•°æ®
                import logging
                logging.warning(f"ä¿å­˜å€ºåˆ¸è¯¦æƒ…åˆ°æ•°æ®åº“å¤±è´¥: {e}")
    
    ok = isinstance(info, dict) and not info.get("error")
    return {"success": ok, "data": info}


@router.get("/yield-curve")
async def get_bond_yield_curve(
    start: Optional[str] = Query(None, description="å¼€å§‹æ—¥æœŸ YYYY-MM-DDï¼Œå¯é€‰"),
    end: Optional[str] = Query(None, description="ç»“æŸæ—¥æœŸ YYYY-MM-DDï¼Œå¯é€‰"),
    curve_name: Optional[str] = Query(None, description="æ›²çº¿åç§°ï¼Œå¯é€‰"),
    format: str = Query("json", description="è¿”å›æ ¼å¼ï¼šjson|text"),
    current_user: dict = Depends(get_current_user),
):
    """è·å–æ”¶ç›Šç‡æ›²çº¿æ•°æ®ï¼Œæ”¯æŒJSONå’Œæ–‡æœ¬ä¸¤ç§æ ¼å¼"""
    db = get_mongo_db()
    svc = BondDataService(db)
    await svc.ensure_indexes()
    
    # ä¼˜å…ˆä»æ•°æ®åº“æŸ¥è¯¢æ”¶ç›Šç‡æ›²çº¿æ•°æ®
    df = await svc.query_yield_curve(start, end, curve_name)
    
    # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®æˆ–æ•°æ®ä¸å®Œæ•´ï¼Œä»æ¥å£è·å–å¹¶ä¿å­˜
    if df is None or df.empty:
        # ä»æ¥å£è·å–æ•°æ®
        result = get_cn_bond_yield_curve_unified(start, end)
        
        # å¦‚æœæ¥å£è¿”å›æˆåŠŸï¼Œå°è¯•ä¿å­˜åˆ°æ•°æ®åº“
        if not result.startswith("âŒ") and not result.startswith("âš ï¸"):
            try:
                # ä½¿ç”¨providerç›´æ¥è·å–DataFrameä»¥ä¾¿ä¿å­˜
                provider = AKShareBondProvider()
                yield_df = await provider.get_yield_curve(start_date=start, end_date=end)
                if yield_df is not None and not yield_df.empty:
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    await svc.save_yield_curve(yield_df)
                    # é‡æ–°æŸ¥è¯¢æ•°æ®åº“
                    df = await svc.query_yield_curve(start, end, curve_name)
            except Exception as e:
                # ä¿å­˜å¤±è´¥ä¸å½±å“è¿”å›æ•°æ®
                import logging
                logging.warning(f"ä¿å­˜æ”¶ç›Šç‡æ›²çº¿æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {e}")
        
        # å¦‚æœä»ç„¶æ²¡æœ‰æ•°æ®ï¼Œè¿”å›æ–‡æœ¬æ ¼å¼
        if format == "text":
            return {"success": not result.startswith("âŒ"), "data": result}
        else:
            return {"success": False, "data": [], "message": "æ— æ•°æ®"}
    else:
        # æ•°æ®åº“ä¸­æœ‰æ•°æ®
        if format == "text":
            # æ–‡æœ¬æ ¼å¼ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
            try:
                preview = df.to_string(index=False)
                rng = f"{start or '-âˆ'} åˆ° {end or '+âˆ'}"
                title = f"## ä¸­å›½å€ºåˆ¸æ”¶ç›Šç‡æ›²çº¿ ({rng})"
                result = f"{title}\n" + preview
                return {"success": True, "data": result, "from_db": True}
            except Exception as e:
                # è½¬æ¢å¤±è´¥ï¼Œå›é€€åˆ°æ¥å£
                result = get_cn_bond_yield_curve_unified(start, end)
                return {"success": not result.startswith("âŒ"), "data": result}
        else:
            # JSONæ ¼å¼ï¼ˆæ–°æ ¼å¼ï¼Œç”¨äºå‰ç«¯å›¾è¡¨ï¼‰
            try:
                # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                records = df.to_dict(orient="records")
                
                # è·å–ç»Ÿè®¡ä¿¡æ¯
                curve_names = df["curve_name"].unique().tolist() if "curve_name" in df.columns else []
                tenors = sorted(df["tenor"].unique().tolist()) if "tenor" in df.columns else []
                dates = sorted(df["date"].unique().tolist()) if "date" in df.columns else []
                
                # æŒ‰æ—¥æœŸå’ŒæœŸé™ç»„ç»‡æ•°æ®ï¼Œä¾¿äºå›¾è¡¨å±•ç¤º
                chart_data = {}
                for record in records:
                    date = record.get("date")
                    tenor = record.get("tenor")
                    curve = record.get("curve_name") or "default"
                    yield_val = record.get("yield")
                    
                    if date not in chart_data:
                        chart_data[date] = {}
                    if curve not in chart_data[date]:
                        chart_data[date][curve] = {}
                    chart_data[date][curve][tenor] = yield_val
                
                return {
                    "success": True,
                    "data": {
                        "records": records,
                        "chart_data": chart_data,
                        "statistics": {
                            "total_records": len(records),
                            "curve_names": curve_names,
                            "tenors": tenors,
                            "date_range": {
                                "start": dates[0] if dates else None,
                                "end": dates[-1] if dates else None,
                                "count": len(dates)
                            }
                        }
                    },
                    "from_db": True
                }
            except Exception as e:
                logger.error(f"è½¬æ¢æ”¶ç›Šç‡æ›²çº¿æ•°æ®å¤±è´¥: {e}", exc_info=True)
                return {"success": False, "error": str(e)}


@router.post("/yield-curve/sync")
async def sync_bond_yield_curve(
    start: Optional[str] = Query(None, description="å¼€å§‹æ—¥æœŸ YYYY-MM-DDï¼Œå¯é€‰"),
    end: Optional[str] = Query(None, description="ç»“æŸæ—¥æœŸ YYYY-MM-DDï¼Œå¯é€‰"),
    current_user: dict = Depends(get_current_user),
):
    provider = AKShareBondProvider()
    df = await provider.get_yield_curve(start, end)
    db = get_mongo_db()
    svc = BondDataService(db)
    await svc.ensure_indexes()
    saved = await svc.save_yield_curve(df)
    return {"success": True, "data": {"saved": saved, "rows": 0 if df is None else len(df)}}


@router.get("/collections")
async def list_bond_collections(
    current_user: dict = Depends(get_current_user),
):
    """è·å–æ‰€æœ‰å€ºåˆ¸ç›¸å…³æ•°æ®é›†åˆåˆ—è¡¨åŠå…¶è¯´æ˜"""
    collections = [
        {
            "name": "bond_info_cm",
            "display_name": "å€ºåˆ¸ä¿¡æ¯æŸ¥è¯¢",
            "description": "ä¸­å›½å¤–æ±‡äº¤æ˜“ä¸­å¿ƒå€ºåˆ¸ä¿¡æ¯æŸ¥è¯¢ï¼Œæ”¯æŒæŒ‰å€ºåˆ¸åç§°ã€ä»£ç ã€å‘è¡Œäººã€å€ºåˆ¸ç±»å‹ã€ä»˜æ¯æ–¹å¼ã€å‘è¡Œå¹´ä»½ã€æ‰¿é”€å•†ã€è¯„çº§ç­‰æ¡ä»¶æŸ¥è¯¢",
            "route": "/bonds/collections/bond_info_cm",
            "fields": ["code", "å€ºåˆ¸ç®€ç§°", "å€ºåˆ¸ä»£ç ", "å‘è¡Œäºº/å—æ‰˜æœºæ„", "å€ºåˆ¸ç±»å‹", "å‘è¡Œæ—¥æœŸ", "æœ€æ–°å€ºé¡¹è¯„çº§", "æŸ¥è¯¢ä»£ç "],
        },
        {
            "name": "bond_basic_info",
            "display_name": "å€ºåˆ¸åŸºç¡€ä¿¡æ¯",
            "description": "å€ºåˆ¸çš„åŸºç¡€ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä»£ç ã€åç§°ã€ç±»åˆ«ã€å‘è¡Œäººã€æ¯ç¥¨ç‡ã€ä¸Šå¸‚æ—¥æœŸã€åˆ°æœŸæ—¥ç­‰",
            "route": "/bonds/collections/bond_basic_info",
            "fields": ["code", "name", "exchange", "category", "issuer", "coupon_rate", "list_date", "maturity_date", "type"],
        },
        {
            "name": "bond_daily",
            "display_name": "å€ºåˆ¸å†å²è¡Œæƒ…",
            "description": "å€ºåˆ¸çš„å†å²è¡Œæƒ…æ•°æ®ï¼ŒåŒ…æ‹¬æ—¥æœŸã€å¼€ç›˜ä»·ã€æœ€é«˜ä»·ã€æœ€ä½ä»·ã€æ”¶ç›˜ä»·ã€æˆäº¤é‡ç­‰",
            "route": "/bonds/collections/bond_daily",
            "fields": ["code", "date", "open", "high", "low", "close", "volume", "amount"],
        },
        {
            "name": "yield_curve_daily",
            "display_name": "æ”¶ç›Šç‡æ›²çº¿",
            "description": "å€ºåˆ¸æ”¶ç›Šç‡æ›²çº¿æ•°æ®ï¼ŒåŒ…æ‹¬æ—¥æœŸã€æ›²çº¿åç§°ã€æœŸé™ã€æ”¶ç›Šç‡ç­‰",
            "route": "/bonds/collections/yield_curve_daily",
            "fields": ["date", "curve_name", "tenor", "yield", "yield_type"],
        },
        {
            "name": "bond_spot_quotes",
            "display_name": "å€ºåˆ¸ç°è´§æŠ¥ä»·",
            "description": "å€ºåˆ¸ç°è´§æŠ¥ä»·æ•°æ®ï¼ŒåŒ…æ‹¬æœ€æ–°ä»·ã€æ¶¨è·Œé¢ã€æ¶¨è·Œå¹…ã€ä¹°å…¥ä»·ã€å–å‡ºä»·ç­‰",
            "route": "/bonds/collections/bond_spot_quotes",
            "fields": ["code", "timestamp", "category", "latest_price", "change", "change_percent", "buy", "sell", "volume", "amount"],
        },
        {
            "name": "bond_minute_quotes",
            "display_name": "å€ºåˆ¸åˆ†é’Ÿæ•°æ®",
            "description": "å€ºåˆ¸åˆ†é’Ÿçº§åˆ†æ—¶è¡Œæƒ…æ•°æ®ï¼ŒåŒ…æ‹¬æ—¶é—´ã€å¼€ç›˜ä»·ã€æœ€é«˜ä»·ã€æœ€ä½ä»·ã€æ”¶ç›˜ä»·ã€æˆäº¤é‡ç­‰",
            "route": "/bonds/collections/bond_minute_quotes",
            "fields": ["code", "datetime", "period", "open", "high", "low", "close", "volume", "amount"],
        },
        {
            "name": "bond_cb_profiles",
            "display_name": "å¯è½¬å€ºæ¡£æ¡ˆ",
            "description": "å¯è½¬å€ºçš„è¯¦ç»†æ¡£æ¡ˆä¿¡æ¯ï¼ŒåŒ…æ‹¬å€ºåˆ¸åŸºæœ¬ä¿¡æ¯ã€è½¬è‚¡æ¡æ¬¾ã€èµå›æ¡æ¬¾ç­‰",
            "route": "/bonds/collections/bond_cb_profiles",
            "fields": ["code", "name", "provider", "endpoint"],
        },
        {
            "name": "bond_cb_valuation_daily",
            "display_name": "å¯è½¬å€ºä¼°å€¼",
            "description": "å¯è½¬å€ºçš„ä»·å€¼åˆ†ææ•°æ®ï¼ŒåŒ…æ‹¬æ—¥æœŸã€æ”¶ç›˜ä»·ã€çº¯å€ºä»·å€¼ã€è½¬è‚¡ä»·å€¼ã€çº¯å€ºæº¢ä»·ç‡ã€è½¬è‚¡æº¢ä»·ç‡ç­‰",
            "route": "/bonds/collections/bond_cb_valuation_daily",
            "fields": ["code", "date", "close", "pure_bond_value", "convert_value", "pure_bond_premium", "convert_premium"],
        },
        {
            "name": "bond_cb_comparison",
            "display_name": "å¯è½¬å€ºæ¯”ä»·è¡¨",
            "description": "å¯è½¬å€ºä¸æ­£è‚¡çš„æ¯”ä»·æ•°æ®ï¼ŒåŒ…æ‹¬è½¬è‚¡ä»·ã€è½¬è‚¡ä»·å€¼ã€è½¬è‚¡æº¢ä»·ç‡ã€å¼ºèµè§¦å‘ä»·ã€å›å”®è§¦å‘ä»·ç­‰",
            "route": "/bonds/collections/bond_cb_comparison",
            "fields": ["code", "date", "convert_price", "convert_value", "convert_premium"],
        },
        {
            "name": "bond_cb_adjustments",
            "display_name": "å¯è½¬å€ºè½¬è‚¡ä»·æ ¼è°ƒæ•´",
            "description": "å¯è½¬å€ºè½¬è‚¡ä»·æ ¼çš„è°ƒæ•´è®°å½•ï¼ŒåŒ…æ‹¬è°ƒæ•´æ—¥æœŸã€è°ƒæ•´å‰è½¬è‚¡ä»·ã€è°ƒæ•´åè½¬è‚¡ä»·ç­‰",
            "route": "/bonds/collections/bond_cb_adjustments",
            "fields": ["code", "date", "before_price", "after_price"],
        },
        {
            "name": "bond_cb_redeems",
            "display_name": "å¯è½¬å€ºå¼ºèµ",
            "description": "å¯è½¬å€ºçš„å¼ºåˆ¶èµå›ä¿¡æ¯ï¼ŒåŒ…æ‹¬å¼ºèµè§¦å‘ä»·ã€å¼ºèµçŠ¶æ€ã€å¼ºèµæ—¥æœŸç­‰",
            "route": "/bonds/collections/bond_cb_redeems",
            "fields": ["code", "redeem_price", "redeem_status", "redeem_date"],
        },
        {
            "name": "bond_issues",
            "display_name": "å€ºåˆ¸å‘è¡Œ",
            "description": "å€ºåˆ¸å‘è¡Œå…¬å‘Šä¿¡æ¯ï¼ŒåŒ…æ‹¬å›½å€ºã€åœ°æ–¹å€ºã€ä¼ä¸šå€ºã€å¯è½¬å€ºç­‰å„ç±»å€ºåˆ¸çš„å‘è¡Œä¿¡æ¯",
            "route": "/bonds/collections/bond_issues",
            "fields": ["code", "issue_type", "date", "issue_amount", "issue_price"],
        },
        {
            "name": "bond_buybacks",
            "display_name": "å€ºåˆ¸å›è´­",
            "description": "å€ºåˆ¸å›è´­æ•°æ®ï¼ŒåŒ…æ‹¬ä¸Šäº¤æ‰€å’Œæ·±äº¤æ‰€çš„è´¨æŠ¼å¼å›è´­è¡Œæƒ…",
            "route": "/bonds/collections/bond_buybacks",
            "fields": ["code", "exchange", "date", "price", "volume"],
        },
        {
            "name": "bond_buybacks_hist",
            "display_name": "å€ºåˆ¸å›è´­å†å²",
            "description": "å€ºåˆ¸å›è´­çš„å†å²æ•°æ®",
            "route": "/bonds/collections/bond_buybacks_hist",
            "fields": ["exchange", "date", "price", "volume"],
        },
        {
            "name": "bond_indices_daily",
            "display_name": "å€ºåˆ¸æŒ‡æ•°",
            "description": "å€ºåˆ¸æŒ‡æ•°æ•°æ®ï¼ŒåŒ…æ‹¬ä¸­å€ºç»¼åˆæŒ‡æ•°ã€ä¸­å€ºæ–°ç»¼åˆæŒ‡æ•°ã€é›†æ€å½•å¯è½¬å€ºç­‰æƒæŒ‡æ•°ç­‰",
            "route": "/bonds/collections/bond_indices_daily",
            "fields": ["index_id", "date", "value"],
        },
        {
            "name": "us_yield_daily",
            "display_name": "ç¾å›½å›½å€ºæ”¶ç›Šç‡",
            "description": "ä¸­ç¾å›½å€ºæ”¶ç›Šç‡å†å²æ•°æ®ï¼ŒåŒ…æ‹¬2å¹´ã€5å¹´ã€10å¹´ã€30å¹´ç­‰æœŸé™çš„æ”¶ç›Šç‡",
            "route": "/bonds/collections/us_yield_daily",
            "fields": ["date", "tenor", "yield"],
        },
        {
            "name": "bond_spot_quote_detail",
            "display_name": "ç°è´§æŠ¥ä»·æ˜ç»†",
            "description": "é“¶è¡Œé—´å¸‚åœºç°åˆ¸æŠ¥ä»·æ˜ç»†ï¼ŒåŒ…æ‹¬æŠ¥ä»·æœºæ„ã€å€ºåˆ¸ç®€ç§°ã€ä¹°å…¥å‡€ä»·ã€å–å‡ºå‡€ä»·ç­‰",
            "route": "/bonds/collections/bond_spot_quote_detail",
            "fields": ["code", "timestamp", "æŠ¥ä»·æœºæ„", "ä¹°å…¥å‡€ä»·", "å–å‡ºå‡€ä»·", "ä¹°å…¥æ”¶ç›Šç‡", "å–å‡ºæ”¶ç›Šç‡"],
        },
        {
            "name": "bond_spot_deals",
            "display_name": "ç°è´§æˆäº¤æ˜ç»†",
            "description": "é“¶è¡Œé—´å¸‚åœºç°åˆ¸æˆäº¤æ˜ç»†ï¼ŒåŒ…æ‹¬å€ºåˆ¸ç®€ç§°ã€æˆäº¤å‡€ä»·ã€æœ€æ–°æ”¶ç›Šç‡ã€æ¶¨è·Œç­‰",
            "route": "/bonds/collections/bond_spot_deals",
            "fields": ["code", "timestamp", "æˆäº¤å‡€ä»·", "æœ€æ–°æ”¶ç›Šç‡", "æ¶¨è·Œ", "åŠ æƒæ”¶ç›Šç‡", "äº¤æ˜“é‡"],
        },
        {
            "name": "bond_deal_summary",
            "display_name": "æˆäº¤æ¦‚è§ˆ",
            "description": "ä¸Šäº¤æ‰€å€ºåˆ¸æˆäº¤æ¦‚è§ˆï¼ŒåŒ…æ‹¬å€ºåˆ¸ç±»å‹ã€å½“æ—¥æˆäº¤ç¬”æ•°ã€å½“æ—¥æˆäº¤é‡‘é¢ç­‰",
            "route": "/bonds/collections/bond_deal_summary",
            "fields": ["date", "å€ºåˆ¸ç±»å‹", "å½“æ—¥æˆäº¤ç¬”æ•°", "å½“æ—¥æˆäº¤é‡‘é¢", "å½“å¹´æˆäº¤ç¬”æ•°", "å½“å¹´æˆäº¤é‡‘é¢"],
        },
        {
            "name": "bond_cash_summary",
            "display_name": "ç°åˆ¸å¸‚åœºæ¦‚è§ˆ",
            "description": "ä¸Šäº¤æ‰€å€ºåˆ¸ç°åˆ¸å¸‚åœºæ¦‚è§ˆï¼ŒåŒ…æ‹¬å€ºåˆ¸ç°è´§ã€æ‰˜ç®¡åªæ•°ã€æ‰˜ç®¡å¸‚å€¼ã€æ‰˜ç®¡é¢å€¼ç­‰",
            "route": "/bonds/collections/bond_cash_summary",
            "fields": ["date", "å€ºåˆ¸ç°è´§", "æ‰˜ç®¡åªæ•°", "æ‰˜ç®¡å¸‚å€¼", "æ‰˜ç®¡é¢å€¼"],
        },
        {
            "name": "bond_nafmii_debts",
            "display_name": "é“¶è¡Œé—´å¸‚åœºå€ºåŠ¡",
            "description": "é“¶è¡Œé—´å¸‚åœºéé‡‘èä¼ä¸šå€ºåŠ¡èèµ„å·¥å…·æ³¨å†Œä¿¡æ¯ï¼ŒåŒ…æ‹¬å€ºåˆ¸åç§°ã€å“ç§ã€é‡‘é¢ã€æ³¨å†Œé€šçŸ¥ä¹¦æ–‡å·ç­‰",
            "route": "/bonds/collections/bond_nafmii_debts",
            "fields": ["code", "å€ºåˆ¸åç§°", "å“ç§", "é‡‘é¢", "æ³¨å†Œé€šçŸ¥ä¹¦æ–‡å·", "æ›´æ–°æ—¥æœŸ", "é¡¹ç›®çŠ¶æ€"],
        },
        {
            "name": "bond_cov_list",
            "display_name": "å¯è½¬å€ºåˆ—è¡¨",
            "description": "ä¸œæ–¹è´¢å¯Œå¯è½¬å€ºæ•°æ®ä¸€è§ˆè¡¨ï¼ŒåŒ…æ‹¬å€ºåˆ¸ä»£ç ã€å€ºåˆ¸ç®€ç§°ã€ç”³è´­æ—¥æœŸã€è½¬è‚¡ä»·ç­‰",
            "route": "/bonds/collections/bond_cov_list",
            "fields": ["code", "å€ºåˆ¸ä»£ç ", "å€ºåˆ¸ç®€ç§°", "ç”³è´­æ—¥æœŸ", "è½¬è‚¡ä»·", "è½¬è‚¡ä»·å€¼", "è½¬è‚¡æº¢ä»·ç‡"],
        },
        {
            "name": "bond_cb_list_jsl",
            "display_name": "é›†æ€å½•å¯è½¬å€º",
            "description": "é›†æ€å½•å¯è½¬å€ºå®æ—¶æ•°æ®ï¼ŒåŒ…æ‹¬è¡Œæƒ…æ•°æ®å’ŒåŸºæœ¬ä¿¡æ¯",
            "route": "/bonds/collections/bond_cb_list_jsl",
            "fields": ["code", "è½¬å€ºåç§°", "ç°ä»·", "æ¶¨è·Œå¹…", "è½¬è‚¡ä»·", "è½¬è‚¡ä»·å€¼", "è½¬è‚¡æº¢ä»·ç‡"],
        },
        {
            "name": "bond_cb_summary",
            "display_name": "å¯è½¬å€ºå€ºåˆ¸æ¦‚å†µ",
            "description": "æ–°æµªè´¢ç»å¯è½¬å€ºå€ºåˆ¸æ¦‚å†µæ•°æ®",
            "route": "/bonds/collections/bond_cb_summary",
            "fields": ["code", "å€ºåˆ¸ç±»å‹", "ç¥¨é¢åˆ©ç‡", "å‘è¡Œä»·æ ¼", "å‘è¡Œè§„æ¨¡", "åˆ°æœŸæ—¥æœŸ"],
        },
        {
            "name": "bond_events",
            "display_name": "å€ºåˆ¸äº‹ä»¶",
            "description": "å€ºåˆ¸ç›¸å…³äº‹ä»¶è®°å½•ï¼ŒåŒ…æ‹¬è°ƒæ•´ã€èµå›ã€ä»˜æ¯ç­‰å„ç±»äº‹ä»¶",
            "route": "/bonds/collections/bond_events",
            "fields": ["code", "date", "event_type", "description"],
        },
        {
            "name": "yield_curve_map",
            "display_name": "æ”¶ç›Šç‡æ›²çº¿æ˜ å°„",
            "description": "æ”¶ç›Šç‡æ›²çº¿å¯è§†åŒ–æ˜ å°„æ•°æ®ï¼Œç”¨äºæ”¶ç›Šç‡æ›²çº¿çš„å›¾å½¢å±•ç¤º",
            "route": "/bonds/collections/yield_curve_map",
            "fields": ["date", "æ›²çº¿æ•°æ®"],
        },
    ]
    return {"success": True, "data": collections}


@router.get("/collections/{collection_name}")
async def get_collection_data(
    collection_name: str,
    page: int = Query(1, ge=1, description="é¡µç ï¼Œä»1å¼€å§‹"),
    page_size: int = Query(50, ge=1, le=500, description="æ¯é¡µæ•°é‡ï¼Œé»˜è®¤50"),
    sort_by: Optional[str] = Query(None, description="æ’åºå­—æ®µ"),
    sort_dir: str = Query("desc", description="æ’åºæ–¹å‘ï¼šasc|desc"),
    filter_field: Optional[str] = Query(None, description="è¿‡æ»¤å­—æ®µ"),
    filter_value: Optional[str] = Query(None, description="è¿‡æ»¤å€¼"),
    current_user: dict = Depends(get_current_user),
):
    """è·å–æŒ‡å®šé›†åˆçš„æ•°æ®ï¼ˆåˆ†é¡µï¼‰"""
    db = get_mongo_db()
    svc = BondDataService(db)
    
    # è·å–é›†åˆ
    collection_map = {
        "bond_basic_info": svc.col_basic,
        "bond_daily": svc.col_daily,
        "yield_curve_daily": svc.col_curve,
        "bond_spot_quotes": svc.col_spot,
        "bond_minute_quotes": svc.col_minute,
        "bond_cb_profiles": svc.col_cb_profiles,
        "bond_cb_valuation_daily": svc.col_cb_valuation,
        "bond_cb_comparison": svc.col_cb_comparison,
        "bond_cb_adjustments": svc.col_cb_adjustments,
        "bond_cb_redeems": svc.col_cb_redeems,
        "bond_issues": svc.col_issues,
        "bond_buybacks": svc.col_buybacks,
        "bond_buybacks_hist": svc.col_buybacks_hist,
        "bond_indices_daily": svc.col_indices,
        "us_yield_daily": svc.col_us_yield,
        "bond_spot_quote_detail": svc.col_spot_quote_detail,
        "bond_spot_deals": svc.col_spot_deals,
        "bond_deal_summary": svc.col_deal_summary,
        "bond_cash_summary": svc.col_cash_summary,
        "bond_nafmii_debts": svc.col_nafmii,
        "bond_info_cm": svc.col_info_cm,
        "bond_cov_list": svc.col_cov_list,
        "bond_cb_list_jsl": svc.col_cb_list_jsl,
        "bond_cb_summary": svc.col_cb_summary,
        "bond_events": svc.col_events,
        "yield_curve_map": svc.col_curve_map,
    }
    
    collection = collection_map.get(collection_name)
    if collection is None:
        return {"success": False, "error": f"é›†åˆ {collection_name} ä¸å­˜åœ¨"}
    
    try:
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        query = {}
        
        # å¯¹äº bond_info_cm é›†åˆï¼ŒåªæŸ¥è¯¢æ ‡å‡†æ•°æ®è®°å½•ï¼Œä¸æŸ¥è¯¢è¯¦ç»†æŸ¥è¯¢è®°å½•
        # è¿™æ ·å¯ä»¥ç¡®ä¿åˆ—è¡¨é¡µé¢ä¸ä¼šæ˜¾ç¤ºè¯¦ç»†æŸ¥è¯¢æ•°æ®ï¼ˆ60+ä¸ªè‹±æ–‡å­—æ®µï¼‰
        if collection_name == "bond_info_cm":
            query["endpoint"] = "bond_info_cm"
        
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿ filter_field å’Œ filter_value éƒ½æ˜¯å­—ç¬¦ä¸²ä¸”éç©º
        # æ³¨æ„ï¼šéœ€è¦å…ˆæ£€æŸ¥ç±»å‹ï¼Œé¿å…å¯¹Collectionå¯¹è±¡è¿›è¡Œå¸ƒå°”è¿ç®—
        # ä½¿ç”¨try-exceptå’Œtype()æ£€æŸ¥ï¼Œå®Œå…¨é¿å…å¸ƒå°”è¿ç®—
        try:
            # å…ˆæ£€æŸ¥ç±»å‹ï¼Œä½¿ç”¨type()è€Œä¸æ˜¯isinstance()ä»¥é¿å…å¸ƒå°”è¿ç®—
            # å¿…é¡»å…ˆæ£€æŸ¥ç±»å‹ï¼Œä¸èƒ½å…ˆè¿›è¡Œå¸ƒå°”è¿ç®—ï¼ˆåŒ…æ‹¬orè¡¨è¾¾å¼ï¼‰
            filter_field_type = type(filter_field) if filter_field is not None else None
            filter_value_type = type(filter_value) if filter_value is not None else None
            
            # åªæœ‰å½“ä¸¤ä¸ªå‚æ•°éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹æ—¶æ‰å¤„ç†
            if filter_field_type is str and filter_value_type is str:
                # ç°åœ¨å¯ä»¥å®‰å…¨åœ°è°ƒç”¨strip()
                filter_field_stripped = filter_field.strip()
                filter_value_stripped = filter_value.strip()
                # æ£€æŸ¥stripåçš„ç»“æœæ˜¯å¦ä¸ºç©ºï¼ˆå­—ç¬¦ä¸²å¯ä»¥ç›´æ¥è¿›è¡Œå¸ƒå°”è¿ç®—ï¼‰
                if filter_field_stripped and filter_value_stripped:
                    # æ”¯æŒæ¨¡ç³ŠæŸ¥è¯¢
                    if filter_field_stripped in ["code", "name", "å€ºåˆ¸ç®€ç§°", "å€ºåˆ¸ä»£ç "]:
                        query[filter_field_stripped] = {"$regex": filter_value_stripped, "$options": "i"}
                    else:
                        query[filter_field_stripped] = filter_value_stripped
        except (AttributeError, NotImplementedError, TypeError) as filter_err:
            # å¦‚æœfilter_fieldæˆ–filter_valueä¸æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼ˆå¯èƒ½æ˜¯Collectionå¯¹è±¡ï¼‰ï¼Œå¿½ç•¥è¿‡æ»¤
            logger.warning(f"âš ï¸ [é›†åˆæ•°æ®] è¿‡æ»¤å‚æ•°æ— æ•ˆï¼Œå°†å¿½ç•¥: {filter_err}")
            pass
        
        # è·å–æ€»æ•°
        total = await collection.count_documents(query)
        
        # æ„å»ºæ’åº
        # é»˜è®¤æŒ‰æ—¥æœŸå€’åºï¼Œå¦‚æœæ²¡æœ‰æ—¥æœŸå­—æ®µåˆ™æŒ‰_idå€’åº
        default_sort_key = None
        for date_field in ["date", "datetime", "timestamp", "æ›´æ–°æ—¥æœŸ", "å‘è¡Œæ—¥æœŸ", "ä¸Šå¸‚æ—¥æœŸ"]:
            # æ£€æŸ¥é›†åˆä¸­æ˜¯å¦æœ‰è¯¥å­—æ®µçš„æ–‡æ¡£
            test_doc = await collection.find_one({date_field: {"$exists": True}})
            if test_doc is not None:
                default_sort_key = date_field
                break
        
        # æ˜¾å¼é€‰æ‹©æ’åºé”®ï¼Œé¿å…ä½¿ç”¨ or é“¾å¼•å‘çš„éšå¼å¸ƒå°”æ±‚å€¼
        if sort_by is not None:
            sort_key = sort_by
        elif default_sort_key is not None:
            sort_key = default_sort_key
        else:
            sort_key = "_id"
        sort_direction = -1 if sort_dir == "desc" else 1
        
        # åˆ†é¡µæŸ¥è¯¢
        skip = (page - 1) * page_size
        cursor = collection.find(query).sort(sort_key, sort_direction).skip(skip).limit(page_size)
        items = []
        
        async for doc in cursor:
            # ç§»é™¤ _id æˆ–è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            if "_id" in doc:
                doc["_id"] = str(doc["_id"])
            items.append(doc)
        
        # è·å–å­—æ®µä¿¡æ¯ï¼ˆä»å½“å‰é¡µçš„è®°å½•æ”¶é›†ï¼‰
        # æ‰€æœ‰é¡µé¢ä½¿ç”¨ç»Ÿä¸€çš„å­—æ®µæ”¶é›†é€»è¾‘
        fields_info = []
        if items:
            field_map = {}  # {field_name: {"type": str, "example": str}}
            
            # ä»å½“å‰é¡µçš„æ‰€æœ‰è®°å½•æ”¶é›†å­—æ®µ
            for item in items:
                # å¯¹äº bond_info_cm é›†åˆï¼Œåªä»æ ‡å‡†æ•°æ®è®°å½•æ”¶é›†å­—æ®µï¼Œå¿½ç•¥è¯¦ç»†æŸ¥è¯¢è®°å½•
                # bond_info_cm é›†åˆåŒ…å«ä¸¤ç§æ•°æ®ï¼š
                # - æ ‡å‡†æ•°æ®ï¼ˆendpoint="bond_info_cm"ï¼‰: 10ä¸ªä¸­æ–‡å­—æ®µï¼Œç”¨äºåˆ—è¡¨æ˜¾ç¤º
                # - è¯¦ç»†æŸ¥è¯¢æ•°æ®ï¼ˆendpoint="bond_info_cm_query"ï¼‰: 60+ä¸ªè‹±æ–‡å­—æ®µï¼Œç”¨äºè¯¦æƒ…é¡µ
                # ä¸ºäº†ä¿è¯ç¬¬ä¸€é¡µå’Œç¬¬äºŒé¡µæ˜¾ç¤ºä¸€è‡´ï¼Œåªä»æ ‡å‡†æ•°æ®æ”¶é›†å­—æ®µ
                if collection_name == "bond_info_cm":
                    item_endpoint = item.get("endpoint", "")
                    if item_endpoint != "bond_info_cm":
                        # è·³è¿‡è¯¦ç»†æŸ¥è¯¢è®°å½•ï¼Œä¸ä»ä¸­æ”¶é›†å­—æ®µ
                        continue
                
                for key, value in item.items():
                    if key != "_id" and key not in field_map:
                        field_type = type(value).__name__
                        if field_type == "int":
                            field_type = "æ•´æ•°"
                        elif field_type == "float":
                            field_type = "æµ®ç‚¹æ•°"
                        elif field_type == "bool":
                            field_type = "å¸ƒå°”å€¼"
                        elif field_type == "list":
                            field_type = "åˆ—è¡¨"
                        elif field_type == "dict":
                            field_type = "å¯¹è±¡"
                        else:
                            field_type = "å­—ç¬¦ä¸²"
                        
                        field_map[key] = {
                            "name": key,
                            "type": field_type,
                            "example": str(value)[:50] if value is not None else None,
                        }
            
            # è½¬æ¢ä¸ºåˆ—è¡¨
            fields_info = list(field_map.values())
        
        # å¯¹äº bond_info_cm é›†åˆï¼Œåªæ˜¾ç¤ºæ ‡å‡†å­—æ®µï¼ˆä¸­æ–‡å­—æ®µï¼‰ï¼Œå¿½ç•¥è¯¦ç»†æŸ¥è¯¢çš„è‹±æ–‡å­—æ®µ
        if collection_name == "bond_info_cm" and fields_info:
            # å®šä¹‰æ ‡å‡†æ˜¾ç¤ºå­—æ®µï¼ˆæŒ‰æ˜¾ç¤ºé¡ºåºï¼‰
            standard_fields = [
                "å€ºåˆ¸ä»£ç ",
                "å€ºåˆ¸ç®€ç§°", 
                "å€ºåˆ¸ç±»å‹",
                "å‘è¡Œäºº/å—æ‰˜æœºæ„",
                "å‘è¡Œæ—¥æœŸ",
                "æœ€æ–°å€ºé¡¹è¯„çº§",
                "æŸ¥è¯¢ä»£ç ",
                "endpoint",
                "code",
                "source"
            ]
            
            # åªä¿ç•™æ ‡å‡†å­—æ®µï¼ˆæŒ‰å®šä¹‰çš„é¡ºåºï¼‰
            ordered_fields = []
            field_dict = {f["name"]: f for f in fields_info}
            
            for field_name in standard_fields:
                if field_name in field_dict:
                    ordered_fields.append(field_dict[field_name])
            
            # å¦‚æœæ ‡å‡†å­—æ®µä¸å­˜åœ¨ï¼ˆå¯èƒ½æ˜¯æ–°æ•°æ®ï¼‰ï¼Œä¿ç•™æ‰€æœ‰ä¸­æ–‡å­—æ®µ
            if len(ordered_fields) < 5:
                logger.warning(f"âš ï¸ [é›†åˆæ•°æ®] bond_info_cmæœªæ‰¾åˆ°æ ‡å‡†å­—æ®µï¼Œä½¿ç”¨æ‰€æœ‰ä¸­æ–‡å­—æ®µ")
                # åˆ†ç¦»ä¸­æ–‡å­—æ®µå’Œå…¶ä»–å­—æ®µ
                chinese_fields = [f for f in fields_info if any('\u4e00' <= c <= '\u9fff' for c in f["name"])]
                meta_fields = [f for f in fields_info if f["name"] in ["endpoint", "code", "source"]]
                ordered_fields = chinese_fields + meta_fields
            
            fields_info = ordered_fields
            logger.info(f"âœ… [é›†åˆæ•°æ®] bond_info_cmæ˜¾ç¤º{len(fields_info)}ä¸ªæ ‡å‡†å­—æ®µ")
        
        return {
            "success": True,
            "data": {
                "items": items,
                "total": total,
                "page": page,
                "page_size": page_size,
                "fields": fields_info,
            },
        }
    except Exception as e:
        logger.error(f"è·å–é›†åˆ {collection_name} æ•°æ®å¤±è´¥: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


@router.get("/collections/{collection_name}/stats")
async def get_collection_stats(
    collection_name: str,
    current_user: dict = Depends(get_current_user),
):
    """è·å–æŒ‡å®šé›†åˆçš„ç»Ÿè®¡ä¿¡æ¯"""
    db = get_mongo_db()
    svc = BondDataService(db)
    
    collection_map = {
        "bond_basic_info": svc.col_basic,
        "bond_daily": svc.col_daily,
        "yield_curve_daily": svc.col_curve,
        "bond_spot_quotes": svc.col_spot,
        "bond_minute_quotes": svc.col_minute,
        "bond_cb_profiles": svc.col_cb_profiles,
        "bond_cb_valuation_daily": svc.col_cb_valuation,
        "bond_cb_comparison": svc.col_cb_comparison,
        "bond_cb_adjustments": svc.col_cb_adjustments,
        "bond_cb_redeems": svc.col_cb_redeems,
        "bond_issues": svc.col_issues,
        "bond_buybacks": svc.col_buybacks,
        "bond_buybacks_hist": svc.col_buybacks_hist,
        "bond_indices_daily": svc.col_indices,
        "us_yield_daily": svc.col_us_yield,
        "bond_spot_quote_detail": svc.col_spot_quote_detail,
        "bond_spot_deals": svc.col_spot_deals,
        "bond_deal_summary": svc.col_deal_summary,
        "bond_cash_summary": svc.col_cash_summary,
        "bond_nafmii_debts": svc.col_nafmii,
        "bond_info_cm": svc.col_info_cm,
        "bond_cov_list": svc.col_cov_list,
        "bond_cb_list_jsl": svc.col_cb_list_jsl,
        "bond_cb_summary": svc.col_cb_summary,
        "bond_events": svc.col_events,
        "yield_curve_map": svc.col_curve_map,
    }
    
    collection = collection_map.get(collection_name)
    if collection is None:
        return {"success": False, "error": f"é›†åˆ {collection_name} ä¸å­˜åœ¨"}
    
    try:
        logger.info(f"ğŸ“Š [é›†åˆç»Ÿè®¡] å¼€å§‹è·å–é›†åˆ {collection_name} çš„ç»Ÿè®¡ä¿¡æ¯")
        
        # æ€»è®°å½•æ•°
        try:
            total_count = await collection.count_documents({})
            logger.info(f"ğŸ“Š [é›†åˆç»Ÿè®¡] é›†åˆ {collection_name} æ€»è®°å½•æ•°: {total_count}")
        except Exception as count_err:
            logger.error(f"âŒ [é›†åˆç»Ÿè®¡] è·å–æ€»è®°å½•æ•°å¤±è´¥: {count_err}", exc_info=True)
            total_count = 0
        
        # è·å–æœ€æ—©å’Œæœ€æ™šçš„æ—¥æœŸï¼ˆå¦‚æœæœ‰dateæˆ–datetimeå­—æ®µï¼‰
        stats = {
            "total_count": total_count,
            "collection_name": collection_name,
        }
        
        # å°è¯•è·å–æ—¥æœŸèŒƒå›´
        date_fields = ["date", "datetime", "timestamp", "æ›´æ–°æ—¥æœŸ", "å‘è¡Œæ—¥æœŸ", "ä¸Šå¸‚æ—¥æœŸ"]
        for date_field in date_fields:
            try:
                # æŸ¥æ‰¾æœ‰è¯¥å­—æ®µçš„æ–‡æ¡£
                first_doc = await collection.find_one({date_field: {"$exists": True}}, sort=[(date_field, 1)])
                last_doc = await collection.find_one({date_field: {"$exists": True}}, sort=[(date_field, -1)])
                
                if first_doc is not None and last_doc is not None:
                    first_date = first_doc.get(date_field)
                    last_date = last_doc.get(date_field)
                    if first_date:
                        stats["earliest_date"] = str(first_date)[:10]
                    if last_date:
                        stats["latest_date"] = str(last_date)[:10]
                    stats["date_field"] = date_field
                    logger.info(f"ğŸ“Š [é›†åˆç»Ÿè®¡] æ‰¾åˆ°æ—¥æœŸå­—æ®µ {date_field}: {stats.get('earliest_date')} - {stats.get('latest_date')}")
                    break
            except Exception as date_err:
                logger.debug(f"âš ï¸ [é›†åˆç»Ÿè®¡] è·å–æ—¥æœŸå­—æ®µ {date_field} å¤±è´¥: {date_err}")
                continue
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰categoryå­—æ®µï¼‰
        try:
            pipeline = [
                {"$group": {"_id": "$category", "count": {"$sum": 1}}},
                {"$sort": {"count": -1}},
            ]
            category_stats = []
            async for doc in collection.aggregate(pipeline):
                category_id = doc.get("_id")
                count = doc.get("count", 0)
                category_stats.append({
                    "category": str(category_id) if category_id is not None else "æœªçŸ¥",
                    "count": int(count)
                })
            if len(category_stats) > 0:
                stats["category_stats"] = category_stats
                logger.info(f"ğŸ“Š [é›†åˆç»Ÿè®¡] æ‰¾åˆ° {len(category_stats)} ä¸ªç±»åˆ«")
        except Exception as cat_err:
            logger.debug(f"âš ï¸ [é›†åˆç»Ÿè®¡] è·å–ç±»åˆ«ç»Ÿè®¡å¤±è´¥: {cat_err}")
            pass
        
        # æŒ‰äº¤æ˜“æ‰€ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰exchangeå­—æ®µï¼‰
        try:
            pipeline = [
                {"$group": {"_id": "$exchange", "count": {"$sum": 1}}},
                {"$sort": {"count": -1}},
            ]
            exchange_stats = []
            async for doc in collection.aggregate(pipeline):
                exchange_id = doc.get("_id")
                count = doc.get("count", 0)
                exchange_stats.append({
                    "exchange": str(exchange_id) if exchange_id is not None else "æœªçŸ¥",
                    "count": int(count)
                })
            if len(exchange_stats) > 0:
                stats["exchange_stats"] = exchange_stats
                logger.info(f"ğŸ“Š [é›†åˆç»Ÿè®¡] æ‰¾åˆ° {len(exchange_stats)} ä¸ªäº¤æ˜“æ‰€")
        except Exception as exch_err:
            logger.debug(f"âš ï¸ [é›†åˆç»Ÿè®¡] è·å–äº¤æ˜“æ‰€ç»Ÿè®¡å¤±è´¥: {exch_err}")
            pass

        # bond_info_cm ä¸“ç”¨ç»Ÿè®¡ï¼šæŒ‰â€œå€ºåˆ¸ç±»å‹â€å’Œâ€œæœ€æ–°å€ºé¡¹è¯„çº§â€ç»Ÿè®¡
        if collection_name == "bond_info_cm":
            # å€ºåˆ¸ç±»å‹åˆ†å¸ƒ
            try:
                pipeline = [
                    {
                        "$match": {
                            "$and": [
                                {"$or": [{"endpoint": "bond_info_cm"}, {"endpoint": {"$exists": False}}]},
                                {"å€ºåˆ¸ç±»å‹": {"$exists": True, "$ne": ""}},
                            ]
                        }
                    },
                    {"$group": {"_id": "$å€ºåˆ¸ç±»å‹", "count": {"$sum": 1}}},
                    {"$sort": {"count": -1}},
                ]
                bond_type_stats: List[Dict[str, Any]] = []
                async for doc in collection.aggregate(pipeline):
                    type_id = doc.get("_id")
                    count = int(doc.get("count", 0))
                    bond_type_stats.append(
                        {"type": str(type_id) if type_id is not None else "æœªçŸ¥", "count": count}
                    )
                if bond_type_stats:
                    stats["bond_type_stats"] = bond_type_stats
                    logger.info(f"ğŸ“Š [é›†åˆç»Ÿè®¡] bond_info_cm å€ºåˆ¸ç±»å‹ç»Ÿè®¡é¡¹æ•°: {len(bond_type_stats)}")
            except Exception as type_err:
                logger.debug(f"âš ï¸ [é›†åˆç»Ÿè®¡] è·å–å€ºåˆ¸ç±»å‹ç»Ÿè®¡å¤±è´¥: {type_err}")

            # æœ€æ–°å€ºé¡¹è¯„çº§åˆ†å¸ƒ
            try:
                pipeline = [
                    {
                        "$match": {
                            "$and": [
                                {"$or": [{"endpoint": "bond_info_cm"}, {"endpoint": {"$exists": False}}]},
                                {"æœ€æ–°å€ºé¡¹è¯„çº§": {"$exists": True, "$ne": ""}},
                            ]
                        }
                    },
                    {"$group": {"_id": "$æœ€æ–°å€ºé¡¹è¯„çº§", "count": {"$sum": 1}}},
                    {"$sort": {"count": -1}},
                ]
                grade_stats: List[Dict[str, Any]] = []
                async for doc in collection.aggregate(pipeline):
                    grade_id = doc.get("_id")
                    count = int(doc.get("count", 0))
                    grade_stats.append(
                        {"grade": str(grade_id) if grade_id is not None else "æœªçŸ¥", "count": count}
                    )
                if grade_stats:
                    stats["grade_stats"] = grade_stats
                    logger.info(f"ğŸ“Š [é›†åˆç»Ÿè®¡] bond_info_cm æœ€æ–°å€ºé¡¹è¯„çº§ç»Ÿè®¡é¡¹æ•°: {len(grade_stats)}")
            except Exception as grade_err:
                logger.debug(f"âš ï¸ [é›†åˆç»Ÿè®¡] è·å–å€ºé¡¹è¯„çº§ç»Ÿè®¡å¤±è´¥: {grade_err}")

        logger.info(f"âœ… [é›†åˆç»Ÿè®¡] é›†åˆ {collection_name} ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ")
        return {"success": True, "data": stats}
    except HTTPException:
        # HTTPExceptionåº”è¯¥ç›´æ¥æŠ›å‡º
        raise
    except Exception as e:
        logger.error(f"âŒ [é›†åˆç»Ÿè®¡] è·å–é›†åˆ {collection_name} ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)
        import traceback
        error_trace = traceback.format_exc()
        logger.error(f"âŒ [é›†åˆç»Ÿè®¡] é”™è¯¯å †æ ˆ: {error_trace}")
        raise HTTPException(
            status_code=500,
            detail=f"è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"
        )


@router.get("/collections/bond_info_cm/issuance/yearly")
async def get_bond_info_cm_yearly_issuance(
    current_user: dict = Depends(get_current_user),
):
    """ç»Ÿè®¡ bond_info_cm é›†åˆæŒ‰å¹´ä»½çš„å€ºåˆ¸å‘è¡Œæ•°é‡"""
    db = get_mongo_db()
    svc = BondDataService(db)

    pipeline = [
        {"$match": {"endpoint": "bond_info_cm", "å‘è¡Œæ—¥æœŸ": {"$exists": True, "$ne": ""}}},
        {"$addFields": {"year": {"$substr": ["$å‘è¡Œæ—¥æœŸ", 0, 4]}}},
        {"$match": {"year": {"$regex": "^[0-9]{4}$"}}},
        {"$group": {"_id": "$year", "count": {"$sum": 1}}},
        {"$sort": {"_id": 1}},
    ]

    try:
        results: List[Dict[str, Any]] = []
        async for doc in svc.col_info_cm.aggregate(pipeline):
            year = str(doc.get("_id", ""))
            count = int(doc.get("count", 0))
            results.append({"year": year, "count": count})

        return {
            "success": True,
            "data": {
                "items": results,
                "total_years": len(results)
            }
        }
    except Exception as e:
        logger.error(f"âŒ [bond_info_cm] è·å–å¹´åº¦å‘è¡Œç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"è·å–å¹´åº¦å‘è¡Œç»Ÿè®¡å¤±è´¥: {str(e)}"
        )




# å€ºåˆ¸åˆ†æç›¸å…³æ¨¡å‹
class BondAnalysisRequest(BaseModel):
    bond_code: str
    parameters: Optional[Dict[str, Any]] = {}


@router.post("/analysis")
async def start_bond_analysis(
    request: BondAnalysisRequest,
    background_tasks: BackgroundTasks,
    current_user: dict = Depends(get_current_user),
):
    """æäº¤å€ºåˆ¸åˆ†æä»»åŠ¡"""
    try:
        logger.info(f"ğŸ¯ æ”¶åˆ°å€ºåˆ¸åˆ†æè¯·æ±‚: {request.bond_code}")
        
        # éªŒè¯å€ºåˆ¸ä»£ç æ ¼å¼
        bond_code = request.bond_code.strip()
        import re
        if not re.match(r'^\d{6}\.(SH|SZ|IB)$', bond_code, re.IGNORECASE):
            raise HTTPException(status_code=400, detail="å€ºåˆ¸ä»£ç æ ¼å¼ä¸æ­£ç¡®ï¼Œåº”ä¸ºï¼šä»£ç .äº¤æ˜“æ‰€ï¼ˆå¦‚ï¼š110062.SHï¼‰")
        
        # åˆ›å»ºä»»åŠ¡ID
        task_id = str(uuid.uuid4())
        
        # å¯¼å…¥åˆ†ææœåŠ¡
        from app.services.bond_analysis_service import get_bond_analysis_service
        service = get_bond_analysis_service()
        
        # åˆ›å»ºä»»åŠ¡è®°å½•
        result = await service.create_analysis_task(
            user_id=current_user["id"],
            task_id=task_id,
            request=request
        )
        
        # åœ¨åå°æ‰§è¡Œåˆ†æä»»åŠ¡
        async def run_analysis_task():
            try:
                logger.info(f"ğŸš€ [BackgroundTask] å¼€å§‹æ‰§è¡Œå€ºåˆ¸åˆ†æä»»åŠ¡: {task_id}")
                await service.execute_analysis_background(task_id, current_user["id"], request)
                logger.info(f"âœ… [BackgroundTask] å€ºåˆ¸åˆ†æä»»åŠ¡å®Œæˆ: {task_id}")
            except Exception as e:
                logger.error(f"âŒ [BackgroundTask] å€ºåˆ¸åˆ†æä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {e}", exc_info=True)
        
        background_tasks.add_task(run_analysis_task)
        
        return {
            "success": True,
            "data": {"task_id": task_id},
            "message": "åˆ†æä»»åŠ¡å·²åœ¨åå°å¯åŠ¨"
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æäº¤å€ºåˆ¸åˆ†æä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/analysis/{task_id}/status")
async def get_bond_analysis_status(
    task_id: str,
    current_user: dict = Depends(get_current_user),
):
    """è·å–å€ºåˆ¸åˆ†æä»»åŠ¡çŠ¶æ€"""
    try:
        from app.services.bond_analysis_service import get_bond_analysis_service
        service = get_bond_analysis_service()
        
        status = await service.get_task_status(task_id)
        
        if not status:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        return {
            "success": True,
            "data": status
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–å€ºåˆ¸åˆ†æä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/analysis/{task_id}/result")
async def get_bond_analysis_result(
    task_id: str,
    current_user: dict = Depends(get_current_user),
):
    """è·å–å€ºåˆ¸åˆ†æç»“æœ"""
    try:
        from app.services.bond_analysis_service import get_bond_analysis_service
        service = get_bond_analysis_service()
        
        result = await service.get_task_result(task_id)
        
        if not result:
            raise HTTPException(status_code=404, detail="åˆ†æç»“æœä¸å­˜åœ¨")
        
        return {
            "success": True,
            "data": result
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–å€ºåˆ¸åˆ†æç»“æœå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/collections/{collection_name}/refresh")
async def refresh_collection_data(
    collection_name: str,
    background_tasks: BackgroundTasks,
    start_date: Optional[str] = Query(None, description="å¼€å§‹æ—¥æœŸ YYYY-MM-DDï¼ˆå¯é€‰ï¼Œä»…é€‚ç”¨äºæŸäº›é›†åˆï¼‰"),
    end_date: Optional[str] = Query(None, description="ç»“æŸæ—¥æœŸ YYYY-MM-DDï¼ˆå¯é€‰ï¼Œä»…é€‚ç”¨äºæŸäº›é›†åˆï¼‰"),
    date: Optional[str] = Query(None, description="æŒ‡å®šæ—¥æœŸ YYYY-MM-DDï¼ˆå¯é€‰ï¼Œç”¨äºå•æ—¥æœŸé›†åˆï¼‰"),
    # bond_info_cm ç‰¹å®šå‚æ•°
    bond_name: Optional[str] = Query(None, description="å€ºåˆ¸åç§°ï¼ˆbond_info_cmä¸“ç”¨ï¼‰"),
    bond_code: Optional[str] = Query(None, description="å€ºåˆ¸ä»£ç ï¼ˆbond_info_cmä¸“ç”¨ï¼‰"),
    bond_issue: Optional[str] = Query(None, description="å‘è¡Œäººï¼ˆbond_info_cmä¸“ç”¨ï¼‰"),
    bond_type: Optional[str] = Query(None, description="å€ºåˆ¸ç±»å‹ï¼ˆbond_info_cmä¸“ç”¨ï¼‰"),
    coupon_type: Optional[str] = Query(None, description="ä»˜æ¯æ–¹å¼ï¼ˆbond_info_cmä¸“ç”¨ï¼‰"),
    issue_year: Optional[str] = Query(None, description="å‘è¡Œå¹´ä»½ï¼ˆbond_info_cmä¸“ç”¨ï¼‰"),
    underwriter: Optional[str] = Query(None, description="æ‰¿é”€å•†ï¼ˆbond_info_cmä¸“ç”¨ï¼‰"),
    grade: Optional[str] = Query(None, description="è¯„çº§ï¼ˆbond_info_cmä¸“ç”¨ï¼‰"),
    current_user: dict = Depends(get_current_user),
):
    """ä»AKShareæ›´æ–°æŒ‡å®šé›†åˆçš„æ•°æ®ï¼ˆå¼‚æ­¥æ‰§è¡Œï¼Œæ”¯æŒè¿›åº¦æŸ¥è¯¢ï¼‰
    
    æ”¯æŒçš„å‚æ•°å› é›†åˆè€Œå¼‚ï¼š
    - bond_info_cm: æ”¯æŒ bond_name, bond_code, bond_issue, bond_type, coupon_type, issue_year, underwriter, grade
    - yield_curve_daily, bond_daily: æ”¯æŒ start_date, end_date
    - bond_cash_summary, bond_deal_summary: æ”¯æŒ date
    """
    try:
        logger.info(f"ğŸ”„ åˆ›å»ºé›†åˆæ›´æ–°ä»»åŠ¡: {collection_name}")
        
        db = get_mongo_db()
        svc = BondDataService(db)
        refresh_service = CollectionRefreshService(svc)
        task_manager = get_task_manager()
        
        # å‡†å¤‡å‚æ•°å­—å…¸
        params = {
            "start_date": start_date,
            "end_date": end_date,
            "date": date,
            "bond_name": bond_name,
            "bond_code": bond_code,
            "bond_issue": bond_issue,
            "bond_type": bond_type,
            "coupon_type": coupon_type,
            "issue_year": issue_year,
            "underwriter": underwriter,
            "grade": grade,
        }
        
        # åˆ›å»ºä»»åŠ¡
        task_id = task_manager.create_task(
            task_type=f"refresh_{collection_name}",
            description=f"æ›´æ–°é›†åˆ: {collection_name}"
        )
        
        # åœ¨åå°å¼‚æ­¥æ‰§è¡Œåˆ·æ–°ä»»åŠ¡
        async def do_refresh():
            try:
                await refresh_service.refresh_collection(
                    collection_name, task_id, params
                )
            except Exception as e:
                logger.error(f"åå°åˆ·æ–°ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
                # ç¡®ä¿ä»»åŠ¡çŠ¶æ€è¢«æ ‡è®°ä¸ºå¤±è´¥
                try:
                    task_manager.fail_task(task_id, str(e))
                except Exception as inner_e:
                    logger.error(f"æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {inner_e}", exc_info=True)
        
        background_tasks.add_task(do_refresh)
        
        # ç«‹å³è¿”å›ä»»åŠ¡IDï¼Œå‰ç«¯å¯ä»¥ç”¨æ­¤IDæŸ¥è¯¢è¿›åº¦
        return {
            "success": True,
            "data": {
                "task_id": task_id,
                "message": f"ä»»åŠ¡å·²åˆ›å»ºï¼Œè¯·ä½¿ç”¨ task_id æŸ¥è¯¢è¿›åº¦"
            }
        }
    
    except Exception as e:
        error_msg = f"åˆ›å»ºæ›´æ–°ä»»åŠ¡å¤±è´¥: {str(e)}"
        logger.error(f"âŒ {error_msg}", exc_info=True)
        raise HTTPException(status_code=500, detail=error_msg)


@router.get("/collections/refresh/task/{task_id}")
async def get_refresh_task_status(
    task_id: str,
    current_user: dict = Depends(get_current_user),
):
    """æŸ¥è¯¢æ•°æ®åˆ·æ–°ä»»åŠ¡çš„è¿›åº¦"""
    try:
        task_manager = get_task_manager()
        task = task_manager.get_task(task_id)
        
        if not task:
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨")
        
        return {"success": True, "data": task}
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/collections/{collection_name}/import")
async def import_collection_data(
    collection_name: str,
    file: UploadFile = File(..., description="CSV æˆ– Excel æ–‡ä»¶"),
    current_user: dict = Depends(get_current_user),
):
    """ä»æ–‡ä»¶å¯¼å…¥å€ºåˆ¸é›†åˆæ•°æ®ï¼ˆç›®å‰ä»…æ”¯æŒ bond_info_cmï¼‰"""
    try:
        logger.info(f"ğŸ“¥ [é›†åˆå¯¼å…¥] collection={collection_name}, filename={file.filename}")

        if collection_name != "bond_info_cm":
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="å½“å‰ä»…æ”¯æŒ bond_info_cm é›†åˆçš„æ–‡ä»¶å¯¼å…¥",
            )

        db = get_mongo_db()
        if db is None:
            raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")

        svc = BondDataService(db)
        content = await file.read()
        filename = file.filename or ""

        result = await svc.import_bond_info_cm_from_file(content, filename)
        saved = int(result.get("saved") or 0)
        rows = int(result.get("rows") or 0)

        message = f"æˆåŠŸå¯¼å…¥ {saved} æ¡è®°å½•" if rows > 0 else "æ–‡ä»¶ä¸­æ²¡æœ‰å¯å¯¼å…¥çš„æ•°æ®"

        return {
            "success": True,
            "data": {
                "collection_name": collection_name,
                "saved": saved,
                "rows": rows,
                "message": message,
            },
        }
    except HTTPException:
        raise
    except ValueError as ve:
        logger.warning(f"âš ï¸ [é›†åˆå¯¼å…¥] å‚æ•°é”™è¯¯: {ve}")
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(ve))
    except Exception as e:
        logger.error(f"âŒ [é›†åˆå¯¼å…¥] å¯¼å…¥é›†åˆ {collection_name} å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å¯¼å…¥æ•°æ®å¤±è´¥: {str(e)}")


@router.post("/collections/{collection_name}/sync-remote")
async def sync_collection_from_remote(
    collection_name: str,
    remote_host: str = Query(..., description="è¿œç¨‹ MongoDB ä¸»æœºåœ°å€æˆ– URI"),
    db_type: str = Query("mongodb", description="æ•°æ®åº“ç±»å‹ï¼Œç›®å‰ä»…æ”¯æŒ mongodb"),
    batch_size: int = Query(5000, ge=100, le=100000, description="æ¯æ‰¹æ¬¡åŒæ­¥æ•°é‡"),
    remote_collection: Optional[str] = Query(None, description="è¿œç¨‹é›†åˆåç§°ï¼Œé»˜è®¤ä¸ºæœ¬åœ°é›†åˆå"),
    remote_username: Optional[str] = Query(None, description="è¿œç¨‹æ•°æ®åº“ç”¨æˆ·å"),
    remote_password: Optional[str] = Query(None, description="è¿œç¨‹æ•°æ®åº“å¯†ç "),
    remote_auth_source: Optional[str] = Query(None, description="è¿œç¨‹è®¤è¯åº“ï¼ˆauthSourceï¼‰ï¼Œé»˜è®¤ä¸ºç›®æ ‡æ•°æ®åº“å"),
    current_user: dict = Depends(get_current_user),
):
    """ä»è¿œç¨‹æ•°æ®åº“åŒæ­¥é›†åˆæ•°æ®åˆ°æœ¬åœ°ï¼ˆå½“å‰ä»…æ”¯æŒ bond_info_cm åŠ MongoDBï¼‰ã€‚"""
    try:
        logger.info(
            f"ğŸ“¡ [é›†åˆè¿œç¨‹åŒæ­¥] collection={collection_name}, remote_host={remote_host}, db_type={db_type}, batch_size={batch_size}"
        )

        if collection_name != "bond_info_cm":
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="å½“å‰ä»…æ”¯æŒ bond_info_cm é›†åˆçš„è¿œç¨‹åŒæ­¥",
            )

        if not remote_host:
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="è¿œç¨‹ä¸»æœºåœ°å€ä¸èƒ½ä¸ºç©º")

        if (db_type or "mongodb").lower() != "mongodb":
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="å½“å‰ä»…æ”¯æŒ MongoDB è¿œç¨‹åŒæ­¥")

        db = get_mongo_db()
        if db is None:
            raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")

        svc = BondDataService(db)
        result = await svc.sync_collection_from_remote_mongo(
            collection_name=collection_name,
            remote_host=remote_host,
            batch_size=batch_size,
            remote_collection=remote_collection,
            remote_username=remote_username,
            remote_password=remote_password,
            remote_auth_source=remote_auth_source,
        )

        synced = int(result.get("synced") or 0)
        remote_total = int(result.get("remote_total") or 0)

        message = f"æˆåŠŸä»è¿œç¨‹åŒæ­¥ {synced} æ¡è®°å½•ï¼ˆè¿œç¨‹å…± {remote_total} æ¡ï¼‰"

        return {
            "success": True,
            "data": {
                "collection_name": collection_name,
                "synced": synced,
                "remote_total": remote_total,
                "batch_size": batch_size,
                "message": message,
            },
        }
    except HTTPException:
        raise
    except ValueError as ve:
        logger.warning(f"âš ï¸ [é›†åˆè¿œç¨‹åŒæ­¥] å‚æ•°é”™è¯¯: {ve}")
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(ve))
    except Exception as e:
        logger.error(f"âŒ [é›†åˆè¿œç¨‹åŒæ­¥] åŒæ­¥é›†åˆ {collection_name} å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è¿œç¨‹åŒæ­¥å¤±è´¥: {str(e)}")


@router.delete("/collections/{collection_name}/clear")
async def clear_collection_data(
    collection_name: str,
    current_user: dict = Depends(get_current_user),
):
    """æ¸…ç©ºé›†åˆæ•°æ®
    
    åˆ é™¤æŒ‡å®šé›†åˆä¸­çš„æ‰€æœ‰æ•°æ®ï¼Œæ­¤æ“ä½œä¸å¯æ¢å¤
    """
    try:
        logger.info(f"âš ï¸  [æ¸…ç©ºé›†åˆ] æ”¶åˆ°æ¸…ç©ºè¯·æ±‚: collection={collection_name}, user={current_user.get('username')}")
        
        db = get_mongo_db()
        if db is None:
            raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")
        
        # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
        if collection_name not in await db.list_collection_names():
            raise HTTPException(status_code=404, detail=f"é›†åˆ {collection_name} ä¸å­˜åœ¨")
        
        # æ¸…ç©ºé›†åˆæ•°æ®
        collection = db[collection_name]
        result = await collection.delete_many({})
        deleted_count = result.deleted_count
        
        logger.info(f"âœ… [æ¸…ç©ºé›†åˆ] æˆåŠŸæ¸…ç©º {collection_name}ï¼Œåˆ é™¤äº† {deleted_count} æ¡è®°å½•")
        
        return {
            "success": True,
            "data": {
                "collection_name": collection_name,
                "deleted_count": deleted_count,
                "message": f"æˆåŠŸæ¸…ç©ºé›†åˆ {collection_name}ï¼Œåˆ é™¤äº† {deleted_count} æ¡è®°å½•"
            }
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æ¸…ç©ºé›†åˆå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== å¯è½¬å€ºä¸“é¡¹åŠŸèƒ½ ====================

@router.get("/convertible/comparison")
async def get_convertible_comparison(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(50, ge=1, le=200, description="æ¯é¡µæ•°é‡"),
    q: Optional[str] = Query(None, description="æœç´¢å…³é”®è¯ï¼ˆä»£ç æˆ–åç§°ï¼‰"),
    sort_by: Optional[str] = Query(None, description="æ’åºå­—æ®µ"),
    sort_dir: str = Query("asc", description="æ’åºæ–¹å‘ï¼šasc/desc"),
    min_premium: Optional[float] = Query(None, description="æœ€å°è½¬è‚¡æº¢ä»·ç‡"),
    max_premium: Optional[float] = Query(None, description="æœ€å¤§è½¬è‚¡æº¢ä»·ç‡"),
    current_user: dict = Depends(get_current_user),
):
    """è·å–å¯è½¬å€ºæ¯”ä»·è¡¨
    
    è¿”å›å¯è½¬å€ºçš„å®æ—¶æ¯”ä»·æ•°æ®ï¼ŒåŒ…æ‹¬è½¬è‚¡ä»·ã€è½¬è‚¡ä»·å€¼ã€æº¢ä»·ç‡ç­‰æ ¸å¿ƒæŒ‡æ ‡
    æ”¯æŒå…³é”®è¯æœç´¢ã€æº¢ä»·ç‡èŒƒå›´è¿‡æ»¤ã€æ’åºå’Œåˆ†é¡µ
    """
    try:
        logger.info(f"ğŸ” [å¯è½¬å€ºæ¯”ä»·] æ”¶åˆ°è¯·æ±‚: page={page}, page_size={page_size}, q={q}, "
                   f"premium_range=[{min_premium}, {max_premium}]")
        
        db = get_mongo_db()
        if db is None:
            raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")
        
        svc = BondDataService(db)
        
        # æŸ¥è¯¢æ•°æ®ï¼ˆåœ¨æ•°æ®åº“å±‚è¿‡æ»¤ï¼Œæ€§èƒ½æ›´å¥½ï¼‰
        result = await svc.query_cov_comparison(
            q=q,
            sort_by=sort_by,
            sort_dir=sort_dir,
            page=page,
            page_size=page_size,
            min_premium=min_premium,
            max_premium=max_premium
        )
        
        logger.info(f"âœ… [å¯è½¬å€ºæ¯”ä»·] è¿”å› {len(result.get('items', []))}/{result.get('total', 0)} æ¡æ•°æ®")
        
        return {
            "success": True,
            "data": {
                "total": result.get("total", 0),
                "page": page,
                "page_size": page_size,
                "items": result.get("items", [])
            }
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºæ¯”ä»·] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/convertible/comparison/sync")
async def sync_convertible_comparison(
    current_user: dict = Depends(get_current_user),
):
    """åŒæ­¥å¯è½¬å€ºæ¯”ä»·æ•°æ®
    
    ä»AKShareè·å–æœ€æ–°çš„å¯è½¬å€ºæ¯”ä»·è¡¨æ•°æ®å¹¶ä¿å­˜åˆ°æ•°æ®åº“
    """
    try:
        logger.info(f"ğŸ”„ [å¯è½¬å€ºæ¯”ä»·åŒæ­¥] å¼€å§‹åŒæ­¥æ•°æ®")
        
        from tradingagents.dataflows.providers.china.bonds import AKShareBondProvider
        
        provider = AKShareBondProvider()
        df = await provider.get_cov_comparison()
        
        if df is None or df.empty:
            logger.warning("âš ï¸ [å¯è½¬å€ºæ¯”ä»·åŒæ­¥] æœªè·å–åˆ°æ•°æ®")
            raise HTTPException(status_code=404, detail="æœªè·å–åˆ°æ•°æ®")
        
        logger.info(f"ğŸ“¡ [å¯è½¬å€ºæ¯”ä»·åŒæ­¥] è·å–åˆ° {len(df)} æ¡æ•°æ®")
        
        db = get_mongo_db()
        if db is None:
            raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")
        
        svc = BondDataService(db)
        saved = await svc.save_cov_comparison(df)
        
        logger.info(f"âœ… [å¯è½¬å€ºæ¯”ä»·åŒæ­¥] æˆåŠŸä¿å­˜ {saved} æ¡æ•°æ®")
        
        return {
            "success": True,
            "data": {
                "saved": saved,
                "total": len(df),
                "message": f"æˆåŠŸåŒæ­¥ {saved} æ¡å¯è½¬å€ºæ¯”ä»·æ•°æ®"
            }
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºæ¯”ä»·åŒæ­¥] å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/convertible/{code}/value-analysis")
async def get_convertible_value_analysis(
    code: str,
    start_date: Optional[str] = Query(None, description="å¼€å§‹æ—¥æœŸ YYYY-MM-DD"),
    end_date: Optional[str] = Query(None, description="ç»“æŸæ—¥æœŸ YYYY-MM-DD"),
    current_user: dict = Depends(get_current_user),
):
    """è·å–å¯è½¬å€ºä»·å€¼åˆ†æå†å²æ•°æ®
    
    è¿”å›æŒ‡å®šå¯è½¬å€ºçš„å†å²ä»·å€¼åˆ†ææ•°æ®ï¼ŒåŒ…æ‹¬çº¯å€ºä»·å€¼ã€è½¬è‚¡ä»·å€¼ã€æº¢ä»·ç‡èµ°åŠ¿ç­‰
    """
    try:
        logger.info(f"ğŸ” [å¯è½¬å€ºä»·å€¼åˆ†æ] æŸ¥è¯¢ {code}")
        
        db = get_mongo_db()
        if db is None:
            raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")
        
        svc = BondDataService(db)
        
        # æŸ¥è¯¢æ•°æ®åº“
        result = await svc.query_cov_value_analysis(
            code=code,
            start_date=start_date,
            end_date=end_date
        )
        
        # å¦‚æœæ•°æ®åº“æ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä»AKShareè·å–
        if not result.get("data"):
            logger.info(f"ğŸ“¡ [å¯è½¬å€ºä»·å€¼åˆ†æ] æ•°æ®åº“æ— æ•°æ®ï¼Œä»AKShareè·å–")
            
            from tradingagents.dataflows.providers.china.bonds import AKShareBondProvider
            provider = AKShareBondProvider()
            df = await provider.get_cov_value_analysis(code)
            
            if df is not None and not df.empty:
                # ä¿å­˜åˆ°æ•°æ®åº“
                saved = await svc.save_cov_value_analysis(code, df)
                logger.info(f"ğŸ’¾ [å¯è½¬å€ºä»·å€¼åˆ†æ] ä¿å­˜ {saved} æ¡æ•°æ®")
                
                # é‡æ–°æŸ¥è¯¢
                result = await svc.query_cov_value_analysis(
                    code=code,
                    start_date=start_date,
                    end_date=end_date
                )
        
        logger.info(f"âœ… [å¯è½¬å€ºä»·å€¼åˆ†æ] è¿”å› {len(result.get('data', []))} æ¡æ•°æ®")
        
        return {
            "success": True,
            "data": result
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [å¯è½¬å€ºä»·å€¼åˆ†æ] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/convertible/{code}/value-analysis/sync")
async def sync_convertible_value_analysis(
    code: str,
    current_user: dict = Depends(get_current_user),
):
    """åŒæ­¥æŒ‡å®šå¯è½¬å€ºçš„ä»·å€¼åˆ†ææ•°æ®"""
    try:
        logger.info(f"ğŸ”„ [ä»·å€¼åˆ†æåŒæ­¥] åŒæ­¥ {code}")
        
        from tradingagents.dataflows.providers.china.bonds import AKShareBondProvider
        
        provider = AKShareBondProvider()
        df = await provider.get_cov_value_analysis(code)
        
        if df is None or df.empty:
            raise HTTPException(status_code=404, detail="æœªè·å–åˆ°æ•°æ®")
        
        db = get_mongo_db()
        if db is None:
            raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")
        
        svc = BondDataService(db)
        saved = await svc.save_cov_value_analysis(code, df)
        
        logger.info(f"âœ… [ä»·å€¼åˆ†æåŒæ­¥] ä¿å­˜ {saved} æ¡æ•°æ®")
        
        return {
            "success": True,
            "data": {
                "saved": saved,
                "total": len(df),
                "message": f"æˆåŠŸåŒæ­¥ {saved} æ¡ä»·å€¼åˆ†ææ•°æ®"
            }
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [ä»·å€¼åˆ†æåŒæ­¥] å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/market/spot-deals")
async def get_spot_deals(
    current_user: dict = Depends(get_current_user),
):
    """è·å–ç°åˆ¸å¸‚åœºæˆäº¤è¡Œæƒ…
    
    è¿”å›é“¶è¡Œé—´ç°åˆ¸å¸‚åœºçš„å®æ—¶æˆäº¤æ•°æ®
    """
    try:
        logger.info(f"ğŸ” [ç°åˆ¸æˆäº¤] æŸ¥è¯¢æˆäº¤è¡Œæƒ…")
        
        from tradingagents.dataflows.providers.china.bonds import AKShareBondProvider
        
        provider = AKShareBondProvider()
        df = await provider.get_spot_deal()
        
        if df is None or df.empty:
            raise HTTPException(status_code=404, detail="æœªè·å–åˆ°æ•°æ®")
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        items = df.to_dict(orient="records")
        
        # æ¸…ç†NaNå€¼
        import math
        for item in items:
            for key, value in list(item.items()):
                if isinstance(value, float) and math.isnan(value):
                    item[key] = None
        
        logger.info(f"âœ… [ç°åˆ¸æˆäº¤] è¿”å› {len(items)} æ¡æ•°æ®")
        
        return {
            "success": True,
            "data": {
                "total": len(items),
                "items": items
            }
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [ç°åˆ¸æˆäº¤] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/market/spot-quotes")
async def get_spot_quotes(
    current_user: dict = Depends(get_current_user),
):
    """è·å–ç°åˆ¸å¸‚åœºåšå¸‚æŠ¥ä»·
    
    è¿”å›é“¶è¡Œé—´ç°åˆ¸å¸‚åœºçš„åšå¸‚å•†æŠ¥ä»·æ•°æ®
    """
    try:
        logger.info(f"ğŸ” [ç°åˆ¸æŠ¥ä»·] æŸ¥è¯¢åšå¸‚æŠ¥ä»·")
        
        from tradingagents.dataflows.providers.china.bonds import AKShareBondProvider
        
        provider = AKShareBondProvider()
        df = await provider.get_spot_quote()
        
        if df is None or df.empty:
            raise HTTPException(status_code=404, detail="æœªè·å–åˆ°æ•°æ®")
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        items = df.to_dict(orient="records")
        
        # æ¸…ç†NaNå€¼
        import math
        for item in items:
            for key, value in list(item.items()):
                if isinstance(value, float) and math.isnan(value):
                    item[key] = None
        
        logger.info(f"âœ… [ç°åˆ¸æŠ¥ä»·] è¿”å› {len(items)} æ¡æ•°æ®")
        
        return {
            "success": True,
            "data": {
                "total": len(items),
                "items": items
            }
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [ç°åˆ¸æŠ¥ä»·] æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/admin/reset-init")
async def reset_initialization(
    current_user: dict = Depends(get_current_user),
):
    """ç®¡ç†ç«¯ç‚¹ï¼šé‡ç½®å€ºåˆ¸æ•°æ®åˆå§‹åŒ–çŠ¶æ€
    
    å½“æ•°æ®åˆå§‹åŒ–å‡ºç°é—®é¢˜æ—¶ï¼Œå¯ä»¥é€šè¿‡æ­¤ç«¯ç‚¹æ‰‹åŠ¨é‡ç½®åˆå§‹åŒ–çŠ¶æ€ï¼Œ
    å…è®¸ç³»ç»Ÿé‡æ–°ä»AKShareè·å–æ•°æ®ã€‚
    
    æ³¨æ„ï¼šä»…ç®¡ç†å‘˜åº”è¯¥ä½¿ç”¨æ­¤ç«¯ç‚¹
    """
    global _init_completed, _init_timestamp, _init_in_progress
    
    try:
        logger.warning(f"âš ï¸ [ç®¡ç†] ç”¨æˆ· {current_user.get('username')} è¯·æ±‚é‡ç½®åˆå§‹åŒ–çŠ¶æ€")
        
        old_status = {
            "completed": _init_completed,
            "timestamp": _init_timestamp.isoformat() if _init_timestamp else None,
            "in_progress": _init_in_progress
        }
        
        # é‡ç½®çŠ¶æ€
        _init_completed = False
        _init_timestamp = None
        # ä¸é‡ç½® _init_in_progressï¼Œé¿å…å¹²æ‰°æ­£åœ¨è¿›è¡Œçš„åˆå§‹åŒ–
        
        logger.info(f"âœ… [ç®¡ç†] åˆå§‹åŒ–çŠ¶æ€å·²é‡ç½®")
        
        return {
            "success": True,
            "message": "åˆå§‹åŒ–çŠ¶æ€å·²é‡ç½®ï¼Œä¸‹æ¬¡æŸ¥è¯¢å°†é‡æ–°è·å–æ•°æ®",
            "old_status": old_status,
            "new_status": {
                "completed": _init_completed,
                "timestamp": None,
                "in_progress": _init_in_progress
            }
        }
    
    except Exception as e:
        logger.error(f"âŒ [ç®¡ç†] é‡ç½®åˆå§‹åŒ–çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== å€ºåˆ¸åŸºç¡€ä¿¡æ¯æ‰¹é‡æ›´æ–°API ====================

@router.post("/basic-info/batch-update")
async def start_bond_basic_batch_update(
    batch_size: int = Query(1000, ge=100, le=5000, description="æ¯æ‰¹å¤„ç†çš„æ•°é‡"),
    concurrent_threads: int = Query(3, ge=1, le=10, description="å¹¶å‘çº¿ç¨‹æ•°"),
    save_interval: int = Query(1000, ge=500, le=2000, description="ä¿å­˜é—´éš”"),
    current_user: dict = Depends(get_current_user),
):
    """
    å¯åŠ¨å€ºåˆ¸åŸºç¡€ä¿¡æ¯æ‰¹é‡æ›´æ–°
    
    ä»bond_info_cmè¡¨æŸ¥è¯¢å€ºåˆ¸ç®€ç§°ï¼Œç„¶åè·å–è¯¦ç»†ä¿¡æ¯æ›´æ–°åˆ°bond_info_detail_cmä¸­ã€‚
    é‡‡ç”¨å¤šçº¿ç¨‹æ‰¹é‡æ›´æ–°ï¼Œæ¯è·å–æŒ‡å®šæ•°é‡çš„æ•°æ®ä¿å­˜åˆ°é›†åˆä¸€æ¬¡ã€‚
    """
    try:
        from app.services.bond_basic_info_service import BondBasicInfoService
        
        db = get_mongo_db()
        service = BondBasicInfoService(db)
        
        logger.info(f"ğŸš€ [æ‰¹é‡æ›´æ–°API] ç”¨æˆ· {current_user.get('username')} å¯åŠ¨å€ºåˆ¸åŸºç¡€ä¿¡æ¯æ‰¹é‡æ›´æ–°")
        logger.info(f"ğŸ“Š [æ‰¹é‡æ›´æ–°API] å‚æ•°: batch_size={batch_size}, threads={concurrent_threads}, save_interval={save_interval}")
        
        # æ‰§è¡Œæ‰¹é‡æ›´æ–°
        result = await service.batch_update_from_bond_info_cm(
            batch_size=batch_size,
            concurrent_threads=concurrent_threads,
            save_interval=save_interval
        )
        
        if result.get("success"):
            logger.info(f"âœ… [æ‰¹é‡æ›´æ–°API] æ‰¹é‡æ›´æ–°å®Œæˆ: {result.get('message')}")
            return {"success": True, "data": result}
        else:
            logger.error(f"âŒ [æ‰¹é‡æ›´æ–°API] æ‰¹é‡æ›´æ–°å¤±è´¥: {result.get('error')}")
            raise HTTPException(status_code=500, detail=result.get("error"))
            
    except Exception as e:
        logger.error(f"âŒ [æ‰¹é‡æ›´æ–°API] æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/basic-info/incremental-update")
async def start_bond_basic_incremental_update(
    current_user: dict = Depends(get_current_user),
):
    """
    å¯åŠ¨å€ºåˆ¸åŸºç¡€ä¿¡æ¯å¢é‡æ›´æ–°
    
    ä»bond_info_cmé›†åˆä¸­æŸ¥è¯¢å€ºåˆ¸ç®€ç§°ï¼Œç„¶åä»bond_info_detail_cmé›†åˆä¸­è·å–å·²æœ‰çš„å€ºåˆ¸ä»£ç ï¼Œ
    æ‰¾å‡ºç¼ºå¤±çš„å€ºåˆ¸åŸºç¡€ä¿¡æ¯å¹¶æ›´æ–°åˆ°é›†åˆä¸­ã€‚
    """
    try:
        from app.services.bond_basic_info_service import BondBasicInfoService
        
        db = get_mongo_db()
        service = BondBasicInfoService(db)
        
        logger.info(f"ğŸ” [å¢é‡æ›´æ–°API] ç”¨æˆ· {current_user.get('username')} å¯åŠ¨å€ºåˆ¸åŸºç¡€ä¿¡æ¯å¢é‡æ›´æ–°")
        
        # æ‰§è¡Œå¢é‡æ›´æ–°
        result = await service.incremental_update_missing_info()
        
        if result.get("success"):
            logger.info(f"âœ… [å¢é‡æ›´æ–°API] å¢é‡æ›´æ–°å®Œæˆ: {result.get('message')}")
            return {"success": True, "data": result}
        else:
            logger.error(f"âŒ [å¢é‡æ›´æ–°API] å¢é‡æ›´æ–°å¤±è´¥: {result.get('error')}")
            raise HTTPException(status_code=500, detail=result.get("error"))
            
    except Exception as e:
        logger.error(f"âŒ [å¢é‡æ›´æ–°API] æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/basic-info/update-statistics")
async def get_bond_basic_update_statistics(
    current_user: dict = Depends(get_current_user),
):
    """
    è·å–å€ºåˆ¸åŸºç¡€ä¿¡æ¯æ›´æ–°ç»Ÿè®¡
    
    è¿”å›bond_info_cmå’Œbond_info_detail_cmçš„è®°å½•æ•°é‡ã€è¦†ç›–ç‡ç­‰ç»Ÿè®¡ä¿¡æ¯ã€‚
    """
    try:
        from app.services.bond_basic_info_service import BondBasicInfoService
        
        db = get_mongo_db()
        service = BondBasicInfoService(db)
        
        logger.debug(f"ğŸ“Š [ç»Ÿè®¡API] ç”¨æˆ· {current_user.get('username')} æŸ¥è¯¢å€ºåˆ¸åŸºç¡€ä¿¡æ¯æ›´æ–°ç»Ÿè®¡")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        result = await service.get_update_statistics()
        
        if result.get("success"):
            return {"success": True, "data": result}
        else:
            logger.error(f"âŒ [ç»Ÿè®¡API] è·å–ç»Ÿè®¡å¤±è´¥: {result.get('error')}")
            raise HTTPException(status_code=500, detail=result.get("error"))
            
    except Exception as e:
        logger.error(f"âŒ [ç»Ÿè®¡API] æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
